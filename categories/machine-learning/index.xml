<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine learning on Writing Lite</title><link>writinglite.com/categories/machine-learning/</link><description>Recent content in machine learning on Writing Lite</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sun, 27 Nov 2016 09:03:04 +0000</lastBuildDate><atom:link href="writinglite.com/categories/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>最大熵模型</title><link>writinglite.com/post/machine-learning/2016-11-27-%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/</link><pubDate>Sun, 27 Nov 2016 09:03:04 +0000</pubDate><guid>writinglite.com/post/machine-learning/2016-11-27-%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/</guid><description>最大熵原理 我们的预测应当满足全部已知条件，而对未知的情况不要做任何主观假设。也可以表述为在满足约束条件的模型集体合选取熵最大的模型。
假设现在需要做一个自动将英语到法语的翻译模型，为了方便说明，我们将这个问题简化为将英文句子中的单词{in}翻译成法语词汇。那么翻译模型p就是对于给定包含单词”in”的英文句子，需要给出选择某个法语单词f 做为”in”的翻译结果的概率p(f)。为了帮助开发这个模型，需要收集大量已经翻译好的样本数据。收集好样本之后，接下来需要做两件事情：一是从样本中抽取规则（特征），二是基于这些规则建立模型。 从样本中我们能得到的第一个规则就是in可能被翻译成的法语词汇有： {dans, en, à, au cours de, pendant}。 也就是说，我们可以给模型p施加第一个约束条件： p(dans)+p(en)+ p(à)+p(au cours de)+p(pendant) = 1。 这个等式是翻译模型可以用到的第一个对样本的统计信息。显然，有无数可以满足上面约束的模型p可供选择，例如： p(dans)=1，即这个模型总是预测dans 或者 p(pendant)=1/2 and p(à)=1/2，即模型要么选择预测pendant，要么预测à。 这两个模型都只是在没有足够经验数据的情况下，做的大胆假设。事实上我们只知道当前可能的选项是5个法语词汇，没法确定究竟哪个概率分布式正确。那么，一个更合理的模型假设可能是： p(dans) = 1/5 p(en) = 1/5 p(à) = 1/5 p(au cours de) = 1/5 p(pendant) = 1/5 即该模型将概率均等地分给5个词汇。但现实情况下，肯定不会这么简单，所以我们尝试收集更多的经验知识。假设我们从语料中发现有30%的情况下，in会被翻译成dans 或者en，那么运用这个知识来更新我们的模型，得到2模型约束： p(dans) + p(en) = 3/10 p(dans)+p(en)+ p(à)+p(au cours de)+p(pendant) = 1 同样，还是有很多概率分布满足这两个约束。在没有其他知识的情况下，最直观的模型p应该是最均匀的模型（例如，我拿出一个色子问你丢出5的概率是多少，你肯定会回答1/6），也就是在满足约束条件的情况下，将概率均等分配： p(dans) = 3/20 p(en) = 3/20 p(à) = 7/30 p(au cours de) = 7/30 p(pendant) = 7/30 假设我们再一次观察样本数据，发现：有一半的情况，in被翻译成了dans 或 à。这样，我们有就了3个模型约束： p(dans) + p(en) = 3/10 p(dans)+p(en)+ p(à)+p(au cours de)+p(pendant) = 1 p(dans)+ p(à)=1/2 我们可以再一次选择满足3个约束的最均匀的模型p，但这一次结果没有那么明显。由于经验知识的增加，问题的复杂度也增加了，归结起来，我们要解决两组问题：第一，均匀(uniform)究竟是什么意思?</description></item><item><title>EM算法</title><link>writinglite.com/post/machine-learning/2016-11-27-em%E7%AE%97%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2016-11-27-em%E7%AE%97%E6%B3%95/</guid><description>EM算法和最大似然估计一样是一种参数估计方法，与最大似然估计不同的是EM算法可以对着包含隐变量的数据进行参数估计。EM算法的思想是：若参数$\Theta$已知，则可根据训练数据推断出隐变量Z的值（E步）；反之，若Z的值已知，则可方便地对参数$\Theta$做极大似然估计（M步）。
Jensen不等式 令f(x)是一个凸函数(e.g f''(x)&amp;gt;=0,二阶导数大于0)，令x为随机变量。 那么， $$ f(E[x])&amp;lt;=E[f(x)] $$ 用一句话表达Jensen不等式，当函数是凸函数，那么该函数的期望大于等于期望的函数值。当X=E(X),当X为常量概率为1，E[f(x)] = f(E[x])。
如图，有0.5的概率是a，有0.5的概率是b。（就像掷硬币一样）。X的期望值就是a和b的中值了。
同理，对于凹函数，f''&amp;lt;=0,$f(E[x])&amp;gt;=E[f(x)]$。
##EM算法 假定有训练数据集 $$ { x^{(1)} , x^{(2)} , x^{(3)} \dots x^{(m)} } $$ 样本相互独立，我们想找到每个样例隐含的类别z。 模型$P(x,z;\theta)$,只能观测到x，对数似然函数， $$ \begin{align} l(\theta) &amp;amp;= \sum^m_{i=1}\log P(x^i;\theta) \
&amp;amp;= \sum^m_{i=1}\log \sum_{z^i} P(x^i,z^i;\theta) \end{align} $$ 然后我们求极大似然 $$ \begin{align} \sum^m_{i=1}\log \sum_{z^i} P(x^i,z^i;\theta) &amp;amp; = \sum_i\log\sum_{z^{(i)}}P(x^{(i)},z^{(i)};\theta) \
&amp;amp; = \sum_i \log \sum_{z^{(i)}} Q(z^{(i)}) \frac{P(x^{(i)},z^{(i)};\theta)}{Q(z^{(i)})} \
&amp;amp; \ge \sum_i \sum_{z^{(i)}} Q(z^{(i)}) \log \frac{P(x^{(i)},z^{(i)};\theta)}{Q(z^{(i)})} \end{align} $$ 最后一步用到了Jensen不等式，f(x)的f对应log函数，x对应$ \frac{P(x^{(i)},z^{(i)};\theta)}{Q(z^{(i)})}$，p(x)对应$Q(z^{(i)})$。那么$f(E[x])$对应$\log \sum_{z^{(i)}} Q(z^{(i)}) \frac{P(x^{(i)},z^{(i)};\theta)}{Q(z^{(i)})}$，$E[f(x)]$对应$\sum_{z^{(i)}} Q(z^{(i)}) \log \frac{P(x^{(i)},z^{(i)};\theta)}{Q(z^{(i)})}$。 因此$Q(z^{(i)})$代表的是p(x)也就是概率，所以显然 $$ \sum_{z^{(i)}} Q(z^{(i)}) = 1 , Q(z^{(i)})&amp;gt;0 $$</description></item><item><title>GBDT 解理</title><link>writinglite.com/post/machine-learning/2019-04-14-gbdt%E7%90%86%E8%A7%A3/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2019-04-14-gbdt%E7%90%86%E8%A7%A3/</guid><description>GBDT 全称是 Gradient Boosting Decision Tree，我们从分别这几个词来理解 GBDT;
Boosting GBDT 整体框架属于Boosting算法。Boosting方法是一种常用的统计学习方法，应用广泛有效。分类问题中，它通过改变训练样本的权重，学习多个弱分类器，并将这些分类器进行线性组合，提高分类性能。这里只对Boosting 这做简单说明。
Decision Tree 在 GBDT中学习的弱分类器就是决策树，具体来说是回归树并不是分类树，这里也不展开说明。
Gradient GBDT中改变训练样本的权重的方式是Gradient，使用 GBDT 来做回归任务时，通过推导Gradient=残差
回归问题的GBDT的学习过程 通俗点来讲，GBDT 是由一排回归树组成的，每一颗决策树学习目标是拟合前一颗树的Gradient或残差。
初始化$f_0(x)=0$ 对$m = 1,2、、、M$ 计算残差 $$ r_{mi} = y_i-f_{m-1}(x), i=1,2、、、N $$ 拟合残差$r_{mi}$学习一棵回归树，得到$h_m(x)$ 更新$f_m(x) = f_{m-1} + h_m(x)$ 得到回归问题的提升树 参考：
https://blog.csdn.net/zpalyq110/article/details/79527653 https://blog.csdn.net/u012422446/article/details/51506392 https://blog.csdn.net/anshuai_aw1/article/details/83040541
机器学习算法GBDT的面试要点总结-上篇
GBDT算法整理 https://www.msra.cn/zh-cn/news/features/lightgbm-20170105</description></item><item><title>Logistic回归</title><link>writinglite.com/post/machine-learning/2017-02-12-logistic%E5%9B%9E%E5%BD%92/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2017-02-12-logistic%E5%9B%9E%E5%BD%92/</guid><description>背景 logistic回归是统计学习中经典的分类方法，在深度学习也有很多应用。本文主要介绍logistic回归，然后将其推广到多分类问题-softmax回归。
什么是logistic 虽然名称中有回归，其实logistic回归模型是一个经典二分类模型。logistic回归在线性回归的基础上，套用了一个逻辑函数，但也就由于这个逻辑函数。
logstic回归模型的特点，一个事件的几率是指该事件发生的概率与不发生的概率的比值，如果事件发生的概率是p，那么该事件的几率是$\frac{p}{1-p}$，该事件的对数几率为 $$ logit(p) = \log \frac{p}{1-p} $$ 对于logistic回归而言这个对数几率就是wx，也就是说线性函数的值越接近正无穷，概率值越接近1；线性函数的值越接近负无穷，概率值越接近0，这样的模型就是logistic回归模型。一句话概括的话，logistic回归模型实际上是在用线性回归模型的预测结果去逼近真实标记的对数几率。
$$ h(\theta) = g(\theta^Tx) = \frac{1}{1+e^{-\theta^Tx}} $$ where $$ g(z) = \frac{1}{1+e^{-z}} $$
$$ P(p=1|x;\theta) = h_\theta(x) \
P(p=0|x;\theta) = 1 - h_\theta(x) $$
因此 $$ P(y|x;\theta) = (h_\theta(x))^y(1-h_\theta(x))^{1-y} $$
所以似然函数为 $$ \begin{align} L(\theta) &amp;amp; = L(\theta;X,\vec{y}) = p(\vec{y}|X;θ) \\
&amp;amp; =\prod_{i=1}^mp(y^{(i)}|x^{(i)};\theta) \\
&amp;amp; =\prod_{i=1}^m(h_\theta(x^{(i)}))^{y^{(i)}}(1-h_\theta(x^{(i)}))^{1-y^{(i)}} \end{align} $$
对数似然函数 $$ \begin{align} l(\theta) &amp;amp; = \log L(\theta) \\
&amp;amp; = \sum_{i=1}^my^{(i)}\log h(x^{(i)}) + (1-y^{(i)})\log (1-h(x^{(i)})) \end{align} $$</description></item><item><title>Logistic回归梯度下降推导</title><link>writinglite.com/post/machine-learning/2017-09-02-logistic%E5%9B%9E%E5%BD%92%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%8E%A8%E5%AF%BC/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2017-09-02-logistic%E5%9B%9E%E5%BD%92%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%8E%A8%E5%AF%BC/</guid><description>Logistic回归梯度下降推导 $$ P(p=1|x;\theta) = h_\theta(x) = \frac{exp(\theta^Tx)}{1+exp(\theta^Tx)} \
P(p=0|x;\theta) = 1 - h_\theta(x) = \frac{1}{1+exp(\theta^Tx)} $$
$$ \begin{align} L(\theta) &amp;amp; = L(\theta;X,\vec{y}) = p(\vec{y}|X;θ) \
&amp;amp; =\prod_{i=1}^mp(y^{(i)}|x^{(i)};\theta) \
&amp;amp; =\prod_{i=1}^m(h_\theta(x^{(i)}))^{y^{(i)}}(1-h_\theta(x^{(i)}))^{1-y^{(i)}} \end{align} $$
$$ \begin{align} l(\theta) &amp;amp; = \log L(\theta) \
&amp;amp; = \sum_{i=1}^m \left[ y^{(i)}\log h(x^{(i)}) + (1-y^{(i)})\log (1-h(x^{(i)})) \right] \
&amp;amp; = \sum_{i=1}^m \left[ y^{(i)}\log \frac{h(x^{(i)})}{1-h(x^{(i)})} + \log (1-h(x^{(i)})) \right] \
&amp;amp; = \sum_{i=1}^m \left[ y^{(i)}\theta^Tx + \log (1-h(x^{(i)})) \right] \end{align} $$</description></item><item><title>似然与极大似然估计</title><link>writinglite.com/post/machine-learning/2017-07-06-%E4%BC%BC%E7%84%B6%E4%B8%8E%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2017-07-06-%E4%BC%BC%E7%84%B6%E4%B8%8E%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/</guid><description>概要 本文先会介绍似然的概念，似然与概率的区别，然后介绍参数估计的方法——极大似然估计。
似然 在统计学中，似然函数（likelihood function，通常简写为likelihood，似然）是一个非常重要的内容，在非正式场合似然和概率（Probability）几乎是一对同义词，但是在统计学中似然和概率却是两个不同的概念。
概率是在特定环境下某件事情发生的可能性，也就是结果没有产生之前依据环境所对应的参数来预测某件事情发生的可能性，比如抛硬币，抛之前我们不知道最后是哪一面朝上，但是根据硬币的性质我们可以推测任何一面朝上的可能性均为50%，这个概率只有在抛硬币之前才是有意义的，抛完硬币后的结果便是确定的；
而似然刚好相反，是在确定的结果下去推测产生这个结果的可能环境（参数），还是抛硬币的例子，假设我们随机抛掷一枚硬币1,000次，结果500次人头朝上，500次数字朝上（实际情况一般不会这么理想，这里只是举个例子），我们很容易判断这是一枚标准的硬币，两面朝上的概率均为50%，这个过程就是我们根据结果来判断这个事情本身的性质（参数），也就是似然。
极大似然估计 似大似然估计解决的问题是，最大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。似大似然估计经常在机器学习方法中作为一种学习策略。
似然函数的最大值意味着什么？让我们回到概率和似然的定义，概率描述的是在一定条件下某个事件发生的可能性，概率越大说明这件事情越可能会发生；而似然描述的是结果已知的情况下，该事件在不同条件下发生的可能性，似然函数的值越大说明该事件在对应的条件下发生的可能性越大。
也就是说似然函数取得最大值表示相应的参数能够使得统计模型最为合理。
考虑一个抛硬币的例子。假设这个硬币正面跟反面轻重不同。我们把这个硬币抛80次（即，我们获取一个采样$x_1=H,x_2=T,&amp;hellip;..x_{80}$并把正面的次数记下来，正面记为H，反面记为T）。并把抛出一个正面的概率记为p，抛出一个反面的概率记为1-p（因此，这里的 p即相当于上边的 $\theta$ ）。 假设我们抛出了49个正面，31个反面，即49次H，31次T。假设这个硬币是我们从一个装了三个硬币的盒子里头取出的。这三个硬币抛出正面的概率分别为p=1/3, p=1/2,p=2/3.这些硬币没有标记，所以我们无法知道哪个是哪个。 使用最大似然估计，通过这些试验数据（即采样数据），我们可以计算出哪个硬币的可能性最大。这个似然函数取以下三个值中的一个： $$ P(H=49,T=31 | p=1/3) = (1/3)^{49}(1-1/3) ^{31}= 0.000 \
P(H=49,T=31 | p=1/2) = (1/2)^{49}(1-1/2)^{31} = 0.012 \
P(H=49,T=31 | p=2/3) = (2/3)^{49}(1-2/3)^{31} = 0.054 \
$$ 我们可以看到当p=2/3时，似然函数取得最大值。这就是 p的最大似然估计。
但在机器学习中我们要估计的并不是离散的情况，因此最大似然估计的一般求解过程是：
写出似然函数； 对似然函数取对数，并整理，也就对数似然函数； 求导数，解似然方程，也就是取极值； 参考： https://zhuanlan.zhihu.com/p/22092462 https://zh.wikipedia.org/wiki/似然函数 https://zh.wikipedia.org/wiki/最大似然估计</description></item><item><title>决策树</title><link>writinglite.com/post/machine-learning/2017-07-19-%E5%86%B3%E7%AD%96%E6%A0%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2017-07-19-%E5%86%B3%E7%AD%96%E6%A0%91/</guid><description>背景 决策树的优点是计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。缺点是可能会产生过度匹配问题。适用于连续值和离散值数据。
决策树生成 训练集$D={(x_1,y_1),(x_2,y_2),\dots,(x_m,y_m)}$ 属性集$A={a_1,a_2,\dots,a_d}$
def function treeGenerate(D,A): 生成结node; if Dv为空: 将该分支结点标记为叶结点，其类别标记为D中样本最多的类;return; if D中所有实例属于同一类: 将该分支结点标记为叶结点，将该类作为其类别标记;return; a* = 从A中选择最优划分属性; for v in a*: 为node生成一个分支； 令Dv表示D中在a*上取值为v的样本子集； 以treeGenerate(Dv,A-a*)为分支结点 特征选择 特征选择在于选取对训练数据具有分类能力的特征。这样可以提高决策树学习的效率。如果利用一个特征进行分类的结果与随机分类的结果没有很大差别，则称这个特征是没有特征是没有分类能力的。
信息增益 信息增益也叫互信息。当获取的信息和要研究的事物“有关系”时，这些信息才能帮助我们消除不确定性。当然“有关系”这种说法太模糊，太不科学，最好能度化的度量“相关性”。 熵： $H(X) = -\sum_i^nP(x_i)\log(P(x_i)$ 条件熵： $H(Y|X) = \sum_i^nP(x_i)H(Y|X=x_i)$ 信息增益就是熵与条件熵的差值： $$ Gain(D,a) = H(D) - H(D|a) = -\sum_i^{|Y|} P(Y_i) \log P(Y_i) - \sum_j^{|a|}P(a_j)H(D|a=a_j) \
= H(D) - \sum_{v=1}^V \frac{|D^v|}{|D|}H(D^v) $$
信息增益比 信息增益作为划分训练数据的特征，存在偏向于选择取值较多的特征的问题。使用信息增益比可以对这一问题进行校正。 信息增益比： $$ Gain_ratio(D,a) = \frac{Gain(D,a)}{H(a)} \
= \frac{H(D) - H(D|a)}{H(a)} \</description></item><item><title>感知机模型</title><link>writinglite.com/post/machine-learning/2017-02-12-%E6%84%9F%E7%9F%A5%E6%9C%BA%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2017-02-12-%E6%84%9F%E7%9F%A5%E6%9C%BA%E6%A8%A1%E5%9E%8B/</guid><description>感知机使用的函数： $$ g(z) = \begin{cases} 1, &amp;amp; \text{if z ≥ 0} \
0, &amp;amp; \text{if z &amp;lt; 0} \
\end{cases} $$
因此， $$ h(\theta) = g(\theta^Tx) $$
学习算法和logistic一样 $$ \theta_j := \theta_j+ \alpha(y^i-h_\theta(x^i))x_j^i $$</description></item><item><title>拉格朗日乘数法</title><link>writinglite.com/post/machine-learning/2017-02-10-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2017-02-10-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6/</guid><description>求下面，约束最优化问题：
$$ \underset{w}{min}f(w) \
s.t. \ h_i(w) = 0,i=1&amp;hellip;l $$
首先创建一个拉格朗日算子 $$ L(w,\beta)=f(w)+\sum_i\beta_ih_i(w) $$ 其中$\beta_i$被称为拉格朗日乘数
然后令 $$ \frac{\partial L}{\partial w} = 0 \
\frac{\partial L}{\partial \beta} = 0
$$ 求方程组的解
广义拉格朗日乘数法 求下面，约束最优化问题： $$ \underset{w}{min}f(w) \
s.t. \ g_i(w) \le 0,i=1&amp;hellip;k \
s.t. \ h_i(w) = 0,i=1&amp;hellip;l $$
首先创建一个拉格朗日算子 $$ L(w,\alpha,\beta)=f(w)+\sum_{i=1}^k\alpha_ig_i(w) +\sum_{i=1}^l\beta_ih_i(w) $$
定义 $$ \theta_p(w) = \underset{\alpha,\beta;\alpha_i&amp;gt;0}{max}L(w,\alpha,\beta) $$
$$ p^*=\underset{w}{min}\ \underset{\alpha,\beta;\alpha_i&amp;gt;0}{max}L(w,\alpha,\beta) = \underset{w}{min}\ \theta_p(w) $$
p代表primal，这类问题称为原始问题
$$ \theta_p(w) = \begin{cases} f(w), &amp;amp; \text{符合约束条件} \</description></item><item><title>最小二乘回归</title><link>writinglite.com/post/machine-learning/2017-01-12-%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E5%9B%9E%E5%BD%92/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2017-01-12-%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E5%9B%9E%E5%BD%92/</guid><description>最小二乘线性回归与梯度下降算法 线性回归 预测函数： $$ h_\theta(x)=\theta_0 + \theta_1x_1 + \theta_2x_2 $$
将$x_0 = 1$
$$ h_\theta(x) = \sum_{i=0}^n\theta_ix_i $$
其中 $\theta$这参数，n表示特征数量
成本函数： $$ J(\theta) = \frac{1}{2}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2 $$
其中m表示样本数量，$(x^{(i)},y^{(i)})$表示第i个样本对儿，1/2是为了方便计算
我们目标： $$ \min_\theta J(\theta) $$
最小二乘成本函数的概率学解释（并不是唯一的解释） 假设该线性模型符合高斯分布 $$ p(y^{(i)}|x^{(i)};\theta) = \frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\sqrt{(y^{(i)}-\theta^Tx^{(i)^2})}{2\sigma^2}\right) $$
似然函数为： $$ L(\theta) = L(\theta;X,\vec{y}) = p(\vec{y}|X;θ) $$ 因此，线性回归的似然函数： $$ \begin{align} L(\theta) &amp;amp; = \prod_{i=1}^mp(y^{(i)}|x^{(i)};\theta) \
&amp;amp; = \prod_{i=1}^m\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{((y^{(i)}) - \theta^Tx^{(i)})^2}{2\sigma^2}\right) \end{align} $$
对数似然度为 $$ \begin{align} l(\theta) &amp;amp; = \log L(\theta)\</description></item><item><title>朴素贝叶斯</title><link>writinglite.com/post/machine-learning/2017-03-12-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2017-03-12-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</guid><description>朴素贝叶斯是一种分类模型，属于生成模型。比较常见的应用是垃圾邮件分类；
在垃圾邮件识别为例
$$ y\in{0,1} $$ y=1表示垃圾邮件
将每封邮件表示成一个向量，向量中每一维都是字典中的一个词的0/1值，1表示该词在邮件中出现，0表示未出现。 假设有一个50000个词的词表，一封邮件x可表示（多元伯努利时间模型） $$ x= \begin{bmatrix} 0 \
1 \
1 \
… \
\end{bmatrix} $$
$$ x=\in{0,1}^n $$ n=50000
假设 我们还是对P(X|Y)建模
$$ \begin{aligned} &amp;amp; P(x_1,x_2,&amp;hellip;x_{50000}|y) \
&amp;amp;= P(x_1|y)*P(x_2|y,x_1)*P(x_3|y,x_1,x_2)&amp;hellip; \
&amp;amp;= P(x_1|y)*P(x_2|y)*P(x_3|y)&amp;hellip;P(x_50000|y) \
&amp;amp;= \prod_{i=1}^{m}P(x_i|y) \end{aligned} $$ NLP中的n元语法模型有点类似，这里相当于一元文法unigram。
这里有个假设，条件独立性假设，形式化表示为，（如果给定Z的情况下，X和Y条件独立）
这里我们发现朴素贝叶斯假设是约束性很强的假设，“buy”从通常上讲与“price”是有关系，我们这里假设的是条件独立。
模型参数 $$ \begin{aligned} \phi_{i|y=1} &amp;amp;= P(x_i=1|y=1) \
\phi_{i|y=0} &amp;amp;= P(x_i=1|y=0) \
\phi_y&amp;amp;=P(y=1) \end{aligned} $$
joint似然函数为： $$ L(\phi_y,\phi_{i|y=0},\phi_{i|y=1})= \prod_{i=1}^{m}P(x^{(i)},y^{(i)}) $$
求该 Joint似然最大化得： $$ \begin{aligned} \phi_{i|y=1} &amp;amp;= \frac{\sum_{i=1}^mI{x_j^{(i)}=1,y^{(i)}=1}}{\sum_{i=1}^mI{y^{(i)}=1}} \</description></item><item><title>模型简要总结</title><link>writinglite.com/post/machine-learning/2017-03-12-%E6%A8%A1%E5%9E%8B%E7%AE%80%E8%A6%81%E6%80%BB%E7%BB%93/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2017-03-12-%E6%A8%A1%E5%9E%8B%E7%AE%80%E8%A6%81%E6%80%BB%E7%BB%93/</guid><description>模型简要总结 决策树 介绍 决策树是一种分类和回归方法。下面主要介绍分类部分。决策树模型呈树状结构，在分类问题中，表示基于特征对实例进行分类的过程。它也可以认为是if-then规则的集合。
模型的学习 决策树的学习本质上是从训练数据中归纳出一组分类规则。能对训练数据进行正确分类的决策树可能有多个，我们需要的是一个与训练数据矛盾较少，同时具有很好的泛化能力。决策树学习通常需要3个步骤：
特征选择 信息增益：特征对训练集的信息增益，等价于互信息。信息增益大的特征具有更强的分类能力。 $$ g(D,A)=H(D)-H(D \mid A) $$ 信息增益比：其信息增益与训练数据集关于特征A的值的熵$H_A(D)$之比 $$ g_R(D,A)=\frac{g(D,A)}{H_A(D)} $$ 决策树生成 决策树的剪枝 优缺点： logstic回归 最大熵 支持向量机 隐马尔可夫模型 条件随机场 关于熵 我们要搞清楚一件非常不确定的事，或是我们一无所知的事情，就需要了解大量的信息。相反，如果我们对某件事情已经有了较多的了解，那么不需要太多的信息就能把它搞清楚。所以，从这个角度来看，可以认为，信息量就等于不确定性的多少。
熵 $$ H(X)=-\sum_{x \in X} P(x) \log P(x) $$
条件熵 $$ H(X \mid Y)=-\sum_{x \in X,y \in Y} P(x,y) \log P(x \mid y) $$ 如果H(X)&amp;gt;=H(X|Y)，也就是说多了Y的信息，关于X的不确定性下降了。
互信息 $$ H(X ; Y)= H(X) - H(X \mid Y) $$ 两件事相关性的量化度量。</description></item><item><title>混合朴素贝叶斯模型</title><link>writinglite.com/post/machine-learning/2017-03-12-%E6%B7%B7%E5%90%88%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2017-03-12-%E6%B7%B7%E5%90%88%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B/</guid><description>训练样本，${x_1,x_2,x_3 &amp;hellip; x_m}$ m个文本。 $$ x^{(i)} \in {0,1}^n \
x^{(i)}_j = I{词j是否在文档x^{(i)}中 } \
z^{(i)} \in {0,1} \
z^{(i)} \sim 伯努利(\phi) $$ zi是隐含随机变量，也就是聚类类别，这里假设是两类，也因此分布为伯努利分布，也可以根据情况有更多类别。
条件独立假设： $$ P(x^{(i)} \mid z^{(i)}) = \prod_i^n P(x^{(i)}_j \mid z^{(i)}) $$ 表示，在给定类别z生成文档x的概率。
$$ P(x^{(i)}j=1 \mid z^{(i)} = 0) = \phi{j \mid z=0} $$ 对应高斯判别分析中的 $$ \begin{aligned} \phi_{i|y=1} &amp;amp;= P(x_i=1|y=1) \
\phi_{i|y=0} &amp;amp;= P(x_i=1|y=0) \
\phi_y&amp;amp;=P(y=1) \end{aligned} $$
E-step: $$ w^{(i)} = P(z^{(i)}=1 \mid x^{(i)};\phi_{j \mid z},\phi) \</description></item><item><title>混合高斯模型</title><link>writinglite.com/post/machine-learning/2017-02-18-%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2017-02-18-%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/</guid><description>混合高斯模型 假设z为隐变量，x,z存在如下关系。 $$ P(x^{(i)},z^{(i)}) = P(x^{(i)}|z^{(i)})P(z^{(i)}) $$ $$ z^{(i)} \sim Multinomial(\phi)$ \
\phi_j=P(z^{(i)}=j)&amp;gt;0 \
\sum_j\phi_j=1 \
(x^{(i)} \mid {z^{(i)}=j} ) \sim N(\mu_j ,\Sigma_j) $$ 这里的j的聚类的一个类别之一。
E-step: 对z的猜测 $$ \begin{aligned} w_j^{(i)} &amp;amp; := P(z^{(i)}_j \mid x^{(i)}=j;\phi,\mu_j,\Sigma_j) \
&amp;amp;= \frac{ P(x^{(i)} \mid z^{(i)}_j=j)P(z^{(i)}_j=j)}{\sum_l^n P(x^{(i)} \mid z^{(i)}_j=l)P(z^{(i)}_j=l)} \end{aligned} $$
其中，$P(z^{(i)}_j \mid x^{(i)}=j;\phi,\mu_j,\Sigma_j)$表示第i个样本生成z为类别j的概率。这里的n表示聚类总类别数。
M-step: 对参数的估计 $$ \phi_j:=\frac{1}{m} \sum_{i=1}^m w_j^{(i)} \
\mu_j:= \frac{\sum_{i=1}^m w_j^{(i)} x^{(i)} }{\sum_{i=1}^m w_j^{(i)}} \
\Sigma_j:=\frac{ \sum_{i=1}^m w_j^{(i)} (x^{(i)} - \mu_j) (x^{(i)} - \mu_j)^T }{\sum_{i=1}^n w_j^{(i)}} $$</description></item><item><title>生成模型与高斯判别分析</title><link>writinglite.com/post/machine-learning/2017-03-12-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E4%B8%8E%E9%AB%98%E6%96%AF%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2017-03-12-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E4%B8%8E%E9%AB%98%E6%96%AF%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/</guid><description>生成模型与判别模型 判别模型 判别模型对P(y|x)或者说对y建模，直接学习得到y。 常见的判别模型有线性回归、对数回归、线性判别分析、支持向量机、boosting、条件随机场、神经网络等。
生成模型 生成模型对P(x|y)或者说对x建模，通过计算 $$ \begin{aligned} \arg\max\limits_{y}p(y\vert x) &amp;amp;= \arg\max\limits_y\frac{p(x\vert y)p(y)}{p(x)} \
&amp;amp;= \arg\max\limits_y p(x\vert y)p(y) \end{aligned} $$ 得到y。 因此给定x进行比较时，P(x)为固定值，所以P(x)可省略。 常见的生产模型有隐马尔科夫模型、朴素贝叶斯模型、高斯混合模型、LDA、Restricted Boltzmann Machine等。
高斯分布 若随机变量 X, X服从一个位置参数为 $\mu$ 、尺度参数为$\sigma$ 的概率分布，记为： $$ \displaystyle X \sim N(\mu ,\sigma ^{2}) $$ 则其概率密度函数为 $$ \displaystyle f(x)={1 \over \sigma {\sqrt {2\pi }}},e^{-{(x-\mu )^{2} \over 2\sigma ^{2}}} $$
多元高斯分布 $$ X ∼ N(\mu,\Sigma) $$
$$ \begin{aligned} E[X] &amp;amp;= \mu \
Cov(X) &amp;amp;= \Sigma \end{aligned} $$ 概率密度函数为 $$ \begin{equation} p(x;\mu,\Sigma) = \frac{1}{(2\pi)^{\frac{n}{2}}\big\vert\Sigma\big\vert^{\frac{1}{2}}}e^{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)} \end{equation} $$ 其中$|\Sigma|$是$\Sigma$的行列式，$\Sigma$是协方差矩阵，而且是对称半正定的。</description></item><item><title>统计学习方法</title><link>writinglite.com/post/machine-learning/2017-01-07-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2017-01-07-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/</guid><description>统计学习 如果一个系统能够通过执行某个过程改进它的性能，这就是学习。
统计学习的前提 统计学习关于数据的基本假设是同类数据具有一定的统计规律性，这就是统计学习的前提。
统计学习方法组成 统计计算由监督学习，非监督学习，半监督学习和强化学习等组成。
监督学习概括 从给定的、有限的、用于学习的训练数据集合出发，假设数据是独立同分布产生的；并且假设要学习模型属于某个函数集合，称为假设空间；应用某个评价准则，从假设空间中选取一个最优的模型，使它对已知训练数据及未知测试数据在给定的评价准则下有最优的预测；最优模型的选取由算法实现。
统计学习方法的三要素 模型 策略 算法 实现统计学习方法的步骤 得到一个有限的训练数据集合 确定包含所有可能模型的假设空间，即学习模型的集合 确定模型选择的准则，即学习的策略 实现求解最优模型的算法，取出学习的算法 通过学习方法选择最做强模型 利用学习的最优模型对新数据进行预测和分析 基本概念 输入空间 输入所有可能的空间
输出空间 输出所有可能的空间
特征空间 每个具体的输入是一个实例，通常由特征向量表示。这时所有特征向量存在的空间称为特征空间。
样本 输入输出对又称为样本或样本点。
问题的分类 回归问题 输入变量与输出变量均为连续变量的预测问题称为回归问题。
分类问题 输出变量为有限个离散变量的预测问题称为分类问题。
标注问题 输入变量与输出变量均为变量序列的预测问题称为标注问题。
联合概率分布 监督学习假设输入与输出的随机变量X与Y遵循联合概率分布。训练数据与测试数据被看作是依联合概率分布P(X,Y)独立同分布产生的。
假设空间 模型属于由输入空间到输出空间的映射的集合，这个集合就是假设空间。
监督学习的模型可以是概率模型或非概率模型，由条件概率分布P(Y|X)或决策函数Y=f(X)表示，随具体学习方法而定。
统计学习的三要素 方法=模型+策略+算法
模型 策略 损失函数:度量一次预测的好坏 风险函数：度量平均意义下模型预测的好坏</description></item><item><title>统计学习方法概论</title><link>writinglite.com/post/machine-learning/2017-06-04-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2017-06-04-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/</guid><description>统计学习的基本概念 学习的定义 如果一个系统能够通过执行某个过程改进它的性能，这就是学习。统计学习的对象是数据；统计学习关于数据的基本假设是同类数据具有一定的统计规律，这是统计学习的前提。统计学习的上的是对未知数据进行预测和分析；对数据的预测可以使计算机更加智能化；对数据的分析可以让人们获取新的知识，给人们带来新的发现。
监督学习的学习方法 从给定的、有限的、用于学习的训练数据集合出发，假设数据是独立同分布产生的；并且假设学习的模型属于某个函数集合，称为假设空间；应用某个评价准则，从假设空间中选取一个最优的模型，使它对已知训练数据及未知测试数据在给定的评价准则下有最优的预测；最优模型的选取由算法实现。
实现统计学习方法的步骤 得到一个有限的训练数据集合 确定包含所有可能模型的假设空间，即学习模型的集合 确定模型选择的准则，即学习的策略 实现求解最优模型的算法，取出学习的算法 通过学习方法选择最做强模型 利用学习的最优模型对新数据进行预测和分析 不同的预测任务名称 输入变量与输出变量均为连续变量的预测问题称为回归问题。 输出变量为有限个离散变量的预测问题称为分类问题。 输入变量与输出变量均为变量序列的预测问题称为标注问题。 联合概率分布 监督学习假设输入与输出的随机变量X和Y遵循联合概率分布P(X,Y)，P(X,Y)表示分布函数，或分布密度函数。训练数据与测试数据被看作是依联合概率分布P(X,Y)独立同分布产生的。
判别模型 判别模型对P(y|x)或者说对y建模，直接学习得到y。 在计算学习算法时，一般使用candidation似然 就是直接用的P(y|x) 常见的判别模型有线性回归、对数回归、线性判别分析、支持向量机、boosting、条件随机场、神经网络等。
生成模型 生成模型对P(x|y)或者说对x建模（从下面的公式可以看到），通过如下计算得到 y。 $$ \begin{aligned} \arg\max\limits_{y}p(y\vert x) &amp;amp;= \arg\max\limits_y\frac{p(x,y)}{p(x)} \
&amp;amp;= \arg\max\limits_y\frac{p(x\vert y)p(y)}{p(x)} \
&amp;amp;= \arg\max\limits_y p(x\vert y)p(y) \end{aligned} $$ 在给定x进行比较时，P(x)为固定值，所以P(x)可省略。在计算学习算法时，一般使用joint似然，就是用的P(x,y)=P(x|y)*P(y)，其实和P(y|x) 一样的。 生成模型表示的是数据生成的方式 ，就是P(x,y) x和y的联合概率。一般来说数据的生成方式是比较复杂的，所以一般都会对数据的生成方式做一定的假设（比如隐马尔科夫模型、朴素贝叶斯模型）。 常见的生产模型有隐马尔科夫模型、朴素贝叶斯模型、高斯混合模型、LDA、Restricted Boltzmann Machine等
统计学习的三要素 统计学习方法包括模型的假设空间、模型选择的准则以及模型的学习算法，称其为统计学习方法的三要素，简称为模型、策略、算法。
模型 在监督学习过程中，模型就是所要学习的条件概率分布或决策函数。模型的假设空间包含所有可能的条件概率分布或决策函数。 假设空间用F表示，假设空间可以定义为决策函数的集合 $$ F={f|Y=f(x)} $$ 假设空间也可以定义为条件概率的集合 $$ F={P|P(Y|X)} $$
策略 首先引入损失函数与风险函数的概念。损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型预测的好坏。
常用的损失函数 **0-1损失函数 ** $$ L(Y,f(X))= \begin{cases} 1,Y \neq f(X)\</description></item><item><title>隐马尔可夫模型</title><link>writinglite.com/post/machine-learning/2016-11-25-%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2016-11-25-%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/</guid><description>隐马尔可夫模型解决的序列标注问题，它是一个生成模型。本文先介绍显马尔可夫模型（或者叫马尔可夫链），然后介绍显马尔可夫模型的扩展，即隐马尔可夫模型。显与隐指的是状态序列是否可观测。
显（可视）马尔可夫模型 显马尔可夫模型、可视马尔可夫模型、马尔可夫链都是指马尔可夫模型。
随机过程又称随机函数，是随时间而随机变化的过程。马尔可夫模型描述了一类（这些随机变量并非相互独立，每个随机变量的值依赖于这个序列前面的状态）重要的随机过程。 随机过程有两层含义：
它是一个时间的函数，随着时间的改变可改变。 每个时刻上的函数值是不确定的，是随机的，也就是说，每一时刻上的函数值按照一定的概率而分布。 马尔可夫模型与有限状态机 马尔可夫模型又可视为随机的有限状态机，更准确的说马尔可夫模型和隐马尔可夫模型都是有限自动机的扩充。
马尔可夫模型与n元文法模型 前面提到在马尔可夫模型中每个随机变量受这个序列前面的状态影响的，如果我们只考虑前面一个状态对后面一个状态出现的概率的影响，这样的链叫做一重马尔可夫链，也就量二元文法模型，如果考虑前面两个状态，这样的叫二重马可尔可夫链，也就是三元文法模型，依此类推，n重马尔可夫链对应n-1元文法模型。
隐马尔可夫模型 马尔可夫模型是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可可观测 的状态随机序列，再由各个状态生成一个观测而产生观测 随机序列的过程。 马尔可夫模型是一个生成模型，因此它也是学习
$$ p(y \vert x) = \frac{p(x,y)}{p(x)} = \frac{p(x \vert y)p(y)}{p(x)} $$
相关符号 高Q是所有可能状态集合，V是所有可能的观测集合。 $$ Q={q_1,q_2, &amp;hellip; q_N },V={v_1,v_2, &amp;hellip; v_M } $$ N是可能的状态数，M是可能的观测数。 I是长度为T的状态序列，O是对应的观测序列。 $$ I={i_1,i_2, &amp;hellip; i_T },O={o_1,o_2, &amp;hellip; o_T } $$ A是状态转移矩阵： $$ A=[a_{ij}]_{M \times N} $$ 其中 $$ a_{ij}=P(i_{t+1}=q_j|i_t=q_i), \qquad i=1,2&amp;hellip;N;j=1,2&amp;hellip;N $$ 表示在时刻t处于状态qi的状态下在时刻t+1转移到状态qj的概率。
B是观测概率矩阵： $$ B=[b_j(k)]_{N \times M} $$</description></item><item><title>集成学习简单介绍</title><link>writinglite.com/post/machine-learning/2017-07-15-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>writinglite.com/post/machine-learning/2017-07-15-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/</guid><description>背景 目前在kaggle中，GBDT和RF都是非常流行的算法，在一些比赛中，排名先前的算法都有这两种算法的身影。这两种算法都属于Ensemble算法，因此，本文将介绍介绍下Ensemble的思想，以及实现Ensemble的两种方法。
什么是集成学习 Ensemble通过构建多个学习器来完成学习任务，直觉上来说，由于不再是单一的模型进行预测，所以模型有了“集思广益”的能力，也就不容易产生过拟合现象。但并不是说，随机进行组合就能得到好的效果，各个子模型应该“好而不同”，即个体学习器要有一定的“准确性”又要有“互补性”。
根据个体学习器的生成方式，目前的集成学习方法大致可分为两大类，即
个体学习器间存在强依赖关系、必须串行生成的序列化算法。 个体学习器间不存在依赖关系、可同时生成的并行化算法。 前者的代表是Bossting，后者的代表是Bagging。从偏差-方差的角度看Bossting主要关注降低偏差，因此Bossting能基于泛化性能相当弱的学习器构建出很强的学习器，比如一棵只有5层的决策树。而Bagging主要关注降低方差，因此它在不剪枝层次较深的决策树、神经网络等易样本干扰的学习器上效用更加明显。 要获得好的集成，个体学习器应“好而不同”，即个体学习器要有一定的“准确性”，即学习器不能太坏，并且要有“多样性”，即学习器间具有差异。
Bostting Bostting是一族可将弱学习器提升为强学习器的算法，这族算法的工作机制类似：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多的关注，然后基于调整后的样本来训练下一个基学习器；如此重复进行，直至基学习器数目达到事先指定的值T，最终将这个T个基学习器进行加权结合。
Bagging 如上所述，一个可行的集成学习算法，要满足两个要点，一是“多样性”二是“准确性”。一个可行的做法是对训练样本进行采样，产生出若干个不同的子集，再从每个数据集中训练出一个学习器，这样就满足了“多样性”。然而，采样的每个子集都完全不同，则每个学习器只用到了一个小部分训练数据，甚至不足以进行有效学习，这显然无法确保产生出比较好的基学习器，为了解决这个问题可以采用自助采样法。
《机器学习》 周志华 https://www.zhihu.com/question/29036379</description></item></channel></rss>