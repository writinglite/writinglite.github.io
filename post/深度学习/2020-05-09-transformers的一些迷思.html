<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Transformers的一些迷思 - Writing Lite</title><script>(function(a,b){a[b]=a[b].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:title" content="Transformers的一些迷思"><meta property="og:description" content="通过from_pretrained缓存的模型在哪 如果调用from_pretrained方法时指定了cache_dir 则保存到cache_dir，
cache_dir = kwargs.pop(&#34;cache_dir&#34;, None) 如果没指定则去通过系统环境变量寻找（&ldquo;PYTORCH_TRANSFORMERS_CACHE&rdquo;&#34;, &ldquo;PYTORCH_PRETRAINED_BERT_CACHE&rdquo;）
os.getenv(&#34;PYTORCH_TRANSFORMERS_CACHE&#34;, os.getenv(&#34;PYTORCH_PRETRAINED_BERT_CACHE&#34;, default_cache_path)) 如果还没找到则设置为pytorch_home下的transformers目录下
from torch.hub import _get_torch_home torch_cache_home = _get_torch_home() os.path.join(torch_cache_home, &#34;transformers&#34;) from_pretrained方法是如何加载模型的 首先判断是否在pretrained_model_archive_map中，然后判断是否为目录或文件，如果都不是则默认为hf_bucket_url
https://s3.amazonaws.com/models.huggingface.co/bert/{pretrained_model_name_or_path}/{pytorch_model.bin/tf_model.h5} pytorch_model.bin或tf_model.h5 通过from_tf判断
不同模型实现from_pretrained的方式 from_pretrained 的根据不同 cls 来实现加载不同模型的差异， 以bert为例， cls -> BertPreTrainedModel；
class BertPreTrainedModel(PreTrainedModel): &#34;&#34;&#34; An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained models. &#34;&#34;&#34; config_class = BertConfig pretrained_model_archive_map = BERT_PRETRAINED_MODEL_ARCHIVE_MAP load_tf_weights = load_tf_weights_in_bert base_model_prefix = &#34;bert&#34; def _init_weights(self, module): &#34;&#34;&#34; Initialize the weights &#34;&#34;&#34; if isinstance(module, (nn."><meta property="og:type" content="article"><meta property="og:url" content="/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2020-05-09-transformers%E7%9A%84%E4%B8%80%E4%BA%9B%E8%BF%B7%E6%80%9D.html"><meta property="article:section" content="post"><meta property="article:published_time" content="2020-05-09T21:07:00+00:00"><meta property="article:modified_time" content="2020-05-09T21:07:00+00:00"><meta itemprop=name content="Transformers的一些迷思"><meta itemprop=description content="通过from_pretrained缓存的模型在哪 如果调用from_pretrained方法时指定了cache_dir 则保存到cache_dir，
cache_dir = kwargs.pop(&#34;cache_dir&#34;, None) 如果没指定则去通过系统环境变量寻找（&ldquo;PYTORCH_TRANSFORMERS_CACHE&rdquo;&#34;, &ldquo;PYTORCH_PRETRAINED_BERT_CACHE&rdquo;）
os.getenv(&#34;PYTORCH_TRANSFORMERS_CACHE&#34;, os.getenv(&#34;PYTORCH_PRETRAINED_BERT_CACHE&#34;, default_cache_path)) 如果还没找到则设置为pytorch_home下的transformers目录下
from torch.hub import _get_torch_home torch_cache_home = _get_torch_home() os.path.join(torch_cache_home, &#34;transformers&#34;) from_pretrained方法是如何加载模型的 首先判断是否在pretrained_model_archive_map中，然后判断是否为目录或文件，如果都不是则默认为hf_bucket_url
https://s3.amazonaws.com/models.huggingface.co/bert/{pretrained_model_name_or_path}/{pytorch_model.bin/tf_model.h5} pytorch_model.bin或tf_model.h5 通过from_tf判断
不同模型实现from_pretrained的方式 from_pretrained 的根据不同 cls 来实现加载不同模型的差异， 以bert为例， cls -> BertPreTrainedModel；
class BertPreTrainedModel(PreTrainedModel): &#34;&#34;&#34; An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained models. &#34;&#34;&#34; config_class = BertConfig pretrained_model_archive_map = BERT_PRETRAINED_MODEL_ARCHIVE_MAP load_tf_weights = load_tf_weights_in_bert base_model_prefix = &#34;bert&#34; def _init_weights(self, module): &#34;&#34;&#34; Initialize the weights &#34;&#34;&#34; if isinstance(module, (nn."><meta itemprop=datePublished content="2020-05-09T21:07:00+00:00"><meta itemprop=dateModified content="2020-05-09T21:07:00+00:00"><meta itemprop=wordCount content="112"><meta itemprop=keywords content="bert,transformers,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Transformers的一些迷思"><meta name=twitter:description content="通过from_pretrained缓存的模型在哪 如果调用from_pretrained方法时指定了cache_dir 则保存到cache_dir，
cache_dir = kwargs.pop(&#34;cache_dir&#34;, None) 如果没指定则去通过系统环境变量寻找（&ldquo;PYTORCH_TRANSFORMERS_CACHE&rdquo;&#34;, &ldquo;PYTORCH_PRETRAINED_BERT_CACHE&rdquo;）
os.getenv(&#34;PYTORCH_TRANSFORMERS_CACHE&#34;, os.getenv(&#34;PYTORCH_PRETRAINED_BERT_CACHE&#34;, default_cache_path)) 如果还没找到则设置为pytorch_home下的transformers目录下
from torch.hub import _get_torch_home torch_cache_home = _get_torch_home() os.path.join(torch_cache_home, &#34;transformers&#34;) from_pretrained方法是如何加载模型的 首先判断是否在pretrained_model_archive_map中，然后判断是否为目录或文件，如果都不是则默认为hf_bucket_url
https://s3.amazonaws.com/models.huggingface.co/bert/{pretrained_model_name_or_path}/{pytorch_model.bin/tf_model.h5} pytorch_model.bin或tf_model.h5 通过from_tf判断
不同模型实现from_pretrained的方式 from_pretrained 的根据不同 cls 来实现加载不同模型的差异， 以bert为例， cls -> BertPreTrainedModel；
class BertPreTrainedModel(PreTrainedModel): &#34;&#34;&#34; An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained models. &#34;&#34;&#34; config_class = BertConfig pretrained_model_archive_map = BERT_PRETRAINED_MODEL_ARCHIVE_MAP load_tf_weights = load_tf_weights_in_bert base_model_prefix = &#34;bert&#34; def _init_weights(self, module): &#34;&#34;&#34; Initialize the weights &#34;&#34;&#34; if isinstance(module, (nn."><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/custom.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=/ title="Writing Lite" rel=home><div class="logo__item logo__text"><div class=logo__title>Writing Lite</div><div class=logo__tagline>Just writing a lite blog</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/archives/><span class=menu__text>archives</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Transformers的一些迷思</h1><div class="post__meta meta"><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2.0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class=meta__text>hwyang</span></div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2020-05-09T21:07:00Z>2020-05-09</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=/categories/deep-learning.html rel=category>deep learning</a></span></div></div></header><div class="post__toc toc"><div class=toc__title>Page content</div><div class=toc__menu><nav id=TableOfContents><ul><li><ul><li></li></ul></li></ul></nav></div></div><div class="content post__content clearfix"><h4 id=通过from_pretrained缓存的模型在哪>通过from_pretrained缓存的模型在哪</h4><p>如果调用from_pretrained方法时指定了cache_dir 则保存到cache_dir，</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>cache_dir <span style=color:#f92672>=</span> kwargs<span style=color:#f92672>.</span>pop(<span style=color:#e6db74>&#34;cache_dir&#34;</span>, None)
</code></pre></div><p>如果没指定则去通过系统环境变量寻找（&ldquo;PYTORCH_TRANSFORMERS_CACHE&rdquo;", &ldquo;PYTORCH_PRETRAINED_BERT_CACHE&rdquo;）</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>os<span style=color:#f92672>.</span>getenv(<span style=color:#e6db74>&#34;PYTORCH_TRANSFORMERS_CACHE&#34;</span>, os<span style=color:#f92672>.</span>getenv(<span style=color:#e6db74>&#34;PYTORCH_PRETRAINED_BERT_CACHE&#34;</span>, default_cache_path))
</code></pre></div><p>如果还没找到则设置为pytorch_home下的transformers目录下</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> torch.hub <span style=color:#f92672>import</span> _get_torch_home
torch_cache_home <span style=color:#f92672>=</span> _get_torch_home()
os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(torch_cache_home, <span style=color:#e6db74>&#34;transformers&#34;</span>)
</code></pre></div><h4 id=from_pretrained方法是如何加载模型的>from_pretrained方法是如何加载模型的</h4><p>首先判断是否在pretrained_model_archive_map中，然后判断是否为目录或文件，如果都不是则默认为hf_bucket_url</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>https:<span style=color:#f92672>//</span>s3<span style=color:#f92672>.</span>amazonaws<span style=color:#f92672>.</span>com<span style=color:#f92672>/</span>models<span style=color:#f92672>.</span>huggingface<span style=color:#f92672>.</span>co<span style=color:#f92672>/</span>bert<span style=color:#f92672>/</span>{pretrained_model_name_or_path}<span style=color:#f92672>/</span>{pytorch_model<span style=color:#f92672>.</span>bin<span style=color:#f92672>/</span>tf_model<span style=color:#f92672>.</span>h5}
</code></pre></div><p>pytorch_model.bin或tf_model.h5 通过from_tf判断</p><h4 id=不同模型实现from_pretrained的方式>不同模型实现from_pretrained的方式</h4><p>from_pretrained 的根据不同 cls 来实现加载不同模型的差异， 以bert为例， cls -> BertPreTrainedModel；</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>BertPreTrainedModel</span>(PreTrainedModel):
    <span style=color:#e6db74>&#34;&#34;&#34; An abstract class to handle weights initialization and
</span><span style=color:#e6db74>        a simple interface for downloading and loading pretrained models.
</span><span style=color:#e6db74>    &#34;&#34;&#34;</span>

    config_class <span style=color:#f92672>=</span> BertConfig
    pretrained_model_archive_map <span style=color:#f92672>=</span> BERT_PRETRAINED_MODEL_ARCHIVE_MAP
    load_tf_weights <span style=color:#f92672>=</span> load_tf_weights_in_bert
    base_model_prefix <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;bert&#34;</span>

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_init_weights</span>(self, module):
        <span style=color:#e6db74>&#34;&#34;&#34; Initialize the weights &#34;&#34;&#34;</span>
        <span style=color:#66d9ef>if</span> isinstance(module, (nn<span style=color:#f92672>.</span>Linear, nn<span style=color:#f92672>.</span>Embedding)):
            <span style=color:#75715e># Slightly different from the TF version which uses truncated_normal for initialization</span>
            <span style=color:#75715e># cf https://github.com/pytorch/pytorch/pull/5617</span>
            module<span style=color:#f92672>.</span>weight<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>normal_(mean<span style=color:#f92672>=</span><span style=color:#ae81ff>0.0</span>, std<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>config<span style=color:#f92672>.</span>initializer_range)
        <span style=color:#66d9ef>elif</span> isinstance(module, BertLayerNorm):
            module<span style=color:#f92672>.</span>bias<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>zero_()
            module<span style=color:#f92672>.</span>weight<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>fill_(<span style=color:#ae81ff>1.0</span>)
        <span style=color:#66d9ef>if</span> isinstance(module, nn<span style=color:#f92672>.</span>Linear) <span style=color:#f92672>and</span> module<span style=color:#f92672>.</span>bias <span style=color:#f92672>is</span> <span style=color:#f92672>not</span> None:
            module<span style=color:#f92672>.</span>bias<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>zero_()
</code></pre></div></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/bert/ rel=tag>bert</a></li><li class=tags__item><a class="tags__link btn" href=/tags/transformers/ rel=tag>transformers</a></li></ul></div></footer></article></main><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=/post/other/2020-03-02-%E5%9F%BA%E4%BA%8Enginx%E7%9A%84acme%E5%85%8D%E8%B4%B9%E8%AF%81%E4%B9%A6%E6%96%B9%E6%A1%88.html rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>基于nginx的acme免费证书方案</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=/post/tensorflow2.x_keras/tensorflow%E5%AE%9E%E6%88%981-tensorflow%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%90%AD%E5%BB%BA%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Tensorflow实战(1)-Tensorflow基本介绍及搭建全连接神经网络</p></a></div></nav><div id=gitalk-container></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css><script src=https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js></script><script>const gitalk=new Gitalk({clientID:'ffbd91469959056415a6',clientSecret:'c7348e2aa3bf5ecd634acef0df3344e3e039eb9c',repo:'writinglite.github.io',owner:'writinglite',admin:['writinglite'],id:decodeURI(location.pathname.split("/").pop()).replace(".html","").substring(0,49),distractionFreeMode:!1});(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('gitalk-container').innerHTML='Gitalk comments not available by default when the website is previewed locally.';return}gitalk.render('gitalk-container')})()</script></div></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2021 Writing Lite.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script><script src=/js/custom.js></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script><script type=text/x-mathjax-config>
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script></body></html>