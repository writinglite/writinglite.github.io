<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>DeepLearning中CRF的Tensorflow代码实现 - Writing Lite</title><script>(function(a,b){a[b]=a[b].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:title" content="DeepLearning中CRF的Tensorflow代码实现"><meta property="og:description" content="主方法 def crf_log_likelihood( inputs: TensorLike, tag_indices: TensorLike, sequence_lengths: TensorLike, transition_params: Optional[TensorLike] = None, ) -> tf.Tensor: &#34;&#34;&#34;Computes the log-likelihood of tag sequences in a CRF. Args: inputs: A [batch_size, max_seq_len, num_tags] tensor of unary potentials to use as input to the CRF layer. tag_indices: A [batch_size, max_seq_len] matrix of tag indices for which we compute the log-likelihood. sequence_lengths: A [batch_size] vector of true sequence lengths. transition_params: A [num_tags, num_tags] transition matrix, if available."><meta property="og:type" content="article"><meta property="og:url" content="writinglite.com/post/deep-learning/2020-10-16-deeplearning%E4%B8%ADcrf%E7%9A%84tensorflow%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"><meta property="article:section" content="post"><meta itemprop=name content="DeepLearning中CRF的Tensorflow代码实现"><meta itemprop=description content="主方法 def crf_log_likelihood( inputs: TensorLike, tag_indices: TensorLike, sequence_lengths: TensorLike, transition_params: Optional[TensorLike] = None, ) -> tf.Tensor: &#34;&#34;&#34;Computes the log-likelihood of tag sequences in a CRF. Args: inputs: A [batch_size, max_seq_len, num_tags] tensor of unary potentials to use as input to the CRF layer. tag_indices: A [batch_size, max_seq_len] matrix of tag indices for which we compute the log-likelihood. sequence_lengths: A [batch_size] vector of true sequence lengths. transition_params: A [num_tags, num_tags] transition matrix, if available."><meta itemprop=wordCount content="1111"><meta itemprop=keywords content="CRF,Tensorflow,"><meta name=twitter:card content="summary"><meta name=twitter:title content="DeepLearning中CRF的Tensorflow代码实现"><meta name=twitter:description content="主方法 def crf_log_likelihood( inputs: TensorLike, tag_indices: TensorLike, sequence_lengths: TensorLike, transition_params: Optional[TensorLike] = None, ) -> tf.Tensor: &#34;&#34;&#34;Computes the log-likelihood of tag sequences in a CRF. Args: inputs: A [batch_size, max_seq_len, num_tags] tensor of unary potentials to use as input to the CRF layer. tag_indices: A [batch_size, max_seq_len] matrix of tag indices for which we compute the log-likelihood. sequence_lengths: A [batch_size] vector of true sequence lengths. transition_params: A [num_tags, num_tags] transition matrix, if available."><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/writinglite.com/css/style.css><link rel=stylesheet href=/writinglite.com/css/custom.css><link rel="shortcut icon" href=/writinglite.com/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=/writinglite.com title="Writing Lite" rel=home><div class="logo__item logo__text"><div class=logo__title>Writing Lite</div><div class=logo__tagline>Just writing a lite blog</div></div></a></div><div class=divider></div></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>DeepLearning中CRF的Tensorflow代码实现</h1><div class="post__meta meta"><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2.0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class=meta__text>hwyang</span></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=writinglite.com/categories/deep-learning/ rel=category>deep learning</a></span></div></div></header><div class="post__toc toc"><div class=toc__title>Page content</div><div class=toc__menu><nav id=TableOfContents><ul><li><ul><li><a href=#主方法>主方法</a></li><li><a href=#sequence_scores-的计算><code>sequence_scores </code>的计算：</a></li><li><a href=#crf_log_norm计算><code>crf_log_norm</code>计算</a></li></ul></li></ul></nav></div></div><div class="content post__content clearfix"><h3 id=主方法>主方法</h3><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>crf_log_likelihood</span>(
    inputs: TensorLike,
    tag_indices: TensorLike,
    sequence_lengths: TensorLike,
    transition_params: Optional[TensorLike] <span style=color:#f92672>=</span> None,
) <span style=color:#f92672>-&gt;</span> tf<span style=color:#f92672>.</span>Tensor:
    <span style=color:#e6db74>&#34;&#34;&#34;Computes the log-likelihood of tag sequences in a CRF.
</span><span style=color:#e6db74>    Args:
</span><span style=color:#e6db74>      inputs: A [batch_size, max_seq_len, num_tags] tensor of unary potentials
</span><span style=color:#e6db74>          to use as input to the CRF layer.
</span><span style=color:#e6db74>      tag_indices: A [batch_size, max_seq_len] matrix of tag indices for which
</span><span style=color:#e6db74>          we compute the log-likelihood.
</span><span style=color:#e6db74>      sequence_lengths: A [batch_size] vector of true sequence lengths.
</span><span style=color:#e6db74>      transition_params: A [num_tags, num_tags] transition matrix,
</span><span style=color:#e6db74>          if available.
</span><span style=color:#e6db74>    Returns:
</span><span style=color:#e6db74>      log_likelihood: A [batch_size] `Tensor` containing the log-likelihood of
</span><span style=color:#e6db74>        each example, given the sequence of tag indices.
</span><span style=color:#e6db74>      transition_params: A [num_tags, num_tags] transition matrix. This is
</span><span style=color:#e6db74>          either provided by the caller or created in this function.
</span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
    num_tags <span style=color:#f92672>=</span> inputs<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>2</span>]

    <span style=color:#75715e># cast type to handle different types</span>
    tag_indices <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>cast(tag_indices, dtype<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>int32)
    sequence_lengths <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>cast(sequence_lengths, dtype<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>int32)

    <span style=color:#66d9ef>if</span> transition_params <span style=color:#f92672>is</span> None:
        initializer <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>keras<span style=color:#f92672>.</span>initializers<span style=color:#f92672>.</span>GlorotUniform()
        transition_params <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>Variable(
            initializer([num_tags, num_tags]), <span style=color:#e6db74>&#34;transitions&#34;</span>
        )

    sequence_scores <span style=color:#f92672>=</span> crf_sequence_score(
        inputs, tag_indices, sequence_lengths, transition_params
    )
    log_norm <span style=color:#f92672>=</span> crf_log_norm(inputs, sequence_lengths, transition_params)

    <span style=color:#75715e># Normalize the scores to get the log-likelihood per example.</span>
    log_likelihood <span style=color:#f92672>=</span> sequence_scores <span style=color:#f92672>-</span> log_norm
    <span style=color:#66d9ef>return</span> log_likelihood, transition_params
</code></pre></div><p><code>log_likelihood = sequence_scores - log_norm</code> 中<code>sequence_scores </code>表示<strong>单路径分数</strong>，<code>log_norm</code> 表示<strong>所有路径总分数</strong>。在<code>-log_likelihood </code>才是我们想要最小化的值（损失函数）。</p><h3 id=sequence_scores-的计算><code>sequence_scores </code>的计算：</h3><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>crf_sequence_score</span>(
    inputs: TensorLike,
    tag_indices: TensorLike,
    sequence_lengths: TensorLike,
    transition_params: TensorLike,
) <span style=color:#f92672>-&gt;</span> tf<span style=color:#f92672>.</span>Tensor:
    <span style=color:#e6db74>&#34;&#34;&#34;Computes the unnormalized score for a tag sequence.
</span><span style=color:#e6db74>    Args:
</span><span style=color:#e6db74>      inputs: A [batch_size, max_seq_len, num_tags] tensor of unary potentials
</span><span style=color:#e6db74>          to use as input to the CRF layer.
</span><span style=color:#e6db74>      tag_indices: A [batch_size, max_seq_len] matrix of tag indices for which
</span><span style=color:#e6db74>          we compute the unnormalized score.
</span><span style=color:#e6db74>      sequence_lengths: A [batch_size] vector of true sequence lengths.
</span><span style=color:#e6db74>      transition_params: A [num_tags, num_tags] transition matrix.
</span><span style=color:#e6db74>    Returns:
</span><span style=color:#e6db74>      sequence_scores: A [batch_size] vector of unnormalized sequence scores.
</span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
    tag_indices <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>cast(tag_indices, dtype<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>int32)
    sequence_lengths <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>cast(sequence_lengths, dtype<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>int32)

    <span style=color:#75715e># If max_seq_len is 1, we skip the score calculation and simply gather the</span>
    <span style=color:#75715e># unary potentials of the single tag.</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_single_seq_fn</span>():
        batch_size <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>shape(inputs, out_type<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>int32)[<span style=color:#ae81ff>0</span>]
        batch_inds <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>reshape(tf<span style=color:#f92672>.</span>range(batch_size), [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>])
        indices <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>concat([batch_inds, tf<span style=color:#f92672>.</span>zeros_like(batch_inds)], axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)

        tag_inds <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>gather_nd(tag_indices, indices)
        tag_inds <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>reshape(tag_inds, [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>])
        indices <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>concat([indices, tag_inds], axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)

        sequence_scores <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>gather_nd(inputs, indices)

        sequence_scores <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>where(
            tf<span style=color:#f92672>.</span>less_equal(sequence_lengths, <span style=color:#ae81ff>0</span>),
            tf<span style=color:#f92672>.</span>zeros_like(sequence_scores),
            sequence_scores,
        )
        <span style=color:#66d9ef>return</span> sequence_scores

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_multi_seq_fn</span>():
        <span style=color:#75715e># Compute the scores of the given tag sequence.</span>
        unary_scores <span style=color:#f92672>=</span> crf_unary_score(tag_indices, sequence_lengths, inputs)
        binary_scores <span style=color:#f92672>=</span> crf_binary_score(
            tag_indices, sequence_lengths, transition_params
        )
        sequence_scores <span style=color:#f92672>=</span> unary_scores <span style=color:#f92672>+</span> binary_scores
        <span style=color:#66d9ef>return</span> sequence_scores

    <span style=color:#66d9ef>return</span> tf<span style=color:#f92672>.</span>cond(tf<span style=color:#f92672>.</span>equal(tf<span style=color:#f92672>.</span>shape(inputs)[<span style=color:#ae81ff>1</span>], <span style=color:#ae81ff>1</span>), _single_seq_fn, _multi_seq_fn)
</code></pre></div><p>如果<code>inputs</code>的lengths是1（即只一个字或词），则使用<code>_single_seq_fn</code>计算，否则使用<code>_multi_seq_fn</code>，这里主要看<code>_multi_seq_fn</code>。</p><p><code>_multi_seq_fn</code>是两个部分组成<code>unary_scores</code>和<code>binary_scores</code>。</p><p><code>unary_scores</code>：计算的是<strong>EmissionScore</strong></p><p><code>binary_scores</code>：计算的是<strong>TransitionScore</strong></p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>crf_unary_score</span>(
    tag_indices: TensorLike, sequence_lengths: TensorLike, inputs: TensorLike
) <span style=color:#f92672>-&gt;</span> tf<span style=color:#f92672>.</span>Tensor:
    <span style=color:#e6db74>&#34;&#34;&#34;Computes the unary scores of tag sequences.
</span><span style=color:#e6db74>    Args:
</span><span style=color:#e6db74>      tag_indices: A [batch_size, max_seq_len] matrix of tag indices.
</span><span style=color:#e6db74>      sequence_lengths: A [batch_size] vector of true sequence lengths.
</span><span style=color:#e6db74>      inputs: A [batch_size, max_seq_len, num_tags] tensor of unary potentials.
</span><span style=color:#e6db74>    Returns:
</span><span style=color:#e6db74>      unary_scores: A [batch_size] vector of unary scores.
</span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
    tag_indices <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>cast(tag_indices, dtype<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>int32)
    sequence_lengths <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>cast(sequence_lengths, dtype<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>int32)

    batch_size <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>shape(inputs)[<span style=color:#ae81ff>0</span>]
    max_seq_len <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>shape(inputs)[<span style=color:#ae81ff>1</span>]
    num_tags <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>shape(inputs)[<span style=color:#ae81ff>2</span>]

    flattened_inputs <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>reshape(inputs, [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])

    offsets <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>expand_dims(tf<span style=color:#f92672>.</span>range(batch_size) <span style=color:#f92672>*</span> max_seq_len <span style=color:#f92672>*</span> num_tags, <span style=color:#ae81ff>1</span>)
    offsets <span style=color:#f92672>+=</span> tf<span style=color:#f92672>.</span>expand_dims(tf<span style=color:#f92672>.</span>range(max_seq_len) <span style=color:#f92672>*</span> num_tags, <span style=color:#ae81ff>0</span>)
    <span style=color:#75715e># Use int32 or int64 based on tag_indices&#39; dtype.</span>
    <span style=color:#66d9ef>if</span> tag_indices<span style=color:#f92672>.</span>dtype <span style=color:#f92672>==</span> tf<span style=color:#f92672>.</span>int64:
        offsets <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>cast(offsets, tf<span style=color:#f92672>.</span>int64)
    flattened_tag_indices <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>reshape(offsets <span style=color:#f92672>+</span> tag_indices, [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])

    unary_scores <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>reshape(
        tf<span style=color:#f92672>.</span>gather(flattened_inputs, flattened_tag_indices), [batch_size, max_seq_len]
    )

    masks <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>sequence_mask(
        sequence_lengths, maxlen<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>shape(tag_indices)[<span style=color:#ae81ff>1</span>], dtype<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>float32
    )

    unary_scores <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>reduce_sum(unary_scores <span style=color:#f92672>*</span> masks, <span style=color:#ae81ff>1</span>)
    <span style=color:#66d9ef>return</span> unary_scores
</code></pre></div><p><code>crf_unary_score</code>的计算方法是先将<code>inputs</code>拉平，然后计算<code>tag_index</code>的<code>flattened_tag_indices</code>，然后根据<code>flattened_tag_indices</code>取到<code>inputs</code>中的内容。</p><pre><code>inputs:
 tf.Tensor(
[[[0.3 0.7]
  [0.2 0.8]
  [0.4 0.6]
  [0.4 0.6]]], shape=(1, 4, 2), dtype=float32)
tag_indices:
 tf.Tensor([[1 0 1 1]], shape=(1, 4), dtype=int32)
offset: 
 tf.Tensor([[0]], shape=(1, 1), dtype=int32)
offset: 
 tf.Tensor([[0 2 4 6]], shape=(1, 4), dtype=int32)
flattened_tag_indices: 
 tf.Tensor([1 2 5 7], shape=(4,), dtype=int32)
unary_scores: 
 tf.Tensor([[0.7 0.2 0.6 0.6]], shape=(1, 4), dtype=float32)
masks: 
 tf.Tensor([[1. 1. 1. 0.]], shape=(1, 4), dtype=float32)
&lt;tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.5], dtype=float32)&gt;
</code></pre><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>crf_binary_score</span>(
    tag_indices: TensorLike, sequence_lengths: TensorLike, transition_params: TensorLike
) <span style=color:#f92672>-&gt;</span> tf<span style=color:#f92672>.</span>Tensor:
    <span style=color:#e6db74>&#34;&#34;&#34;Computes the binary scores of tag sequences.
</span><span style=color:#e6db74>    Args:
</span><span style=color:#e6db74>      tag_indices: A [batch_size, max_seq_len] matrix of tag indices.
</span><span style=color:#e6db74>      sequence_lengths: A [batch_size] vector of true sequence lengths.
</span><span style=color:#e6db74>      transition_params: A [num_tags, num_tags] matrix of binary potentials.
</span><span style=color:#e6db74>    Returns:
</span><span style=color:#e6db74>      binary_scores: A [batch_size] vector of binary scores.
</span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
    tag_indices <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>cast(tag_indices, dtype<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>int32)
    sequence_lengths <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>cast(sequence_lengths, dtype<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>int32)

    num_tags <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>shape(transition_params)[<span style=color:#ae81ff>0</span>]
    num_transitions <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>shape(tag_indices)[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>

    <span style=color:#75715e># Truncate by one on each side of the sequence to get the start and end</span>
    <span style=color:#75715e># indices of each transition.</span>
    start_tag_indices <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>slice(tag_indices, [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>], [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, num_transitions])
    end_tag_indices <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>slice(tag_indices, [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>], [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, num_transitions])

    <span style=color:#75715e># Encode the indices in a flattened representation.</span>
    flattened_transition_indices <span style=color:#f92672>=</span> start_tag_indices <span style=color:#f92672>*</span> num_tags <span style=color:#f92672>+</span> end_tag_indices
    flattened_transition_params <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>reshape(transition_params, [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])

    <span style=color:#75715e># Get the binary scores based on the flattened representation.</span>
    binary_scores <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>gather(flattened_transition_params, flattened_transition_indices)

    masks <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>sequence_mask(
        sequence_lengths, maxlen<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>shape(tag_indices)[<span style=color:#ae81ff>1</span>], dtype<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>float32
    )
    truncated_masks <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>slice(masks, [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>], [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])
    binary_scores <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>reduce_sum(binary_scores <span style=color:#f92672>*</span> truncated_masks, <span style=color:#ae81ff>1</span>)
    <span style=color:#66d9ef>return</span> binary_scores
</code></pre></div><p>与<code>crf_unary_score</code>类似，<code>crf_unary_score</code>是要在<code>inputs</code>这个二维矩阵中选值，而<code>crf_binary_score</code>要做的是要在同样是二维矩阵的<code>transition_params</code>中选值。<code>start_tag_indices * num_tags</code>计算的就是<code>offsets</code>，即横坐标。</p><h3 id=crf_log_norm计算><code>crf_log_norm</code>计算</h3><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>crf_log_norm</span>(
    inputs: TensorLike, sequence_lengths: TensorLike, transition_params: TensorLike
) <span style=color:#f92672>-&gt;</span> tf<span style=color:#f92672>.</span>Tensor:
    <span style=color:#e6db74>&#34;&#34;&#34;Computes the normalization for a CRF.
</span><span style=color:#e6db74>    Args:
</span><span style=color:#e6db74>      inputs: A [batch_size, max_seq_len, num_tags] tensor of unary potentials
</span><span style=color:#e6db74>          to use as input to the CRF layer.
</span><span style=color:#e6db74>      sequence_lengths: A [batch_size] vector of true sequence lengths.
</span><span style=color:#e6db74>      transition_params: A [num_tags, num_tags] transition matrix.
</span><span style=color:#e6db74>    Returns:
</span><span style=color:#e6db74>      log_norm: A [batch_size] vector of normalizers for a CRF.
</span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
    sequence_lengths <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>cast(sequence_lengths, dtype<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>int32)
    <span style=color:#75715e># Split up the first and rest of the inputs in preparation for the forward</span>
    <span style=color:#75715e># algorithm.</span>
    first_input <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>slice(inputs, [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>], [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])
    first_input <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>squeeze(first_input, [<span style=color:#ae81ff>1</span>])

    <span style=color:#75715e># If max_seq_len is 1, we skip the algorithm and simply reduce_logsumexp</span>
    <span style=color:#75715e># over the &#34;initial state&#34; (the unary potentials).</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_single_seq_fn</span>():
        log_norm <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>reduce_logsumexp(first_input, [<span style=color:#ae81ff>1</span>])
        <span style=color:#75715e># Mask `log_norm` of the sequences with length &lt;= zero.</span>
        log_norm <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>where(
            tf<span style=color:#f92672>.</span>less_equal(sequence_lengths, <span style=color:#ae81ff>0</span>), tf<span style=color:#f92672>.</span>zeros_like(log_norm), log_norm
        )
        <span style=color:#66d9ef>return</span> log_norm

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_multi_seq_fn</span>():
        <span style=color:#e6db74>&#34;&#34;&#34;Forward computation of alpha values.&#34;&#34;&#34;</span>
        rest_of_input <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>slice(inputs, [<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>], [<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])
        <span style=color:#75715e># Compute the alpha values in the forward algorithm in order to get the</span>
        <span style=color:#75715e># partition function.</span>

        alphas <span style=color:#f92672>=</span> crf_forward(
            rest_of_input, first_input, transition_params, sequence_lengths
        )
        log_norm <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>reduce_logsumexp(alphas, [<span style=color:#ae81ff>1</span>])
        <span style=color:#75715e># Mask `log_norm` of the sequences with length &lt;= zero.</span>
        log_norm <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>where(
            tf<span style=color:#f92672>.</span>less_equal(sequence_lengths, <span style=color:#ae81ff>0</span>), tf<span style=color:#f92672>.</span>zeros_like(log_norm), log_norm
        )
        <span style=color:#66d9ef>return</span> log_norm

    <span style=color:#66d9ef>return</span> tf<span style=color:#f92672>.</span>cond(tf<span style=color:#f92672>.</span>equal(tf<span style=color:#f92672>.</span>shape(inputs)[<span style=color:#ae81ff>1</span>], <span style=color:#ae81ff>1</span>), _single_seq_fn, _multi_seq_fn)
</code></pre></div><p>计算是当每个字拿出来当初始值，即第一次的<strong>previous</strong>。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>crf_forward</span>(
    inputs: TensorLike,
    state: TensorLike,
    transition_params: TensorLike,
    sequence_lengths: TensorLike,
) <span style=color:#f92672>-&gt;</span> tf<span style=color:#f92672>.</span>Tensor:
    <span style=color:#e6db74>&#34;&#34;&#34;Computes the alpha values in a linear-chain CRF.
</span><span style=color:#e6db74>    See http://www.cs.columbia.edu/~mcollins/fb.pdf for reference.
</span><span style=color:#e6db74>    Args:
</span><span style=color:#e6db74>      inputs: A [batch_size, num_tags] matrix of unary potentials.
</span><span style=color:#e6db74>      state: A [batch_size, num_tags] matrix containing the previous alpha
</span><span style=color:#e6db74>         values.
</span><span style=color:#e6db74>      transition_params: A [num_tags, num_tags] matrix of binary potentials.
</span><span style=color:#e6db74>          This matrix is expanded into a [1, num_tags, num_tags] in preparation
</span><span style=color:#e6db74>          for the broadcast summation occurring within the cell.
</span><span style=color:#e6db74>      sequence_lengths: A [batch_size] vector of true sequence lengths.
</span><span style=color:#e6db74>    Returns:
</span><span style=color:#e6db74>      new_alphas: A [batch_size, num_tags] matrix containing the
</span><span style=color:#e6db74>          new alpha values.
</span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
    sequence_lengths <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>cast(sequence_lengths, dtype<span style=color:#f92672>=</span>tf<span style=color:#f92672>.</span>int32)

    last_index <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>maximum(
        tf<span style=color:#f92672>.</span>constant(<span style=color:#ae81ff>0</span>, dtype<span style=color:#f92672>=</span>sequence_lengths<span style=color:#f92672>.</span>dtype), sequence_lengths <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>
    )
    inputs <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>transpose(inputs, [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>2</span>])
    transition_params <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>expand_dims(transition_params, <span style=color:#ae81ff>0</span>)

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_scan_fn</span>(_state, _inputs):
        _state <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>expand_dims(_state, <span style=color:#ae81ff>2</span>)
        transition_scores <span style=color:#f92672>=</span> _state <span style=color:#f92672>+</span> transition_params
        new_alphas <span style=color:#f92672>=</span> _inputs <span style=color:#f92672>+</span> tf<span style=color:#f92672>.</span>reduce_logsumexp(transition_scores, [<span style=color:#ae81ff>1</span>])
        <span style=color:#66d9ef>return</span> new_alphas

    all_alphas <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>transpose(tf<span style=color:#f92672>.</span>scan(_scan_fn, inputs, state), [<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>2</span>])
    <span style=color:#75715e># add first state for sequences of length 1</span>
    all_alphas <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>concat([tf<span style=color:#f92672>.</span>expand_dims(state, <span style=color:#ae81ff>1</span>), all_alphas], <span style=color:#ae81ff>1</span>)

    idxs <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>stack([tf<span style=color:#f92672>.</span>range(tf<span style=color:#f92672>.</span>shape(last_index)[<span style=color:#ae81ff>0</span>]), last_index], axis<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
    <span style=color:#66d9ef>return</span> tf<span style=color:#f92672>.</span>gather_nd(all_alphas, idxs)
</code></pre></div><p>这里要注意的是<code>tf.scan</code>负责遍历， <code>tf.reduce_logsumexp</code>表示<code>log(sum(exp(元素值))</code></p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/writinglite.com/tags/crf/ rel=tag>CRF</a></li><li class=tags__item><a class="tags__link btn" href=/writinglite.com/tags/tensorflow/ rel=tag>Tensorflow</a></li></ul></div></footer></article></main><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=writinglite.com/post/deep-learning/2020-10-16-deeplearning%E4%B8%ADcrf%E8%AE%A1%E7%AE%97%E5%8E%9F%E7%90%86/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>DeepLearning中CRF计算原理</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=writinglite.com/post/deep-learning/2019-09-14-bert%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>bert的基本使用</p></a></div></nav></div></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2021 Writing Lite.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/writinglite.com/js/menu.js></script><script src=/writinglite.com/js/custom.js></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script></body></html>