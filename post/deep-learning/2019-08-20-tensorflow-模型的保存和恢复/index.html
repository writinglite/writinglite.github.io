<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Tensorflow 模型的保存和恢复 - Writing Lite</title><script>(function(a,b){a[b]=a[b].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:title" content="Tensorflow 模型的保存和恢复"><meta property="og:description" content="tensorflow模型的保存和恢复方法基本上可以参考其官方文档： https://www.tensorflow.org/guide/saved_model?hl=zh-cn 本文讨论 自定义estimato保存恢复方法r 和 fine-tune 的参数恢复方法
自定义estimator的保存和恢复 run_config = tf.estimator.RunConfig(model_dir=args.output_dir, save_summary_steps=500, save_checkpoints_steps=500, session_config=session_config) estimator = tf.estimator.Estimator( model_fn, params=params, config=run_config) 在train时会根据参数自动读取和保存模型 如果checkpoint 中的状态与描述的模型不兼容，因此重新训练失败并出现以下错误：
... InvalidArgumentError (see above for traceback): tensor_name = dnn/hiddenlayer_1/bias/t_0/Adagrad; shape in shape_and_slice spec [10] does not match the shape stored in checkpoint: [20] fine-tune 参数恢复方法 tvars = tf.trainable_variables() (assignment_map, initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint) tf.train.init_from_checkpoint(init_checkpoint, assignment_map) graph = tf.get_default_graph() test_varibal = graph.get_tensor_by_name('bert/encoder/layer_9/output/dense/bias:0') with tf.Session() as sess: # 最后初始化变量 sess."><meta property="og:type" content="article"><meta property="og:url" content="/post/deep-learning/2019-08-20-tensorflow-%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E5%92%8C%E6%81%A2%E5%A4%8D/"><meta property="article:section" content="post"><meta property="article:published_time" content="2019-08-20T20:07:00+00:00"><meta property="article:modified_time" content="2019-08-20T20:07:00+00:00"><meta itemprop=name content="Tensorflow 模型的保存和恢复"><meta itemprop=description content="tensorflow模型的保存和恢复方法基本上可以参考其官方文档： https://www.tensorflow.org/guide/saved_model?hl=zh-cn 本文讨论 自定义estimato保存恢复方法r 和 fine-tune 的参数恢复方法
自定义estimator的保存和恢复 run_config = tf.estimator.RunConfig(model_dir=args.output_dir, save_summary_steps=500, save_checkpoints_steps=500, session_config=session_config) estimator = tf.estimator.Estimator( model_fn, params=params, config=run_config) 在train时会根据参数自动读取和保存模型 如果checkpoint 中的状态与描述的模型不兼容，因此重新训练失败并出现以下错误：
... InvalidArgumentError (see above for traceback): tensor_name = dnn/hiddenlayer_1/bias/t_0/Adagrad; shape in shape_and_slice spec [10] does not match the shape stored in checkpoint: [20] fine-tune 参数恢复方法 tvars = tf.trainable_variables() (assignment_map, initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint) tf.train.init_from_checkpoint(init_checkpoint, assignment_map) graph = tf.get_default_graph() test_varibal = graph.get_tensor_by_name('bert/encoder/layer_9/output/dense/bias:0') with tf.Session() as sess: # 最后初始化变量 sess."><meta itemprop=datePublished content="2019-08-20T20:07:00+00:00"><meta itemprop=dateModified content="2019-08-20T20:07:00+00:00"><meta itemprop=wordCount content="77"><meta itemprop=keywords content="深度学习,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Tensorflow 模型的保存和恢复"><meta name=twitter:description content="tensorflow模型的保存和恢复方法基本上可以参考其官方文档： https://www.tensorflow.org/guide/saved_model?hl=zh-cn 本文讨论 自定义estimato保存恢复方法r 和 fine-tune 的参数恢复方法
自定义estimator的保存和恢复 run_config = tf.estimator.RunConfig(model_dir=args.output_dir, save_summary_steps=500, save_checkpoints_steps=500, session_config=session_config) estimator = tf.estimator.Estimator( model_fn, params=params, config=run_config) 在train时会根据参数自动读取和保存模型 如果checkpoint 中的状态与描述的模型不兼容，因此重新训练失败并出现以下错误：
... InvalidArgumentError (see above for traceback): tensor_name = dnn/hiddenlayer_1/bias/t_0/Adagrad; shape in shape_and_slice spec [10] does not match the shape stored in checkpoint: [20] fine-tune 参数恢复方法 tvars = tf.trainable_variables() (assignment_map, initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint) tf.train.init_from_checkpoint(init_checkpoint, assignment_map) graph = tf.get_default_graph() test_varibal = graph.get_tensor_by_name('bert/encoder/layer_9/output/dense/bias:0') with tf.Session() as sess: # 最后初始化变量 sess."><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/custom.css><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=/ title="Writing Lite" rel=home><div class="logo__item logo__text"><div class=logo__title>Writing Lite</div><div class=logo__tagline>Just writing a lite blog</div></div></a></div><div class=divider></div></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>Tensorflow 模型的保存和恢复</h1><div class="post__meta meta"><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2.0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class=meta__text>hwyang</span></div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2019-08-20T20:07:00Z>2019-08-20</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=/categories/deep-learning/ rel=category>deep learning</a></span></div></div></header><div class="post__toc toc"><div class=toc__title>Page content</div><div class=toc__menu><nav id=TableOfContents><ul><li><ul><li></li></ul></li></ul></nav></div></div><div class="content post__content clearfix"><p>tensorflow模型的保存和恢复方法基本上可以参考其官方文档： <a href="https://www.tensorflow.org/guide/saved_model?hl=zh-cn">https://www.tensorflow.org/guide/saved_model?hl=zh-cn</a>
本文讨论 自定义estimato保存恢复方法r 和 fine-tune 的参数恢复方法</p><h4 id=自定义estimator的保存和恢复>自定义estimator的保存和恢复</h4><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>run_config <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>estimator<span style=color:#f92672>.</span>RunConfig(model_dir<span style=color:#f92672>=</span>args<span style=color:#f92672>.</span>output_dir, save_summary_steps<span style=color:#f92672>=</span><span style=color:#ae81ff>500</span>, save_checkpoints_steps<span style=color:#f92672>=</span><span style=color:#ae81ff>500</span>, session_config<span style=color:#f92672>=</span>session_config)
estimator <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>estimator<span style=color:#f92672>.</span>Estimator(
    model_fn,
    params<span style=color:#f92672>=</span>params,
    config<span style=color:#f92672>=</span>run_config)
</code></pre></div><p>在train时会根据参数自动读取和保存模型
如果checkpoint 中的状态与描述的模型不兼容，因此重新训练失败并出现以下错误：</p><pre><code>...
InvalidArgumentError (see above for traceback): tensor_name =
dnn/hiddenlayer_1/bias/t_0/Adagrad; shape in shape_and_slice spec [10]
does not match the shape stored in checkpoint: [20]
</code></pre><h4 id=fine-tune-参数恢复方法>fine-tune 参数恢复方法</h4><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>tvars <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>trainable_variables()
(assignment_map, initialized_variable_names) <span style=color:#f92672>=</span> modeling<span style=color:#f92672>.</span>get_assignment_map_from_checkpoint(tvars, init_checkpoint)
tf<span style=color:#f92672>.</span>train<span style=color:#f92672>.</span>init_from_checkpoint(init_checkpoint, assignment_map)
graph <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>get_default_graph()
test_varibal <span style=color:#f92672>=</span> graph<span style=color:#f92672>.</span>get_tensor_by_name(<span style=color:#e6db74>&#39;bert/encoder/layer_9/output/dense/bias:0&#39;</span>)
<span style=color:#66d9ef>with</span> tf<span style=color:#f92672>.</span>Session() <span style=color:#66d9ef>as</span> sess:
    <span style=color:#75715e># 最后初始化变量</span>
    sess<span style=color:#f92672>.</span>run(tf<span style=color:#f92672>.</span>global_variables_initializer())
    <span style=color:#66d9ef>print</span>(sess<span style=color:#f92672>.</span>run(test_varibal))
</code></pre></div><p>在session run tf.global_variables_initializer() 时 会将tf.train.init_from_checkpoint处理的参数进行恢复，这种方法应该只会恢复指定名称的参数，不强制要求模型结构一致。</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/ rel=tag>深度学习</a></li></ul></div></footer></article></main><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=/post/deep-learning/2019-08-18-auto-encoder/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>Auto-Encoder</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=/post/deep-learning/2019-08-29-tensorflow-dataset/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>Tensorflow dataset</p></a></div></nav></div></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2021 Writing Lite.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script><script src=/js/custom.js></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script></body></html>