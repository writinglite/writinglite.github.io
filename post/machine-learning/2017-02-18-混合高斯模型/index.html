<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>混合高斯模型 - Writing Lite</title><script>(function(a,b){a[b]=a[b].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:title" content="混合高斯模型"><meta property="og:description" content="混合高斯模型 假设z为隐变量，x,z存在如下关系。 $$ P(x^{(i)},z^{(i)}) = P(x^{(i)}|z^{(i)})P(z^{(i)}) $$ $$ z^{(i)} \sim Multinomial(\phi)$ \
\phi_j=P(z^{(i)}=j)>0 \
\sum_j\phi_j=1 \
(x^{(i)} \mid {z^{(i)}=j} ) \sim N(\mu_j ,\Sigma_j) $$ 这里的j的聚类的一个类别之一。
E-step: 对z的猜测 $$ \begin{aligned} w_j^{(i)} & := P(z^{(i)}_j \mid x^{(i)}=j;\phi,\mu_j,\Sigma_j) \
&= \frac{ P(x^{(i)} \mid z^{(i)}_j=j)P(z^{(i)}_j=j)}{\sum_l^n P(x^{(i)} \mid z^{(i)}_j=l)P(z^{(i)}_j=l)} \end{aligned} $$
其中，$P(z^{(i)}_j \mid x^{(i)}=j;\phi,\mu_j,\Sigma_j)$表示第i个样本生成z为类别j的概率。这里的n表示聚类总类别数。
M-step: 对参数的估计 $$ \phi_j:=\frac{1}{m} \sum_{i=1}^m w_j^{(i)} \
\mu_j:= \frac{\sum_{i=1}^m w_j^{(i)} x^{(i)} }{\sum_{i=1}^m w_j^{(i)}} \
\Sigma_j:=\frac{ \sum_{i=1}^m w_j^{(i)} (x^{(i)} - \mu_j) (x^{(i)} - \mu_j)^T }{\sum_{i=1}^n w_j^{(i)}} $$"><meta property="og:type" content="article"><meta property="og:url" content="writinglite.com/post/machine-learning/2017-02-18-%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/"><meta property="article:section" content="post"><meta itemprop=name content="混合高斯模型"><meta itemprop=description content="混合高斯模型 假设z为隐变量，x,z存在如下关系。 $$ P(x^{(i)},z^{(i)}) = P(x^{(i)}|z^{(i)})P(z^{(i)}) $$ $$ z^{(i)} \sim Multinomial(\phi)$ \
\phi_j=P(z^{(i)}=j)>0 \
\sum_j\phi_j=1 \
(x^{(i)} \mid {z^{(i)}=j} ) \sim N(\mu_j ,\Sigma_j) $$ 这里的j的聚类的一个类别之一。
E-step: 对z的猜测 $$ \begin{aligned} w_j^{(i)} & := P(z^{(i)}_j \mid x^{(i)}=j;\phi,\mu_j,\Sigma_j) \
&= \frac{ P(x^{(i)} \mid z^{(i)}_j=j)P(z^{(i)}_j=j)}{\sum_l^n P(x^{(i)} \mid z^{(i)}_j=l)P(z^{(i)}_j=l)} \end{aligned} $$
其中，$P(z^{(i)}_j \mid x^{(i)}=j;\phi,\mu_j,\Sigma_j)$表示第i个样本生成z为类别j的概率。这里的n表示聚类总类别数。
M-step: 对参数的估计 $$ \phi_j:=\frac{1}{m} \sum_{i=1}^m w_j^{(i)} \
\mu_j:= \frac{\sum_{i=1}^m w_j^{(i)} x^{(i)} }{\sum_{i=1}^m w_j^{(i)}} \
\Sigma_j:=\frac{ \sum_{i=1}^m w_j^{(i)} (x^{(i)} - \mu_j) (x^{(i)} - \mu_j)^T }{\sum_{i=1}^n w_j^{(i)}} $$"><meta itemprop=wordCount content="77"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="混合高斯模型"><meta name=twitter:description content="混合高斯模型 假设z为隐变量，x,z存在如下关系。 $$ P(x^{(i)},z^{(i)}) = P(x^{(i)}|z^{(i)})P(z^{(i)}) $$ $$ z^{(i)} \sim Multinomial(\phi)$ \
\phi_j=P(z^{(i)}=j)>0 \
\sum_j\phi_j=1 \
(x^{(i)} \mid {z^{(i)}=j} ) \sim N(\mu_j ,\Sigma_j) $$ 这里的j的聚类的一个类别之一。
E-step: 对z的猜测 $$ \begin{aligned} w_j^{(i)} & := P(z^{(i)}_j \mid x^{(i)}=j;\phi,\mu_j,\Sigma_j) \
&= \frac{ P(x^{(i)} \mid z^{(i)}_j=j)P(z^{(i)}_j=j)}{\sum_l^n P(x^{(i)} \mid z^{(i)}_j=l)P(z^{(i)}_j=l)} \end{aligned} $$
其中，$P(z^{(i)}_j \mid x^{(i)}=j;\phi,\mu_j,\Sigma_j)$表示第i个样本生成z为类别j的概率。这里的n表示聚类总类别数。
M-step: 对参数的估计 $$ \phi_j:=\frac{1}{m} \sum_{i=1}^m w_j^{(i)} \
\mu_j:= \frac{\sum_{i=1}^m w_j^{(i)} x^{(i)} }{\sum_{i=1}^m w_j^{(i)}} \
\Sigma_j:=\frac{ \sum_{i=1}^m w_j^{(i)} (x^{(i)} - \mu_j) (x^{(i)} - \mu_j)^T }{\sum_{i=1}^n w_j^{(i)}} $$"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/writinglite.com/css/style.css><link rel=stylesheet href=/writinglite.com/css/custom.css><link rel="shortcut icon" href=/writinglite.com/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=/writinglite.com title="Writing Lite" rel=home><div class="logo__item logo__text"><div class=logo__title>Writing Lite</div><div class=logo__tagline>Just writing a lite blog</div></div></a></div><div class=divider></div></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>混合高斯模型</h1><div class="post__meta meta"><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2.0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class=meta__text>hwyang</span></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=writinglite.com/categories/machine-learning/ rel=category>machine learning</a></span></div></div></header><div class="post__toc toc"><div class=toc__title>Page content</div><div class=toc__menu><nav id=TableOfContents><ul><li><a href=#混合高斯模型>混合高斯模型</a></li></ul></nav></div></div><div class="content post__content clearfix"><p><img src=./_image/%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF%E6%A8%A1%E5%9E%8B/%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF.bmp alt></p><h2 id=混合高斯模型>混合高斯模型</h2><p>假设z为隐变量，x,z存在如下关系。
$$
P(x^{(i)},z^{(i)}) = P(x^{(i)}|z^{(i)})P(z^{(i)})
$$
$$
z^{(i)} \sim Multinomial(\phi)$ \<br>\phi_j=P(z^{(i)}=j)>0 \<br>\sum_j\phi_j=1 \<br>(x^{(i)} \mid {z^{(i)}=j} ) \sim N(\mu_j ,\Sigma_j)
$$
这里的j的聚类的一个类别之一。</p><p>E-step:
对z的猜测
$$
\begin{aligned}
w_j^{(i)} & := P(z^{(i)}_j \mid x^{(i)}=j;\phi,\mu_j,\Sigma_j) \<br>&= \frac{ P(x^{(i)} \mid z^{(i)}_j=j)P(z^{(i)}_j=j)}{\sum_l^n P(x^{(i)} \mid z^{(i)}_j=l)P(z^{(i)}_j=l)}
\end{aligned}
$$</p><p>其中，$P(z^{(i)}_j \mid x^{(i)}=j;\phi,\mu_j,\Sigma_j)$表示第i个样本生成z为类别j的概率。这里的n表示聚类总类别数。</p><p>M-step:
对参数的估计
$$
\phi_j:=\frac{1}{m} \sum_{i=1}^m w_j^{(i)} \<br>\mu_j:= \frac{\sum_{i=1}^m w_j^{(i)} x^{(i)} }{\sum_{i=1}^m w_j^{(i)}} \<br>\Sigma_j:=\frac{ \sum_{i=1}^m w_j^{(i)} (x^{(i)} - \mu_j) (x^{(i)} - \mu_j)^T }{\sum_{i=1}^n w_j^{(i)}}
$$</p><p>与高斯差别分析不同的是，一般对于高斯差别分析会假设有共同的协方差矩阵，而这里认为不同的高斯分布有不同的协方差矩阵。另一点，$I{y^{(i)}=1}$改为了$\sum_{i=1}^m w_j^{(i)}$。</p></div></article></main><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=writinglite.com/post/machine-learning/2017-03-12-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E4%B8%8E%E9%AB%98%E6%96%AF%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>生成模型与高斯判别分析</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=writinglite.com/post/machine-learning/2017-03-12-%E6%B7%B7%E5%90%88%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>混合朴素贝叶斯模型</p></a></div></nav></div></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2021 Writing Lite.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/writinglite.com/js/menu.js></script><script src=/writinglite.com/js/custom.js></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script></body></html>