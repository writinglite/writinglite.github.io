<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>Posts - Writing Lite</title><script>(function(a,b){a[b]=a[b].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:title" content="Posts"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="/post.html"><meta itemprop=name content="Posts"><meta itemprop=description content><meta name=twitter:card content="summary"><meta name=twitter:title content="Posts"><meta name=twitter:description content><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel=stylesheet href=/css/custom.css><link rel=alternate type=application/rss+xml href=/post/index.xml title="Writing Lite"><link rel="shortcut icon" href=/favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=/ title="Writing Lite" rel=home><div class="logo__item logo__text"><div class=logo__title>Writing Lite</div><div class=logo__tagline>Just writing a lite blog</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=/archives/><span class=menu__text>archives</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class="main list" role=main><header class=main__header><h1 class=main__title>Posts</h1></header><article class="list__item post"><header class=list__header><h2 class="list__title post__title"><a href=/post/deep-learning/2019-08-20-tensorflow-%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E5%92%8C%E6%81%A2%E5%A4%8D.html rel=bookmark>Tensorflow 模型的保存和恢复</a></h2><div class="list__meta meta"><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2.0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class=meta__text>hwyang</span></div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2019-08-20T20:07:00Z>2019-08-20</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=/categories/deep-learning.html rel=category>deep learning</a></span></div></div></header><div class="content list__excerpt post__content clearfix">tensorflow模型的保存和恢复方法基本上可以参考其官方文档： https://www.tensorflow.org/guide/saved_model?hl=zh-cn 本文讨论 自定义estimato保存恢复方法r 和 fine-tune 的参数恢复方法
自定义estimator的保存和恢复 run_config = tf.estimator.RunConfig(model_dir=args.output_dir, save_summary_steps=500, save_checkpoints_steps=500, session_config=session_config) estimator = tf.estimator.Estimator( model_fn, params=params, config=run_config) 在train时会根据参数自动读取和保存模型 如果checkpoint 中的状态与描述的模型不兼容，因此重新训练失败并出现以下错误：
...
InvalidArgumentError (see above for traceback): tensor_name =
dnn/hiddenlayer_1/bias/t_0/Adagrad; shape in shape_and_slice spec [10]
does not match the shape stored in checkpoint: [20]
fine-tune 参数恢复方法 tvars = tf.trainable_variables() (assignment_map, initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint) tf.train.init_from_checkpoint(init_checkpoint, assignment_map) graph = tf.get_default_graph() test_varibal = graph.get_tensor_by_name('bert/encoder/layer_9/output/dense/bias:0') with tf.Session() as sess: # 最后初始化变量 sess.</div></article><article class="list__item post"><header class=list__header><h2 class="list__title post__title"><a href=/post/deep-learning/2019-08-18-auto-encoder.html rel=bookmark>Auto-Encoder</a></h2><div class="list__meta meta"><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2.0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class=meta__text>hwyang</span></div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2019-08-18T20:07:00Z>2019-08-18</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=/categories/deep-learning.html rel=category>deep learning</a></span></div></div></header><div class="content list__excerpt post__content clearfix">什么是auto-encoder ?
auto-encoder输入一个向量，目标是要让网络可以还原输入向量；从input layer 到bottle的过程叫encoder目的是给input降维，从bottle到output layer 的过程叫decoder目的是从input的低维向量表示还原回Input；bottle 是 compact（稠密，维度远低于input维度）的向量；
核心是思想是：如果低维的code 能够还原回input 那说明 code 能够很好的表示input向量（即稠密又没有丢失信息）；
decoder 的不同方式： 如下是一种让decoder （判断input 与 code 是否匹配）以二分类方式来评估 decoder 是否足够好</div></article><article class="list__item post"><header class=list__header><h2 class="list__title post__title"><a href=/post/java/2019-08-08-java%E5%B9%B6%E5%8F%91%E6%B5%8B%E8%AF%95cyclicbarrier%E4%B8%8Ecountdownlatch.html rel=bookmark>Java并发测试CyclicBarrier与CountDownLatch</a></h2><div class="list__meta meta"><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2.0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class=meta__text>hwyang</span></div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2019-08-08T21:57:00Z>2019-08-08</time></div></div></header><div class="content list__excerpt post__content clearfix">CountDownLatch 相关的api
//构造方法 public CountDownLatch(int count) //调用await()方法的线程会被挂起，它会等待直到count值为0才继续执行 public void await() throws InterruptedException { }; //和await()类似，只不过等待一定的时间后count值还没变为0的话就会继续执行 public boolean await(long timeout, TimeUnit unit) throws InterruptedException { }; //将count值减1 public void countDown() { }; 简单来说它的执行逻辑是：先初始化count，当执行countDown()时count会减1，当count为零时之前因为await()被挂起的线程都会被唤醒。
示例代码：
public static void main(String[] args) { int bash = 10; CountDownLatch countDownLatch = new CountDownLatch(1); for (int index = 0; index &lt; bash; index++) { new Thread(new Runnable() { @Override public void run() { try { countDownLatch.await(); } catch (InterruptedException e) { e.</div></article><article class="list__item post"><header class=list__header><h2 class="list__title post__title"><a href=/post/other/2019-07-27-%E6%A0%91%E8%8E%93%E6%B4%BE3b+-%E5%AE%89%E8%A3%85openwrt.html rel=bookmark>树莓派3b+安装openwrt 18.06.4</a></h2><div class="list__meta meta"><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2.0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class=meta__text>hwyang</span></div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2019-07-27T22:36:15Z>2019-07-27</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=/categories/other.html rel=category>other</a></span></div></div></header><div class="content list__excerpt post__content clearfix">本文的连接方式是，将树莓派连唯一的网口作为wan口连接到上级路由lan口上，然后通过树莓派无线来访问网络。
刷固件 目前openwrt官方Stable Release版本是18.06.4，但是对于树莓派3b+开发版是不支持无线wifi的（unsupported functions：Country Code setting, WiFi 2.4GHz WiFi 5GHz , WIP）官方树莓派网页 ；不过snapshot版本支持，因此咱们刷这个版本；
下载
(下载地址)[https://downloads.openwrt.org/snapshots/targets/brcm2708/bcm2710/ ] 点击 rpi-3-ext4-factory.img.gz 下载
格式化树莓派存储卡
将img文件写到树莓派存储卡中
设置树莓派网络 将树莓派连接电源，并将树莓派通过网线连接到电脑上 通过ssh连接树莓派（树莓派默认的ip是192.168.1.1） ssh root@192.168.1.1 修改树莓派的网络设置 vi /etc/config/network 此处有两处修改，一是将 config interface 'lan'下的option ifname 'eth0'注释掉，二是添加一个wan的interface，具体如下：
config interface 'lan' option type 'bridge' # option ifname 'eth0' option proto 'static' option ipaddr '192.168.1.1' option netmask '255.255.255.0' option ip6assign '60' config interface 'wan' option proto 'dhcp' option ifname 'eth0' option ipv6 'auto' 在将无线的配置修改掉</div></article><article class="list__item post"><header class=list__header><h2 class="list__title post__title"><a href=/post/deep-learning/2019-07-17-%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html rel=bookmark>深度神经网络</a></h2><div class="list__meta meta"><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2.0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class=meta__text>hwyang</span></div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2019-07-17T20:43:00Z>2019-07-17</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=/categories/deep-learning.html rel=category>deep learning</a></span></div></div></header><div class="content list__excerpt post__content clearfix">全连接神经网络 neroun的输出 用 $a_i^l$ 表示，l表示layer，i表示第i个neuron，同一层output用 vector $a^l$表示
两层网络之间的weit用$w_{ij}^l$表示l-1层的第i个neroun到l层的第j个neuron
$\sigma$ 表示激活函数
循环神经网络 基础网络架构 单层RNN $x^1、h^0、y^1、h^1$都是vector
多层RNN 双向RNN $f_1、f_2、f_3$没有强制规定可以自己设计
Native RNN LSTM c 的变化慢，可以记忆很久以前的数据
GRU 李宏毅
未完待续&mldr;</div></article><article class="list__item post"><header class=list__header><h2 class="list__title post__title"><a href=/post/other/2019-05-18-git-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html rel=bookmark>Git 常用命令</a></h2><div class="list__meta meta"><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2.0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class=meta__text>hwyang</span></div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2019-05-18T19:36:15Z>2019-05-18</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=/categories/other.html rel=category>other</a></span></div></div></header><div class="content list__excerpt post__content clearfix">1、删除文件
rm test.txt git rm test.txt git commit -m "remove test.txt" git push 2、git更换远程仓库Ur
git remote set-url origin [url] 3、把误删的文件恢复到最新版本：
git checkout -- test.txt 4、创建新分支：
git branch branchName 5、分支合并
# 切换到Master分支 git checkout master # 对Develop分支进行合并 git merge --no-ff develo 6、切换到新分支：
git checkout branchName 7、添加远程仓库
git remote add origin &lt;your_github_repo_url> 8、删除远程分支
git push origin :branchname 9、查找删除的文件
# 通过git log可查找到文件的commitid git checkout commit_id -- file_name 10、.git目录清理-删除git中的大文件
# 1.使用以下命令可以查看占用空间最多的五个文件： git rev-list --objects --all | grep "$(git verify-pack -v .</div></article><article class="list__item post"><header class=list__header><h2 class="list__title post__title"><a href=/post/other/2019-05-18-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html rel=bookmark>Linux 常用命令</a></h2><div class="list__meta meta"><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2.0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class=meta__text>hwyang</span></div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2019-05-18T19:36:15Z>2019-05-18</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=/categories/other.html rel=category>other</a></span></div></div></header><div class="content list__excerpt post__content clearfix">1、scp
scp -r /home/xxx/xxx.txt root@192.168.1.122:/home/xxx/xxx 2、 磁盘空间
du -h --max-depth=0 ./ du sh * 3、当前文件夹大小：
du -sm 4、查看文档多少行
cat **.txt | wc -l 5、解压
tar -xzvf .tar.gz 6、压缩
tar –czf jpg.tar.gz *.jpg 7、给file的属主增加执行权限
chmod u+x file 8、zip 解压
unzip mydata.zip -d mydatabak 9、zip 压缩：
zip -r xx.zip dir 10、进行压缩，但不要.git目录下的所有文件（包含data目录）
zip -r yasuo.zip * -x *.git* 11、查看 zip 文件列表
unzip -l xx.zip</div></article><article class="list__item post"><header class=list__header><h2 class="list__title post__title"><a href=/post/java/2019-04-18-java-nio.html rel=bookmark>Java NIO</a></h2><div class="list__meta meta"><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2.0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class=meta__text>hwyang</span></div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2019-04-18T13:03:00Z>2019-04-18</time></div></div></header><div class="content list__excerpt post__content clearfix">IO (input/output) 通常指数据在内部存储器和外部存储器或其他周边设备之间的输入和输出。 NIO 是 Non-blocking IO 的缩写，即非阻塞式 IO，是一种计算机处理输入和输出的一种方式。
原始 IO 处理方式是，当数据可读之前会一直等待并占用线程资源却不做任何事情，因此当需要处理多个 chanle时就需要启用多个线程；而 NIO 可以只用一个线程来处理多个 chanle ,因为 NIO当数据可读之前不会一直傻等，而是每隔一段时间就检查，那么对于多个 chanle 来说，他们中有一个是可读状态才使用 cpu执行；
JJava IO: A classic IO server design - one connection handled by one thread.
Java NIO: A single thread managing multiple connections
&ndash; 参考：
https://tech.meituan.com/2016/11/04/nio.html
https://segmentfault.com/a/1190000017040893
http://tutorials.jenkov.com/java-nio/nio-vs-io.html</div></article><article class="list__item post"><header class=list__header><h2 class="list__title post__title"><a href=/post/machine-learning/2019-04-14-gbdt%E7%90%86%E8%A7%A3.html rel=bookmark>GBDT 解理</a></h2><div class="list__meta meta"><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2.0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class=meta__text>hwyang</span></div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2019-04-14T09:03:00Z>2019-04-14</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=/categories/machine-learning.html rel=category>machine learning</a></span></div></div></header><div class="content list__excerpt post__content clearfix">GBDT 全称是 Gradient Boosting Decision Tree，我们从分别这几个词来理解 GBDT;
Boosting GBDT 整体框架属于Boosting算法。Boosting方法是一种常用的统计学习方法，应用广泛有效。分类问题中，它通过改变训练样本的权重，学习多个弱分类器，并将这些分类器进行线性组合，提高分类性能。这里只对Boosting 这做简单说明。
Decision Tree 在 GBDT中学习的弱分类器就是决策树，具体来说是回归树并不是分类树，这里也不展开说明。
Gradient GBDT中改变训练样本的权重的方式是Gradient，使用 GBDT 来做回归任务时，通过推导Gradient=残差
回归问题的GBDT的学习过程 通俗点来讲，GBDT 是由一排回归树组成的，每一颗决策树学习目标是拟合前一颗树的Gradient或残差。
初始化$f_0(x)=0$ 对$m = 1,2、、、M$ 计算残差 $$ r_{mi} = y_i-f_{m-1}(x), i=1,2、、、N $$ 拟合残差$r_{mi}$学习一棵回归树，得到$h_m(x)$ 更新$f_m(x) = f_{m-1} + h_m(x)$ 得到回归问题的提升树 参考：
https://blog.csdn.net/zpalyq110/article/details/79527653 https://blog.csdn.net/u012422446/article/details/51506392 https://blog.csdn.net/anshuai_aw1/article/details/83040541
机器学习算法GBDT的面试要点总结-上篇
GBDT算法整理 https://www.msra.cn/zh-cn/news/features/lightgbm-20170105</div></article><article class="list__item post"><header class=list__header><h2 class="list__title post__title"><a href=/post/reading/2018-10-04-%E4%B8%80%E5%B0%8F%E6%97%B6%E5%A4%96.html rel=bookmark>一小时外</a></h2><div class="list__meta meta"><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 12 16"><path d="M6 1c2.2.0 3.5 2 3.5 4.5C9.5 7 8.9 8.2 8 9c2.9.8 4 2.5 4 5v1H0v-1c0-2.5 1.1-4.2 4-5-.9-.8-1.5-2-1.5-3.5C2.5 3 3.8 1 6 1z"/></svg><span class=meta__text>hwyang</span></div><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class=meta__text datetime=2018-10-04T09:21:00Z>2018-10-04</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=/categories/reading.html rel=category>reading</a></span></div></div></header><div class="content list__excerpt post__content clearfix">「做事就可以有结果，不管做的是什么事，都一样。」
心理治疗的目标，并不是制造一种廉价的甚至虚幻的开心，恰恰相反，它应当致力于让来访者有更高的内省力，更强的自主感，更符合现实的自尊，更清晰地认识并处理自身情绪的能力，面对困境时更强的自我力量以及自我协调性，爱的能力，工作的能力，以及成熟依赖的能力——最终的目标，是进入一种她称之为「平和」的心境。而那也许是一个人毕生的追求。
我相信生命是美好的，我深信这种美好，即使我们身处严峻的时代。但同时我也深信，这美好是一种复杂而深沉的体验，它同时包含着开心和痛苦，包含着我所体验到的一切真实。它承载我，如同大地。如果这种承载带来愉悦，那自然值得享受，而如果这种承载带来痛苦，那自然也就值得深深的哀伤——握着它，体会它的痛感，而不是幻想它变成一种别的什么。
我们感到愤怒，往往是我们认为一件事不公平，打破了某种既定的规则，
一个半吊子，图样图森破，但是自信，敢讲，也许会被当面反驳，也许会被背后窃笑。 或者玩沉默，笑而不语，光听不评，别人摸不清水有多深，也可能会显得很怯懦。 ——无所谓哪种比哪种更好，两种形象各有人喜欢，也各有人反感。</div></article></main><div class=pagination><a class="pagination__item pagination__item--prev btn" href=/post/page/2.html>«</a>
<span class="pagination__item pagination__item--current">3/8</span>
<a class="pagination__item pagination__item--next btn" href=/post/page/4.html>»</a></div></div><aside class="sidebar sidebar--left"><div class="widget-search widget"><form class=widget-search__form role=search method=get action=https://google.com/search><label><input class=widget-search__field type=search placeholder=SEARCH… name=q aria-label=SEARCH…></label>
<input class=widget-search__submit type=submit value=Search>
<input type=hidden name=sitesearch value=/></form></div><div class="widget-recent widget"><h4 class=widget__title>Recent Posts</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=/post/nlp/2021-05-13-han-for-document-classification.html>HAN for Document Classification</a></li><li class=widget__item><a class=widget__link href=/post/other/2021-05-06-%E4%BD%BF%E7%94%A8github-actions%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2hugo%E5%88%B0github-pages.html>使用GitHub Actions自动部署hugo到GitHub Pages</a></li><li class=widget__item><a class=widget__link href=/post/deep-learning/2020-10-16-deeplearning%E4%B8%ADcrf%E7%9A%84tensorflow%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0.html>DeepLearning中CRF的Tensorflow代码实现</a></li><li class=widget__item><a class=widget__link href=/post/deep-learning/2020-10-16-deeplearning%E4%B8%ADcrf%E8%AE%A1%E7%AE%97%E5%8E%9F%E7%90%86.html>DeepLearning中CRF计算原理</a></li><li class=widget__item><a class=widget__link href=/post/tensorflow2.x-keras/tensorflow%E5%AE%9E%E6%88%984-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98_%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB.html>卷积神经网络实战_图片分类</a></li></ul></div></div><div class="widget-categories widget"><h4 class=widget__title>Categories</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=/categories/algorithm.html>algorithm</a></li><li class=widget__item><a class=widget__link href=/categories/deep-learning.html>deep learning</a></li><li class=widget__item><a class=widget__link href=/categories/machine-learning.html>machine learning</a></li><li class=widget__item><a class=widget__link href=/categories/mathematics.html>mathematics</a></li><li class=widget__item><a class=widget__link href=/categories/nlp.html>NLP</a></li><li class=widget__item><a class=widget__link href=/categories/other.html>other</a></li><li class=widget__item><a class=widget__link href=/categories/reading.html>reading</a></li><li class=widget__item><a class=widget__link href=/categories/tensorflow2.x-keras.html>Tensorflow2.x keras</a></li></ul></div></div><div class="widget-taglist widget"><h4 class=widget__title>Tags</h4><div class=widget__content><a class="widget-taglist__link widget__link btn" href=/tags/acme.html title=acme>acme</a>
<a class="widget-taglist__link widget__link btn" href=/tags/albert.html title=albert>albert</a>
<a class="widget-taglist__link widget__link btn" href=/tags/batch-normalization.html title="Batch Normalization">Batch Normalization</a>
<a class="widget-taglist__link widget__link btn" href=/tags/bert.html title=bert>bert</a>
<a class="widget-taglist__link widget__link btn" href=/tags/blog.html title=blog>blog</a>
<a class="widget-taglist__link widget__link btn" href=/tags/crf.html title=crf>crf</a>
<a class="widget-taglist__link widget__link btn" href=/tags/deep-learning.html title="Deep Learning">Deep Learning</a>
<a class="widget-taglist__link widget__link btn" href=/tags/git.html title=Git>Git</a>
<a class="widget-taglist__link widget__link btn" href=/tags/github-actions.html title="github actions">github actions</a>
<a class="widget-taglist__link widget__link btn" href=/tags/github-pages.html title="github pages">github pages</a>
<a class="widget-taglist__link widget__link btn" href=/tags/guice.html title=guice>guice</a>
<a class="widget-taglist__link widget__link btn" href=/tags/hexo.html title=hexo>hexo</a>
<a class="widget-taglist__link widget__link btn" href=/tags/hugo.html title=hugo>hugo</a>
<a class="widget-taglist__link widget__link btn" href=/tags/kaggle.html title=kaggle>kaggle</a>
<a class="widget-taglist__link widget__link btn" href=/tags/keras.html title=keras>keras</a>
<a class="widget-taglist__link widget__link btn" href=/tags/layer-normalization.html title="Layer Normalization">Layer Normalization</a>
<a class="widget-taglist__link widget__link btn" href=/tags/linux.html title=Linux>Linux</a>
<a class="widget-taglist__link widget__link btn" href=/tags/log.html title=log>log</a>
<a class="widget-taglist__link widget__link btn" href=/tags/logback.html title=logback>logback</a>
<a class="widget-taglist__link widget__link btn" href=/tags/nginx.html title=nginx>nginx</a>
<a class="widget-taglist__link widget__link btn" href=/tags/openwrt.html title=openwrt>openwrt</a>
<a class="widget-taglist__link widget__link btn" href=/tags/slf4j.html title=slf4j>slf4j</a>
<a class="widget-taglist__link widget__link btn" href=/tags/stanford-corenlp.html title="Stanford CoreNLP">Stanford CoreNLP</a>
<a class="widget-taglist__link widget__link btn" href=/tags/tensorflow.html title=Tensorflow>Tensorflow</a>
<a class="widget-taglist__link widget__link btn" href=/tags/tensorflow-hub.html title="tensorflow hub">tensorflow hub</a>
<a class="widget-taglist__link widget__link btn" href=/tags/tensorflow2.0.html title=tensorflow2.0>tensorflow2.0</a>
<a class="widget-taglist__link widget__link btn" href=/tags/tra.html title=tra>tra</a>
<a class="widget-taglist__link widget__link btn" href=/tags/transformers.html title=transformers>transformers</a>
<a class="widget-taglist__link widget__link btn" href=/tags/ubuntu.html title=ubuntu>ubuntu</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E5%88%86%E8%AF%8D.html title=分词>分词</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E5%93%88%E5%B8%8C.html title=哈希>哈希</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D.html title=字符串匹配>字符串匹配</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E5%B9%B6%E5%8F%91.html title=并发>并发</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E6%8E%92%E5%BA%8F.html title=排序>排序</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E6%95%A3%E5%88%97%E8%A1%A8.html title=散列表>散列表</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BE%8E.html title=数学之美>数学之美</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E6%97%A0%E7%9B%91%E7%9D%A3.html title=无监督>无监督</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.html title=机器学习>机器学习</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html title=深度学习>深度学习</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E7%86%B5.html title=熵>熵</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E7%AE%97%E6%B3%95.html title=算法>算法</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0.html title=统计学习>统计学习</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86.html title=自然语言处理>自然语言处理</a></div></div><div class="widget-social widget"><h4 class="widget-social__title widget__title">Social</h4><div class="widget-social__content widget__content"><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=GitHub rel="noopener noreferrer" href=https://github.com/writinglite target=_blank><svg class="widget-social__link-icon icon icon-github" width="24" height="24" viewBox="0 0 384 374"><path d="m192 0C85.9.0.0 85.8.0 191.7c0 84.7 55 156.6 131.3 181.9 9.6 1.8 13.1-4.2 13.1-9.2.0-4.6-.2-16.6-.3-32.6-53.4 11.6-64.7-25.7-64.7-25.7-8.7-22.1-21.3-28-21.3-28-17.4-11.9 1.3-11.6 1.3-11.6 19.3 1.4 29.4 19.8 29.4 19.8 17.1 29.3 44.9 20.8 55.9 15.9 1.7-12.4 6.7-20.8 12.2-25.6-42.6-4.8-87.5-21.3-87.5-94.8.0-20.9 7.5-38 19.8-51.4-2-4.9-8.6-24.3 1.9-50.7.0.0 16.1-5.2 52.8 19.7 15.3-4.2 31.7-6.4 48.1-6.5 16.3.1 32.7 2.2 48.1 6.5 36.7-24.8 52.8-19.7 52.8-19.7 10.5 26.4 3.9 45.9 1.9 50.7 12.3 13.4 19.7 30.5 19.7 51.4.0 73.7-44.9 89.9-87.7 94.6 6.9 5.9 13 17.6 13 35.5.0 25.6-.2 46.3-.2 52.6.0 5.1 3.5 11.1 13.2 9.2C329 348.2 384 276.4 384 191.7 384 85.8 298 0 192 0z"/></svg><span>GitHub</span></a></div><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Email href=mailto:yhw1813@126.com><svg class="widget-social__link-icon icon icon-mail" width="24" height="24" viewBox="0 0 416 288"><path d="m0 16v256 16h16 384 16v-16V16 0h-16H16 0zm347 16-139 92.5L69 32zM199 157.5l9 5.5 9-5.5L384 46v210H32V46z"/></svg><span>yhw1813@126.com</span></a></div></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2021 Writing Lite.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=/js/menu.js></script><script src=/js/custom.js></script></body></html>