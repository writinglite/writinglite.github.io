<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Writing Lite">
<meta property="og:url" content="http://example.com/page/4/index.html">
<meta property="og:site_name" content="Writing Lite">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="hwyoung">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Writing Lite</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Writing Lite</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/08/11/%E5%85%B6%E5%AE%83/2018--8-11-shadowsocks%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%AE%89%E8%A3%85/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/08/11/%E5%85%B6%E5%AE%83/2018--8-11-shadowsocks%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%AE%89%E8%A3%85/" class="post-title-link" itemprop="url">shadowsocks服务端服务安装</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-08-11 14:27:00" itemprop="dateCreated datePublished" datetime="2018-08-11T14:27:00+00:00">2018-08-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Shadowsocks服务端服务安装"><a href="#Shadowsocks服务端服务安装" class="headerlink" title="Shadowsocks服务端服务安装"></a>Shadowsocks服务端服务安装</h2><blockquote>
<p>环境：centos</p>
</blockquote>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>安装python pip环境</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install python-setuptools &amp;&amp; easy_install pip</span><br></pre></td></tr></table></figure>

<p>通过pip安装shadowsocks</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install shadowsocks</span><br></pre></td></tr></table></figure>



<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi /etc/shadowsocks.json</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;server&quot;</span>:<span class="string">&quot;0.0.0.0&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;local_address&quot;</span>: <span class="string">&quot;127.0.0.1&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;local_port&quot;</span>:<span class="number">1080</span>,</span><br><span class="line">  <span class="attr">&quot;server_port&quot;</span>:my_server_port,</span><br><span class="line">  <span class="attr">&quot;password&quot;</span>:<span class="string">&quot;my_password&quot;</span>,</span><br><span class="line">  <span class="attr">&quot;timeout&quot;</span>:<span class="number">300</span>,</span><br><span class="line">  <span class="attr">&quot;method&quot;</span>:<span class="string">&quot;aes-256-cfb&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="防火墙设置"><a href="#防火墙设置" class="headerlink" title="防火墙设置"></a>防火墙设置</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --permanent --add-port=my_server_port/tcp</span><br><span class="line">firewall-cmd --permanent --add-port=my_server_port/udp</span><br><span class="line">firewall-cmd --reload</span><br></pre></td></tr></table></figure>



<h3 id="服务启动"><a href="#服务启动" class="headerlink" title="服务启动"></a>服务启动</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssserver -c /etc/shadowsocks.json -d start</span><br></pre></td></tr></table></figure>






      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2018/06/19/%E8%AF%BB%E4%B9%A6/2018-06-19-%E6%96%9C%E6%9D%A0%E9%9D%92%E5%B9%B4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2018/06/19/%E8%AF%BB%E4%B9%A6/2018-06-19-%E6%96%9C%E6%9D%A0%E9%9D%92%E5%B9%B4/" class="post-title-link" itemprop="url">斜杠青年</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2018-06-19 16:21:00" itemprop="dateCreated datePublished" datetime="2018-06-19T16:21:00+00:00">2018-06-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>“斜杠青年”代表的是一种全新的人生价值观，它的核心不在于多重收，也不在于多重身份，而在于多元化的人生。</p>
<p>我绝对没有想要否定上班这种生活方式，毕竟朝九晚五的上班生活是现在的主流生活方式，但我们需要意识到，它既不是赚钱的唯一方式，也不是实现自我价值的唯一方式。</p>
<p>我们应该允许不一样的生活方式的存在，不去过分评判他人的人生选择，因为当我们把自己的价值观强加于他人时，我们也在限制自己，同时推动了本可以打拥有更多生活的可能性。</p>
<p>当你的才华还撑不起你的野心的时候，你就应该静下心来学习；当你的能力还驾驭不了你的目标时，就应该沉下心来历练。梦想，不是浮躁，而是沉淀和积累。</p>
<p>我们在工作中无法获得快乐最核心的原因之一，就在于我们被剥夺了独立自主的权利，因为根据美国心理学家德西和瑞安提出的自我决定理论，人类有自主、独立、寻求归属感的内在动机。</p>
<p>价格实际上是实现将源高配的一种重要手段，价格反应了商品供求关系的变化。</p>
<p>按照现代经济学理论，企业本质上只不过是一种将源配置机制，它能够按照一定的组织和管理方式实现整个社会经济资源的优化配置，降低整个社会的“交易成本”。尽管企业本身存在着管理成本，但只要管理成本低于交易成本，企业就有存在的价值。</p>
<p>一个人的收入不是和他的劳动时间成正比，而是和他的劳动的不可替代性成正比。</p>
<p>真正的自由不是“拥有”的自由而是“拒绝”的自由，当我们不再需要为了钱而去做自己不喜欢或者不愿意做的事情的时候，我们才获得了真正意义上的财务自由。</p>
<p>在以后的日子里，当我再次遇到恶意的贬低和攻击时，我也不再以愤怒、反驳或者对抗来回应，而是大大方方承认：我的确不够好，但我在进步。</p>
<p>内心和头脑的丰富让我越来越淡定和从容；自我认可让我不再在意别人对我的看法；而对自身价值和能力的肯定给了我足够的安全感。我不再害怕失去，因为我知道自己内在所拥有的是别人夺不走的，也不会因为外在的变化而有所增减。</p>
<p>所有能够快速获得或者能够用金钱换来的都无法成为核心竞争力。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/11/18/%E5%85%B6%E5%AE%83/2017-11-18-Git%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/11/18/%E5%85%B6%E5%AE%83/2017-11-18-Git%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/" class="post-title-link" itemprop="url">Git版本控制</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-11-18 10:11:00" itemprop="dateCreated datePublished" datetime="2017-11-18T10:11:00+00:00">2017-11-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>git是日常工作常用的开发工具，本篇文章将粗略讲解关于git的两部分内容，一是git中的基本概念这将有助于了解git命令的具体含义，二是日常工作中常用到的一些git命令和git的开发流程。</p>
<h2 id="Git中的基础概念"><a href="#Git中的基础概念" class="headerlink" title="Git中的基础概念"></a>Git中的基础概念</h2><p>git中比较重要的两个概念是空间和版本（commit），git中的命令都是对这两个概念的操作。了解了这两个概念，就可以感知到git中可以支持哪些操作，即使有些命令我们没有学过，也可以通过到搜索了解到。</p>
<h3 id="第一个概念：空间"><a href="#第一个概念：空间" class="headerlink" title="第一个概念：空间"></a>第一个概念：空间</h3><p>git中有三种空间</p>
<ul>
<li>工作区（Word Space）</li>
<li>储存库（Repo）</li>
<li>暂存区（Staged Area，Index）</li>
</ul>
<p>工作区就是git所在目录，就是文件系统中的一个普通目录。</p>
<p>暂存区指.git目录下的index文件，通过git add命令可以将工作区目录下的文件添加到暂存区中。同时它也有索引作用，它对应到储存库中的文件（索引理解的还不是很透彻可能有错误）。</p>
<p>储存库指工作区下的.git目录（应该是里面的某个目录），里面记录了各个版本的所有内容，只有commit的内容才是真正会保存到储存库中。</p>
<p><img src="_image/git_space.png" alt="git_space"></p>
<h3 id="第二个概念：版本（commit）"><a href="#第二个概念：版本（commit）" class="headerlink" title="第二个概念：版本（commit）"></a>第二个概念：版本（commit）</h3><p>我理解的版本就是每一次commit的内容。各个版本之间是一种增量并且依赖的关系，新的版本会依赖旧的版本。每一个版本都有一个key来唯一标识这个commit。</p>
<p>通过commit可以引出分支的概念，每个分支其实是其实就是指向了一个commit，HEAD指向的就是当前的commit。</p>
<p><img src="_image/git_commit.png" alt="git_space"></p>
<h2 id="Git日常开发"><a href="#Git日常开发" class="headerlink" title="Git日常开发"></a>Git日常开发</h2><p>git命令比较多，但日常开发中实际用到的比较小，下面会通过一些实际场景介绍一些常用的git命令。</p>
<h3 id="git配置"><a href="#git配置" class="headerlink" title="git配置"></a>git配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global user.name &quot;John Doe&quot;</span><br><span class="line">$ git config --global user.email johndoe@example.com</span><br></pre></td></tr></table></figure>

<p>git提交时会注明提交人的姓名和邮箱，当多个协同工作时以标名操作人。</p>
<h3 id="git初始化"><a href="#git初始化" class="headerlink" title="git初始化"></a>git初始化</h3><p>git的初始化分为两种场景，一是git库已经有了，要在这个git库基本上进行开发；另外一种是，我们先在本地进行的开发，然后想上传到服务器上。</p>
<p>第一种的话可以使用git clone命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git clone git:&#x2F;&#x2F;github.com&#x2F;schacon&#x2F;grit.git</span><br></pre></td></tr></table></figure>

<p>第二种话，要先添加远程git然后将自己的代码提交上去。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git remote add origin git@github.xxx.cn:xxx&#x2F;xxx.git</span><br><span class="line">$ git push -u origin master</span><br></pre></td></tr></table></figure>



<h3 id="程序开发"><a href="#程序开发" class="headerlink" title="程序开发"></a>程序开发</h3><p>git有不同的工作的流（gitflow），但共同的特点是，对于先功能的开发，要先新建分支开发完成后再merge回master分支。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ git branch &lt;branch name&gt;</span><br><span class="line">$ git checkout &lt;branch name&gt;</span><br><span class="line">...开发</span><br><span class="line">$ git checkout master</span><br><span class="line">$ git merge &lt;branch name&gt;</span><br></pre></td></tr></table></figure>



<h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>git的分支是一种指标，指向commit</p>
<p>head也是一种指标，指向当前工作区的分支</p>
<p>对于一个已跟踪的文件，当对该文件进行修改后，该文件的状态为modify，使用git add 可以将这次的modify内容添加到暂存区，如果再对该文件进行修改，并进行git commit，那么commit的只是git add时刻的内容，最新修改的内容将不会提交，这也是git add命令和暂存区的意义所在。</p>
<p><code>git diff</code> 不过是显示还没有暂存起来的改动，而不是这次工作和上次提交之间的差异。</p>
<p>git rm 可以不再跟踪文件，但存储库依然</p>
<p>每一个commit都是一个Key，代表了存储库中的一个版本，</p>
<p>更多好细节和命令可心参考<a target="_blank" rel="noopener" href="https://git-scm.com/book/zh/v1/%E8%B5%B7%E6%AD%A5">git book</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/09/09/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/2017-09-09-%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E8%AF%8D%E5%88%87%E5%88%86%E5%92%8C%E6%A0%87%E6%B3%A8%E4%B8%80%E4%BD%93%E5%8C%96%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/09/09/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/2017-09-09-%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E7%9A%84%E8%AF%8D%E5%88%87%E5%88%86%E5%92%8C%E6%A0%87%E6%B3%A8%E4%B8%80%E4%BD%93%E5%8C%96%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">基于统计的词切分和标注一体化模型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-09-09 16:18:00" itemprop="dateCreated datePublished" datetime="2017-09-09T16:18:00+00:00">2017-09-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="基于统计的切记和标注一体化模型"><a href="#基于统计的切记和标注一体化模型" class="headerlink" title="基于统计的切记和标注一体化模型"></a>基于统计的切记和标注一体化模型</h2><p>假设$C=c_1,c_2 \dots c_m$为m个的字符串，$W=w_1,_2 \dots w_n$是把C切分后得到的由n个词组成的词序列，$T=t_1,t_2 \dots t_n$是对W进行标注后的标记序列。</p>
<p>$$<br>P(W|C) = \frac{P(C|W)P(W)}{P(C)}<br>$$<br>可知P(C)是一个确定的值，P(C|W)是在给定词序列的情况下字符串的概率，可以认为是1。因此可得：<br>$$<br>\max P(W|C) =  \max P(W)<br>$$<br>即是说，分词的过程即是寻找概率最大词序列的过程。<br>我们再来考虑词序列与词序列与词性标注序列的关系。<br>$$<br>P(T|W) = \frac{P(W|T)P(T)}{P(W)}<br>$$<br>可推导出：<br>$$<br>P(W) = \frac{P(W|T)P(T)}{P(T|W)}<br>$$<br>如果隐马尔可夫假设和独立输出假设<br>即：<br>$$<br>P(T) = \prod_i^n P(t_i)P(t_{i-1}) \<br>P(W|T) = \prod_i^n P(|w_i,t_i) \<br>P(T|W) = \prod_i^n P(|t_i,w_i)<br>$$</p>
<p>计算方法：</p>
<ol>
<li>找到一条分词路径W</li>
<li>用记性标注的模型计算具有最大概率的记性标注序列，得到对应的标注路径T。</li>
<li>利用公式可得到W的概率</li>
<li>若干个健忘路径中，概率最大的W即为分词结果</li>
</ol>
<hr>
<p>引用：<br>白栓虎 - 基于统计的切记和标注一体化模型</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/09/08/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/2017-09-08-MMSeg%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/09/08/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/2017-09-08-MMSeg%E5%88%86%E8%AF%8D%E6%96%B9%E6%B3%95/" class="post-title-link" itemprop="url">MMSeg分词方法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-09-08 20:18:00" itemprop="dateCreated datePublished" datetime="2017-09-08T20:18:00+00:00">2017-09-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>陈和刘（1992）完成的最大匹配的另一个变体比基本形式更复杂。 这种演算法指出，最可能的分词方式是三个单词，方式为从一个字串的第一个字开始，寻找分词的方式，只要存在有不同意义的词。</p>
<h2 id="MMSeg的四个规则"><a href="#MMSeg的四个规则" class="headerlink" title="MMSeg的四个规则"></a>MMSeg的四个规则</h2><h3 id="规则-1：最大匹配-Maximum-matching"><a href="#规则-1：最大匹配-Maximum-matching" class="headerlink" title="规则 1：最大匹配(Maximum matching)"></a>规则 1：最大匹配(Maximum matching)</h3><p>Simple方法：取最大长度的单词。<br>Complex方法：匹配出所有的“三个词的词组”（原文中使用了chunk，这里感觉用“词组”比较合适），即从某一既定的字为起始位置，得到所有可能的“以三个词为一组”的所有组合。比如“研究生命起源”，可以得到</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">研_究_生</span><br><span class="line">研_究_生命</span><br><span class="line">研究生_命_起源</span><br><span class="line">研究_生命_起源</span><br></pre></td></tr></table></figure>

<h3 id="规则-2：最大平均单词长度-Largest-average-word-length"><a href="#规则-2：最大平均单词长度-Largest-average-word-length" class="headerlink" title="规则 2：最大平均单词长度(Largest average word length)"></a>规则 2：最大平均单词长度(Largest average word length)</h3><p>经过规则1过滤后，如果剩余的词组超过1个，那就选择平均词语长度最大的那个（平均词长＝词组总字数／词语数量）。比如“生活水平”，可能得到如下词组：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">生_活水_平 (4&#x2F;3&#x3D;1.33)</span><br><span class="line">生活_水_平 (4&#x2F;3&#x3D;1.33)</span><br><span class="line">生活_水平 (4&#x2F;2&#x3D;2)</span><br></pre></td></tr></table></figure>
<p>根据此规则，就可以确定选择“生活_水平”这个词组</p>
<h3 id="规则-3：单词长度的最小方差-Smallest-variance-of-word-lengths"><a href="#规则-3：单词长度的最小方差-Smallest-variance-of-word-lengths" class="headerlink" title="规则 3：单词长度的最小方差(Smallest variance of word lengths)"></a>规则 3：单词长度的最小方差(Smallest variance of word lengths)</h3><p>由于词语长度的变化率可以由标准差反映，所以此处直接套用标准差公式即可。比如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">研究_生命_起源 （标准差&#x3D;sqrt(((2-2)^2+(2-2)^2+(2-2^2))&#x2F;3)&#x3D;0）</span><br><span class="line">研究生_命_起源 （标准差&#x3D;sqrt(((2-3)^2+(2-1)^2+(2-2)^2)&#x2F;3)&#x3D;0.8165）</span><br></pre></td></tr></table></figure>
<p>于是选择“研究_生命_起源”这个词组。</p>
<h3 id="规则-4：单字单词的语素自由度的最大和-Largest-sum-of-degree-of-morphemic-freedom-of-one-character-words"><a href="#规则-4：单字单词的语素自由度的最大和-Largest-sum-of-degree-of-morphemic-freedom-of-one-character-words" class="headerlink" title="规则 4：单字单词的语素自由度的最大和(Largest sum of degree of morphemic freedom of one-character words)"></a>规则 4：单字单词的语素自由度的最大和(Largest sum of degree of morphemic freedom of one-character words)</h3><p>其中degree of morphemic freedom可以用一个数学公式表达：log(frequency)，即词频的自然对数（这里log表示数学中的ln）。这个规则的意思是“计算词组中的所有单字词词频的自然对数，然后将得到的值相加，取总和最大的词组”。比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">设施_和服_务</span><br><span class="line">设施_和_服务</span><br></pre></td></tr></table></figure>
<p>这两个词组中分别有“务”和“和”这两个单字词，假设“务”作为单字词时候的频率是5，“和”作为单字词时候的频率是10，对5和10取自然对数，然后取最大值者，所以取“和”字所在的词组，即“设施_和_服务”。<br>也许会问为什么要对“词频”取自然对数呢？可以这样理解，词组中单字词词频总和可能一样，但是实际的效果并不同，比如</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A_BBB_C （单字词词频，A:3， C:7）</span><br><span class="line">DD_E_F （单字词词频，E:5，F:5）</span><br></pre></td></tr></table></figure>
<p>表示两个词组，A、C、E、F表示不同的单字词，如果不取自然对数，单纯就词频来计算，那么这两个词组是一样的（3+7=5+5），但实际上不同的词频范围所表示的效果也不同，所以这里取自然对数，以表区分（ln(3)+ln(7) &lt; ln(5)+ln(5)， 3.0445&lt;3.2189）。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这个四个过滤规则中，如果使用simple的匹配方法，只能使用第一个规则过滤，如果使用complex的匹配方法，则四个规则都可以使用。实际使用中，一般都是使用complex的匹配方法＋四个规则过滤。<br>看到这里也许对MMSEG的分词方法有了一个大致的了解，它是一个“直观”的分词方法。<strong>它把一个句子“尽可能长（这里的长，是指所切分的词尽可能的长）”“尽可能均匀”的去切分</strong>，与中文的语法习惯比较相符。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/09/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2017-09-02-Logistic%E5%9B%9E%E5%BD%92%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%8E%A8%E5%AF%BC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/09/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2017-09-02-Logistic%E5%9B%9E%E5%BD%92%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%8E%A8%E5%AF%BC/" class="post-title-link" itemprop="url">Logistic回归梯度下降推导</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-09-02 20:34:00" itemprop="dateCreated datePublished" datetime="2017-09-02T20:34:00+00:00">2017-09-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Logistic回归梯度下降推导"><a href="#Logistic回归梯度下降推导" class="headerlink" title="Logistic回归梯度下降推导"></a>Logistic回归梯度下降推导</h2><p>$$<br>P(p=1|x;\theta) = h_\theta(x) = \frac{exp(\theta^Tx)}{1+exp(\theta^Tx)} \<br>P(p=0|x;\theta) = 1 - h_\theta(x) = \frac{1}{1+exp(\theta^Tx)}<br>$$</p>
<p>$$<br>\begin{align}<br>L(\theta) &amp; = L(\theta;X,\vec{y}) = p(\vec{y}|X;θ) \<br>&amp; =\prod_{i=1}^mp(y^{(i)}|x^{(i)};\theta) \<br>&amp; =\prod_{i=1}^m(h_\theta(x^{(i)}))^{y^{(i)}}(1-h_\theta(x^{(i)}))^{1-y^{(i)}}<br>\end{align}<br>$$</p>
<p>$$<br>\begin{align}<br>l(\theta) &amp; = \log L(\theta) \<br>&amp; = \sum_{i=1}^m \left[ y^{(i)}\log h(x^{(i)}) + (1-y^{(i)})\log (1-h(x^{(i)})) \right] \<br>&amp; = \sum_{i=1}^m \left[ y^{(i)}\log \frac{h(x^{(i)})}{1-h(x^{(i)})} + \log (1-h(x^{(i)})) \right] \<br>&amp; = \sum_{i=1}^m \left[ y^{(i)}\theta^Tx + \log (1-h(x^{(i)})) \right]<br>\end{align}<br>$$</p>
<p>$$<br>\frac{\partial}{\partial\theta_j}l(\theta) = \frac{\partial}{\partial\theta_j}y\theta^Tx + \frac{\partial}{\partial\theta_j}\log(1-h(x))<br>$$</p>
<p>$$<br>\frac{\partial}{\partial\theta_j}y\theta^Tx = yx_j<br>$$</p>
<p>$$<br>\begin{align}<br>\frac{\partial}{\partial\theta_j}\log(1-h(x)) &amp; = \frac{1}{1-h(x)}<em>\frac{\partial}{\partial\theta_j}(1-h(x)) \<br>&amp; = \frac{1}{1-h(x)}</em>(-1)\frac{\partial}{\partial\theta_j}h(x) \<br>&amp; = \frac{1}{1-h(x)}<em>(-1)\frac{\partial}{\partial\theta_j} \frac{g(\theta^Tx)}{1+g(\theta^Tx)} \<br>&amp; = \frac{1}{1-h(x)}</em>(-1)\frac{\partial}{\partial\theta_j} \frac{g(\theta^Tx)}{1+g(\theta^Tx)} \<br>\end{align}<br>$$</p>
<p>$$<br>\begin{align}<br>\frac{\partial}{\partial\theta_j}\log(1-h(x)) &amp; = \frac{\partial \log(1-h(x))}{\partial (1-h(x))} * \frac{\partial (1-h(x))}{\partial h(x)} * \frac{\partial h(x)}{\partial g(\theta^Tx)} * \frac{\partial g(\theta^Tx)}{\partial \theta^Tx} * \frac{\partial \theta^Tx}{\partial \theta_j} \<br> &amp; = \frac{1}{1-h(\theta(x))} * (-1) * \frac{1}{(1-g(\theta^Tx))^2} * g(\theta^Tx) * x_j \<br> &amp; = \frac{1}{1-h(\theta(x))} * (-1) * \frac{1}{1-g(\theta^Tx)} * \frac{g(\theta^Tx)}{1-g(\theta^Tx)} * x_j \<br> &amp; = \frac{1}{1-h(\theta^Tx)} * (-1) * (1-h(\theta^Tx) * h(\theta^Tx) * x_j \<br> &amp; = - h(\theta^Tx)x_j<br>\end{align}<br>$$</p>
<p>$$<br>\frac{\partial}{\partial\theta_j}l(\theta) =  yx_j - h(\theta^Tx)x_j = (y-h(\theta^Tx))x_j<br>$$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/07/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2017-07-19-%E5%86%B3%E7%AD%96%E6%A0%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/07/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2017-07-19-%E5%86%B3%E7%AD%96%E6%A0%91/" class="post-title-link" itemprop="url">决策树</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-07-20 21:00:00" itemprop="dateCreated datePublished" datetime="2017-07-20T21:00:00+00:00">2017-07-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>决策树的优点是计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。缺点是可能会产生过度匹配问题。适用于连续值和离散值数据。</p>
<h2 id="决策树生成"><a href="#决策树生成" class="headerlink" title="决策树生成"></a>决策树生成</h2><p>训练集$D={(x_1,y_1),(x_2,y_2),\dots,(x_m,y_m)}$<br>属性集$A={a_1,a_2,\dots,a_d}$</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def function treeGenerate(D,A):</span><br><span class="line">    生成结node;</span><br><span class="line">    if Dv为空:</span><br><span class="line">        将该分支结点标记为叶结点，其类别标记为D中样本最多的类;return;</span><br><span class="line">    if D中所有实例属于同一类:</span><br><span class="line">        将该分支结点标记为叶结点，将该类作为其类别标记;return;</span><br><span class="line">    a* &#x3D; 从A中选择最优划分属性;</span><br><span class="line">    for v in a*:</span><br><span class="line">        为node生成一个分支；</span><br><span class="line">        令Dv表示D中在a*上取值为v的样本子集；</span><br><span class="line">        以treeGenerate(Dv,A-a*)为分支结点</span><br></pre></td></tr></table></figure>

<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><p>特征选择在于选取对训练数据具有分类能力的特征。这样可以提高决策树学习的效率。如果利用一个特征进行分类的结果与随机分类的结果没有很大差别，则称这个特征是没有特征是没有分类能力的。</p>
<h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><p>信息增益也叫互信息。当获取的信息和要研究的事物“有关系”时，这些信息才能帮助我们消除不确定性。当然“有关系”这种说法太模糊，太不科学，最好能度化的度量“相关性”。<br>熵：<br>$H(X) = -\sum_i^nP(x_i)\log(P(x_i)$<br>条件熵：<br>$H(Y|X) = \sum_i^nP(x_i)H(Y|X=x_i)$<br>信息增益就是熵与条件熵的差值：<br>$$<br>Gain(D,a) = H(D) - H(D|a) = -\sum_i^{|Y|} P(Y_i) \log P(Y_i) - \sum_j^{|a|}P(a_j)H(D|a=a_j)  \<br>= H(D) - \sum_{v=1}^V \frac{|D^v|}{|D|}H(D^v)<br>$$</p>
<h3 id="信息增益比"><a href="#信息增益比" class="headerlink" title="信息增益比"></a>信息增益比</h3><p>信息增益作为划分训练数据的特征，存在偏向于选择取值较多的特征的问题。使用信息增益比可以对这一问题进行校正。<br>信息增益比：<br>$$<br>Gain_ratio(D,a) = \frac{Gain(D,a)}{H(a)} \<br>= \frac{H(D) - H(D|a)}{H(a)} \<br>=  \frac{Gain(D,a)}{-\sum_{v=1}^V  \frac{|D^v|}{|D|} \log \frac{|D^v|}{|D|}}<br>$$</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>除了信息增益与信息增益比，特征的选择还可以使用基尼指数；另外决策树生成的过程中，<strong>剪枝</strong>的操作也很重要，可以防止模型的过拟合；决策树了除了可以用于分类也适用于回归任务，当然方式也会有相应不同；</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/07/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2017-02-12-Logistic%E5%9B%9E%E5%BD%92/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/07/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2017-02-12-Logistic%E5%9B%9E%E5%BD%92/" class="post-title-link" itemprop="url">Logistic回归</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-07-19 21:41:00" itemprop="dateCreated datePublished" datetime="2017-07-19T21:41:00+00:00">2017-07-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>logistic回归是统计学习中经典的分类方法，在深度学习也有很多应用。本文主要介绍logistic回归，然后将其推广到多分类问题-softmax回归。</p>
<h2 id="什么是logistic"><a href="#什么是logistic" class="headerlink" title="什么是logistic"></a>什么是logistic</h2><p>虽然名称中有回归，其实logistic回归模型是一个经典二分类模型。logistic回归在线性回归的基础上，套用了一个逻辑函数，但也就由于这个逻辑函数。</p>
<p>logstic回归模型的特点，一个事件的几率是指该事件发生的概率与不发生的概率的比值，如果事件发生的概率是p，那么该事件的几率是$\frac{p}{1-p}$，该事件的对数几率为<br>$$<br>logit(p) = \log \frac{p}{1-p}<br>$$<br>对于logistic回归而言这个对数几率就是wx，也就是说线性函数的值越接近正无穷，概率值越接近1；线性函数的值越接近负无穷，概率值越接近0，这样的模型就是logistic回归模型。一句话概括的话，logistic回归模型实际上是在用线性回归模型的预测结果去逼近真实标记的对数几率。</p>
<p>$$<br>h(\theta) = g(\theta^Tx) = \frac{1}{1+e^{-\theta^Tx}}<br>$$<br>where<br>$$<br>g(z) = \frac{1}{1+e^{-z}}<br>$$</p>
<hr>
<p>$$<br>P(p=1|x;\theta) = h_\theta(x) \<br>P(p=0|x;\theta) = 1 - h_\theta(x)<br>$$</p>
<p>因此<br>$$<br>P(y|x;\theta) = (h_\theta(x))^y(1-h_\theta(x))^{1-y}<br>$$</p>
<p>所以似然函数为<br>$$<br>\begin{align}<br>L(\theta) &amp; = L(\theta;X,\vec{y}) = p(\vec{y}|X;θ) \\<br>&amp; =\prod_{i=1}^mp(y^{(i)}|x^{(i)};\theta) \\<br>&amp; =\prod_{i=1}^m(h_\theta(x^{(i)}))^{y^{(i)}}(1-h_\theta(x^{(i)}))^{1-y^{(i)}}<br>\end{align}<br>$$</p>
<p>对数似然函数<br>$$<br>\begin{align}<br>l(\theta) &amp; = \log L(\theta) \\<br>&amp; = \sum_{i=1}^my^{(i)}\log h(x^{(i)}) + (1-y^{(i)})\log (1-h(x^{(i)}))<br>\end{align}<br>$$</p>
<p>$l(\theta)$梯度：<br>$$<br>\begin{align}<br>\frac{\partial}{\partial\theta_j}l(\theta) &amp; = \left(y\frac{1}{g(\theta^T)}-(1-y)\frac{1}{1-g(\theta^T)}\right)\frac{\partial}{\partial\theta_j}g(\theta^Tx) \\<br>&amp; = \left(y\frac{1}{g(\theta^T)}-(1-y)\frac{1}{1-g(\theta^T)}\right)g(\theta^Tx)g(1-\theta^Tx)\frac{\partial}{\partial\theta_j}\theta^Tx \\<br>&amp; = (y(1-g(\theta^Tx))-(1-y)g(\theta^Tx))x_j \\<br>&amp; = (y-h_\theta(x))x_j<br>\end{align}<br>$$</p>
<p>对了求最大似然，使用梯度上升算法：<br>$$<br>\theta_j := \theta_j+ \alpha(y^i-h_\theta(x^i))x_j^i<br>$$</p>
<h2 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h2><p>对于类别数目为k的分类问题，softmax为<br>$$<br>h_{\theta}(x_{(i)}) = \begin{matrix}<br>p(y_{(i)}=1|x_{(i)};\theta) \<br>p(y_{(i)}=2|x_{(i)};\theta) \<br>\vdots \<br>p(y_{(i)}=k|x_{(i)};\theta)<br>  \end{matrix}<br>  =\frac{1}{\sum_{j=1}^ke^{\theta_j^Tx^{(i)}}}<br>\begin{matrix}<br>e^{\theta_1^Tx^{(i)}}\<br>e^{\theta_2^Tx^{(i)}}\<br>\vdots \<br>e^{\theta_3^Tx^{(i)}}\<br>\end{matrix}<br>$$<br>$\theta_1,\theta_2,\dots,\theta_k$都是模型参数,其中 $\frac{1}{\sum_{j=1}^ke^{\theta_j^Tx^{(i)}}}$是对概率分布做归一化。</p>
<p>softmax的似然函数为<br>$$<br>\begin{align}<br>L(\theta) &amp; = L(\theta;X,\vec{y}) = p(\vec{y}|X;θ) \\<br>&amp; =\prod_{i=1}^mp(y^{(i)}|x^{(i)};\theta) \\<br>&amp; =\prod_{i=1}^m\prod_{j=1}^k(\frac{e^{\theta_j^Tx^{(i)}}}{\sum_{j=1}^ke^{\theta_j^Tx^{(i)}}})^{I{y^{(i)}=j}}<br>\end{align}<br>$$<br>其中$I{y^{(i)}=j}$是指示函数，当表达式成立值为1否则为0。因此可以得到log似然函数</p>
<p>$$<br>\begin{align}<br>l(\theta) &amp; = \log L(\theta) \\<br>&amp; = \sum_{i=1}^m \sum_{j=1}^k I{y^{(i)}=j} \log p(y_{(i)}=j|x_{(i)};\theta)<br>\end{align}<br>$$<br>可以看到，Softmax代价函数与logistic 代价函数在形式上非常类似，只是在Softmax损失函数中对类标记的  k 个可能值进行了累加。</p>
<p>Softmax回归模型参数化的特点<br>oftmax 回归有一个不寻常的特点：它有一个“冗余”的参数集。直观上来解释，如果要进行k个分类，只需要k-1个参数即可，因为要做归一化，可以用1减其余的概率即可得到最后一个的概率，其实logistic回归就是这样做的。</p>
<p>Softmax回归与Logistic 回归的关系<br>将k设为2<br>$$<br>h_{\theta}(x_{(i)}) =\frac{1}{e^{\theta_1^Tx^{(i)}} + e^{\theta_2^Tx^{(i)}}}<br>\begin{matrix}<br>e^{\theta_1^Tx^{(i)}}\<br>e^{\theta_2^Tx^{(i)}}\<br>\end{matrix}<br>$$<br>利用softmax回归参数冗余的特点，从两个参数向量中都减去向量$\theta_1$，得到:</p>
<p>Softmax 回归 vs. k 个二元分类器<br>果你在开发一个音乐分类的应用，需要对k种类型的音乐进行识别，那么是选择使用 softmax 分类器呢，还是使用 logistic 回归算法建立 k 个独立的二元分类器呢？<br>这一选择取决于你的类别之间是否互斥，例如，如果你有四个类别的音乐，分别为：古典音乐、乡村音乐、摇滚乐和爵士乐，那么你可以假设每个训练样本只会被打上一个标签（即：一首歌只能属于这四种音乐类型的其中一种），此时你应该使用类别数 k = 4 的softmax回归。（如果在你的数据集中，有的歌曲不属于以上四类的其中任何一类，那么你可以添加一个“其他类”，并将类别数 k 设为5。）<br>如果你的四个类别如下：人声音乐、舞曲、影视原声、流行歌曲，那么这些类别之间并不是互斥的。例如：一首歌曲可以来源于影视原声，同时也包含人声 。这种情况下，使用4个二分类的 logistic 回归分类器更为合适。这样，对于每个新的音乐作品 ，我们的算法可以分别判断它是否属于各个类别。<br>现在我们来看一个计算视觉领域的例子，你的任务是将图像分到三个不同类别中。(i) 假设这三个类别分别是：室内场景、户外城区场景、户外荒野场景。你会使用sofmax回归还是 3个logistic 回归分类器呢？ (ii) 现在假设这三个类别分别是室内场景、黑白图片、包含人物的图片，你又会选择 softmax 回归还是多个 logistic 回归分类器呢？<br>在第一个例子中，三个类别是互斥的，因此更适于选择softmax回归分类器 。而在第二个例子中，建立三个独立的 logistic回归分类器更加合适。</p>
<hr>
<p><a target="_blank" rel="noopener" href="http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92">http://ufldl.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92</a><br>《统计学习方法》<br>《机器学习》周志华</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/07/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2017-07-15-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/07/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2017-07-15-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/" class="post-title-link" itemprop="url">集成学习简单介绍</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-07-15 14:32:00" itemprop="dateCreated datePublished" datetime="2017-07-15T14:32:00+00:00">2017-07-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>目前在kaggle中，GBDT和RF都是非常流行的算法，在一些比赛中，排名先前的算法都有这两种算法的身影。这两种算法都属于Ensemble算法，因此，本文将介绍介绍下Ensemble的思想，以及实现Ensemble的两种方法。</p>
<h2 id="什么是集成学习"><a href="#什么是集成学习" class="headerlink" title="什么是集成学习"></a>什么是集成学习</h2><p>Ensemble通过构建多个学习器来完成学习任务，直觉上来说，由于不再是单一的模型进行预测，所以模型有了“集思广益”的能力，也就不容易产生过拟合现象。但并不是说，随机进行组合就能得到好的效果，各个子模型应该“好而不同”，即个体学习器要有一定的“准确性”又要有“互补性”。</p>
<p>根据个体学习器的生成方式，目前的集成学习方法大致可分为两大类，即</p>
<ol>
<li>个体学习器间存在强依赖关系、必须串行生成的序列化算法。</li>
<li>个体学习器间不存在依赖关系、可同时生成的并行化算法。<br>前者的代表是Bossting，后者的代表是Bagging。从偏差-方差的角度看Bossting主要关注降低偏差，因此Bossting能基于泛化性能相当弱的学习器构建出很强的学习器，比如一棵只有5层的决策树。而Bagging主要关注降低方差，因此它在不剪枝层次较深的决策树、神经网络等易样本干扰的学习器上效用更加明显。</li>
</ol>
<p><strong>要获得好的集成，个体学习器应“好而不同”，即个体学习器要有一定的“准确性”，即学习器不能太坏，并且要有“多样性”，即学习器间具有差异。</strong></p>
<h2 id="Bostting"><a href="#Bostting" class="headerlink" title="Bostting"></a>Bostting</h2><p>Bostting是一族可将弱学习器提升为强学习器的算法，这族算法的工作机制类似：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多的关注，然后基于调整后的样本来训练下一个基学习器；如此重复进行，直至基学习器数目达到事先指定的值T，最终将这个T个基学习器进行加权结合。</p>
<h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><p>如上所述，一个可行的集成学习算法，要满足两个要点，一是“多样性”二是“准确性”。一个可行的做法是对训练样本进行采样，产生出若干个不同的子集，再从每个数据集中训练出一个学习器，这样就满足了“多样性”。然而，采样的每个子集都完全不同，则每个学习器只用到了一个小部分训练数据，甚至不足以进行有效学习，这显然无法确保产生出比较好的基学习器，为了解决这个问题可以采用自助采样法。</p>
<hr>
<p>《机器学习》 周志华<br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/29036379">https://www.zhihu.com/question/29036379</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2017/07/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2017-07-11-%E5%9C%A8kaggle%E4%B8%AD%E4%BD%BF%E7%94%A8keras%E5%81%9A%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2017/07/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2017-07-11-%E5%9C%A8kaggle%E4%B8%AD%E4%BD%BF%E7%94%A8keras%E5%81%9A%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/" class="post-title-link" itemprop="url">在kaggle中使用keras做数字识别</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-07-11 20:43:00" itemprop="dateCreated datePublished" datetime="2017-07-11T20:43:00+00:00">2017-07-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>本文将讲述通过keras写一个深度学习模型，来完成 kaggle 的 Digit Recognizer 准确率可达到98%。</p>
<h2 id="下载数据"><a href="#下载数据" class="headerlink" title="下载数据"></a>下载数据</h2><p>首先登入kaggle网站，点击competitions，在类型筛选中选择 Getting Started。然后点击Digit Recognizer。</p>
<p><img src="./_image/2017-07-11-21-30-31.jpg"><br>下载Data中的train.csv（模型的训练数据）和test.csv（测试数据）。<br><img src="./_image/2017-07-11-21-31-02.jpg"></p>
<h2 id="使用keras训练卷积神经网络模型"><a href="#使用keras训练卷积神经网络模型" class="headerlink" title="使用keras训练卷积神经网络模型"></a>使用keras训练卷积神经网络模型</h2><p>下面的代码分为三部分：</p>
<ol>
<li>读取数据</li>
<li>训练模型</li>
<li>预测测试数据</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout, Activation, Flatten</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">epochs = <span class="number">12</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read data</span></span><br><span class="line">train = pd.read_csv(<span class="string">&#x27;input/train.csv&#x27;</span>)</span><br><span class="line">y_train = train.ix[:,<span class="number">0</span>].values.astype(<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line">x_train = (train.ix[:,<span class="number">1</span>:].values).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">x_test = (pd.read_csv(<span class="string">&#x27;input/test.csv&#x27;</span>).values).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># input image dimensions</span></span><br><span class="line">img_rows, img_cols = <span class="number">28</span>, <span class="number">28</span></span><br><span class="line"></span><br><span class="line">x_train = x_train.reshape(x_train.shape[<span class="number">0</span>], img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line">x_test = x_test.reshape(x_test.shape[<span class="number">0</span>], img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line">input_shape = (img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x_train /= <span class="number">255</span></span><br><span class="line">x_test /= <span class="number">255</span></span><br><span class="line">print(<span class="string">&#x27;x_train shape:&#x27;</span>, x_train.shape)</span><br><span class="line">print(x_train.shape[<span class="number">0</span>], <span class="string">&#x27;train samples&#x27;</span>)</span><br><span class="line">print(x_test.shape[<span class="number">0</span>], <span class="string">&#x27;test samples&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># convert class vectors to binary class matrices</span></span><br><span class="line">y_train = keras.utils.to_categorical(y_train, num_classes)</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Conv2D(<span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                 activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                 input_shape=input_shape))</span><br><span class="line">model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(Dropout(<span class="number">0.25</span>))</span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(num_classes, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=keras.losses.categorical_crossentropy,</span><br><span class="line">              optimizer=keras.optimizers.Adadelta(),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          batch_size=batch_size,</span><br><span class="line">          epochs=epochs,</span><br><span class="line">          verbose=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">&quot;Generating test predictions...&quot;</span>)</span><br><span class="line">preds = model.predict_classes(x_test, verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_preds</span>(<span class="params">preds, fname</span>):</span></span><br><span class="line">    pd.DataFrame(&#123;<span class="string">&quot;ImageId&quot;</span>: <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(preds)+<span class="number">1</span>)), <span class="string">&quot;Label&quot;</span>: preds&#125;).to_csv(fname, index=<span class="literal">False</span>, header=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">write_preds(preds, <span class="string">&quot;keras-cnn.csv&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="提交数据"><a href="#提交数据" class="headerlink" title="提交数据"></a>提交数据</h2><p>将生成的keras-cnn.csv上传到kaggle中。</p>
<p><img src="./_image/2017-07-11-21-35-21.jpg"><br>最终可以看到我们的准确率：</p>
<p><img src="./_image/2017-07-11-21-35-57.jpg"><br>排名上中间左右</p>
<p><img src="./_image/2017-07-11-21-36-51.jpg"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="hwyoung"
      src="/avatar.png">
  <p class="site-author-name" itemprop="name">hwyoung</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">77</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">hwyoung</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
