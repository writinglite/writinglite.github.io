<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Writing Lite">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Writing Lite">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="hwyoung">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Writing Lite</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Writing Lite</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/10/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2020-10-16-DeepLearning%E4%B8%ADCRF%E7%9A%84Tensorflow%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2020-10-16-DeepLearning%E4%B8%ADCRF%E7%9A%84Tensorflow%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/" class="post-title-link" itemprop="url">DeepLearning中CRF的Tensorflow代码实现</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-10-16 21:07:00" itemprop="dateCreated datePublished" datetime="2020-10-16T21:07:00+00:00">2020-10-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="主方法"><a href="#主方法" class="headerlink" title="主方法"></a>主方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crf_log_likelihood</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">    inputs: TensorLike,</span></span></span><br><span class="line"><span class="function"><span class="params">    tag_indices: TensorLike,</span></span></span><br><span class="line"><span class="function"><span class="params">    sequence_lengths: TensorLike,</span></span></span><br><span class="line"><span class="function"><span class="params">    transition_params: Optional[TensorLike] = <span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params"></span>) -&gt; tf.Tensor:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Computes the log-likelihood of tag sequences in a CRF.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      inputs: A [batch_size, max_seq_len, num_tags] tensor of unary potentials</span></span><br><span class="line"><span class="string">          to use as input to the CRF layer.</span></span><br><span class="line"><span class="string">      tag_indices: A [batch_size, max_seq_len] matrix of tag indices for which</span></span><br><span class="line"><span class="string">          we compute the log-likelihood.</span></span><br><span class="line"><span class="string">      sequence_lengths: A [batch_size] vector of true sequence lengths.</span></span><br><span class="line"><span class="string">      transition_params: A [num_tags, num_tags] transition matrix,</span></span><br><span class="line"><span class="string">          if available.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      log_likelihood: A [batch_size] `Tensor` containing the log-likelihood of</span></span><br><span class="line"><span class="string">        each example, given the sequence of tag indices.</span></span><br><span class="line"><span class="string">      transition_params: A [num_tags, num_tags] transition matrix. This is</span></span><br><span class="line"><span class="string">          either provided by the caller or created in this function.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    num_tags = inputs.shape[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># cast type to handle different types</span></span><br><span class="line">    tag_indices = tf.cast(tag_indices, dtype=tf.int32)</span><br><span class="line">    sequence_lengths = tf.cast(sequence_lengths, dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> transition_params <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        initializer = tf.keras.initializers.GlorotUniform()</span><br><span class="line">        transition_params = tf.Variable(</span><br><span class="line">            initializer([num_tags, num_tags]), <span class="string">&quot;transitions&quot;</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    sequence_scores = crf_sequence_score(</span><br><span class="line">        inputs, tag_indices, sequence_lengths, transition_params</span><br><span class="line">    )</span><br><span class="line">    log_norm = crf_log_norm(inputs, sequence_lengths, transition_params)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Normalize the scores to get the log-likelihood per example.</span></span><br><span class="line">    log_likelihood = sequence_scores - log_norm</span><br><span class="line">    <span class="keyword">return</span> log_likelihood, transition_params</span><br></pre></td></tr></table></figure>



<p><code>log_likelihood = sequence_scores - log_norm</code> 中<code>sequence_scores </code>表示<strong>单路径分数</strong>，<code>log_norm</code> 表示<strong>所有路径总分数</strong>。在<code>-log_likelihood </code>才是我们想要最小化的值（损失函数）。</p>
<h3 id="sequence-scores-的计算："><a href="#sequence-scores-的计算：" class="headerlink" title="sequence_scores 的计算："></a><code>sequence_scores </code>的计算：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crf_sequence_score</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">    inputs: TensorLike,</span></span></span><br><span class="line"><span class="function"><span class="params">    tag_indices: TensorLike,</span></span></span><br><span class="line"><span class="function"><span class="params">    sequence_lengths: TensorLike,</span></span></span><br><span class="line"><span class="function"><span class="params">    transition_params: TensorLike,</span></span></span><br><span class="line"><span class="function"><span class="params"></span>) -&gt; tf.Tensor:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Computes the unnormalized score for a tag sequence.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      inputs: A [batch_size, max_seq_len, num_tags] tensor of unary potentials</span></span><br><span class="line"><span class="string">          to use as input to the CRF layer.</span></span><br><span class="line"><span class="string">      tag_indices: A [batch_size, max_seq_len] matrix of tag indices for which</span></span><br><span class="line"><span class="string">          we compute the unnormalized score.</span></span><br><span class="line"><span class="string">      sequence_lengths: A [batch_size] vector of true sequence lengths.</span></span><br><span class="line"><span class="string">      transition_params: A [num_tags, num_tags] transition matrix.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      sequence_scores: A [batch_size] vector of unnormalized sequence scores.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    tag_indices = tf.cast(tag_indices, dtype=tf.int32)</span><br><span class="line">    sequence_lengths = tf.cast(sequence_lengths, dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># If max_seq_len is 1, we skip the score calculation and simply gather the</span></span><br><span class="line">    <span class="comment"># unary potentials of the single tag.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_single_seq_fn</span>():</span></span><br><span class="line">        batch_size = tf.shape(inputs, out_type=tf.int32)[<span class="number">0</span>]</span><br><span class="line">        batch_inds = tf.reshape(tf.<span class="built_in">range</span>(batch_size), [-<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">        indices = tf.concat([batch_inds, tf.zeros_like(batch_inds)], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        tag_inds = tf.gather_nd(tag_indices, indices)</span><br><span class="line">        tag_inds = tf.reshape(tag_inds, [-<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">        indices = tf.concat([indices, tag_inds], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        sequence_scores = tf.gather_nd(inputs, indices)</span><br><span class="line"></span><br><span class="line">        sequence_scores = tf.where(</span><br><span class="line">            tf.less_equal(sequence_lengths, <span class="number">0</span>),</span><br><span class="line">            tf.zeros_like(sequence_scores),</span><br><span class="line">            sequence_scores,</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> sequence_scores</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_multi_seq_fn</span>():</span></span><br><span class="line">        <span class="comment"># Compute the scores of the given tag sequence.</span></span><br><span class="line">        unary_scores = crf_unary_score(tag_indices, sequence_lengths, inputs)</span><br><span class="line">        binary_scores = crf_binary_score(</span><br><span class="line">            tag_indices, sequence_lengths, transition_params</span><br><span class="line">        )</span><br><span class="line">        sequence_scores = unary_scores + binary_scores</span><br><span class="line">        <span class="keyword">return</span> sequence_scores</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.cond(tf.equal(tf.shape(inputs)[<span class="number">1</span>], <span class="number">1</span>), _single_seq_fn, _multi_seq_fn)</span><br></pre></td></tr></table></figure>



<p>如果<code>inputs</code>的lengths是1（即只一个字或词），则使用<code>_single_seq_fn</code>计算，否则使用<code>_multi_seq_fn</code>，这里主要看<code>_multi_seq_fn</code>。</p>
<p><code>_multi_seq_fn</code>是两个部分组成<code>unary_scores</code>和<code>binary_scores</code>。</p>
<p><code>unary_scores</code>：计算的是<strong>EmissionScore</strong></p>
<p><code>binary_scores</code>：计算的是<strong>TransitionScore</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crf_unary_score</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">    tag_indices: TensorLike, sequence_lengths: TensorLike, inputs: TensorLike</span></span></span><br><span class="line"><span class="function"><span class="params"></span>) -&gt; tf.Tensor:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Computes the unary scores of tag sequences.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      tag_indices: A [batch_size, max_seq_len] matrix of tag indices.</span></span><br><span class="line"><span class="string">      sequence_lengths: A [batch_size] vector of true sequence lengths.</span></span><br><span class="line"><span class="string">      inputs: A [batch_size, max_seq_len, num_tags] tensor of unary potentials.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      unary_scores: A [batch_size] vector of unary scores.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    tag_indices = tf.cast(tag_indices, dtype=tf.int32)</span><br><span class="line">    sequence_lengths = tf.cast(sequence_lengths, dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">    batch_size = tf.shape(inputs)[<span class="number">0</span>]</span><br><span class="line">    max_seq_len = tf.shape(inputs)[<span class="number">1</span>]</span><br><span class="line">    num_tags = tf.shape(inputs)[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    flattened_inputs = tf.reshape(inputs, [-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    offsets = tf.expand_dims(tf.<span class="built_in">range</span>(batch_size) * max_seq_len * num_tags, <span class="number">1</span>)</span><br><span class="line">    offsets += tf.expand_dims(tf.<span class="built_in">range</span>(max_seq_len) * num_tags, <span class="number">0</span>)</span><br><span class="line">    <span class="comment"># Use int32 or int64 based on tag_indices&#x27; dtype.</span></span><br><span class="line">    <span class="keyword">if</span> tag_indices.dtype == tf.int64:</span><br><span class="line">        offsets = tf.cast(offsets, tf.int64)</span><br><span class="line">    flattened_tag_indices = tf.reshape(offsets + tag_indices, [-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    unary_scores = tf.reshape(</span><br><span class="line">        tf.gather(flattened_inputs, flattened_tag_indices), [batch_size, max_seq_len]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    masks = tf.sequence_mask(</span><br><span class="line">        sequence_lengths, maxlen=tf.shape(tag_indices)[<span class="number">1</span>], dtype=tf.float32</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    unary_scores = tf.reduce_sum(unary_scores * masks, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> unary_scores</span><br></pre></td></tr></table></figure>

<p><code>crf_unary_score</code>的计算方法是先将<code>inputs</code>拉平，然后计算<code>tag_index</code>的<code>flattened_tag_indices</code>，然后根据<code>flattened_tag_indices</code>取到<code>inputs</code>中的内容。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">inputs:</span><br><span class="line"> tf.Tensor(</span><br><span class="line">[[[0.3 0.7]</span><br><span class="line">  [0.2 0.8]</span><br><span class="line">  [0.4 0.6]</span><br><span class="line">  [0.4 0.6]]], shape&#x3D;(1, 4, 2), dtype&#x3D;float32)</span><br><span class="line">tag_indices:</span><br><span class="line"> tf.Tensor([[1 0 1 1]], shape&#x3D;(1, 4), dtype&#x3D;int32)</span><br><span class="line">offset: </span><br><span class="line"> tf.Tensor([[0]], shape&#x3D;(1, 1), dtype&#x3D;int32)</span><br><span class="line">offset: </span><br><span class="line"> tf.Tensor([[0 2 4 6]], shape&#x3D;(1, 4), dtype&#x3D;int32)</span><br><span class="line">flattened_tag_indices: </span><br><span class="line"> tf.Tensor([1 2 5 7], shape&#x3D;(4,), dtype&#x3D;int32)</span><br><span class="line">unary_scores: </span><br><span class="line"> tf.Tensor([[0.7 0.2 0.6 0.6]], shape&#x3D;(1, 4), dtype&#x3D;float32)</span><br><span class="line">masks: </span><br><span class="line"> tf.Tensor([[1. 1. 1. 0.]], shape&#x3D;(1, 4), dtype&#x3D;float32)</span><br><span class="line">&lt;tf.Tensor: shape&#x3D;(1,), dtype&#x3D;float32, numpy&#x3D;array([1.5], dtype&#x3D;float32)&gt;</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crf_binary_score</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">    tag_indices: TensorLike, sequence_lengths: TensorLike, transition_params: TensorLike</span></span></span><br><span class="line"><span class="function"><span class="params"></span>) -&gt; tf.Tensor:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Computes the binary scores of tag sequences.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      tag_indices: A [batch_size, max_seq_len] matrix of tag indices.</span></span><br><span class="line"><span class="string">      sequence_lengths: A [batch_size] vector of true sequence lengths.</span></span><br><span class="line"><span class="string">      transition_params: A [num_tags, num_tags] matrix of binary potentials.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      binary_scores: A [batch_size] vector of binary scores.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    tag_indices = tf.cast(tag_indices, dtype=tf.int32)</span><br><span class="line">    sequence_lengths = tf.cast(sequence_lengths, dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">    num_tags = tf.shape(transition_params)[<span class="number">0</span>]</span><br><span class="line">    num_transitions = tf.shape(tag_indices)[<span class="number">1</span>] - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Truncate by one on each side of the sequence to get the start and end</span></span><br><span class="line">    <span class="comment"># indices of each transition.</span></span><br><span class="line">    start_tag_indices = tf.<span class="built_in">slice</span>(tag_indices, [<span class="number">0</span>, <span class="number">0</span>], [-<span class="number">1</span>, num_transitions])</span><br><span class="line">    end_tag_indices = tf.<span class="built_in">slice</span>(tag_indices, [<span class="number">0</span>, <span class="number">1</span>], [-<span class="number">1</span>, num_transitions])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Encode the indices in a flattened representation.</span></span><br><span class="line">    flattened_transition_indices = start_tag_indices * num_tags + end_tag_indices</span><br><span class="line">    flattened_transition_params = tf.reshape(transition_params, [-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get the binary scores based on the flattened representation.</span></span><br><span class="line">    binary_scores = tf.gather(flattened_transition_params, flattened_transition_indices)</span><br><span class="line"></span><br><span class="line">    masks = tf.sequence_mask(</span><br><span class="line">        sequence_lengths, maxlen=tf.shape(tag_indices)[<span class="number">1</span>], dtype=tf.float32</span><br><span class="line">    )</span><br><span class="line">    truncated_masks = tf.<span class="built_in">slice</span>(masks, [<span class="number">0</span>, <span class="number">1</span>], [-<span class="number">1</span>, -<span class="number">1</span>])</span><br><span class="line">    binary_scores = tf.reduce_sum(binary_scores * truncated_masks, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> binary_scores</span><br></pre></td></tr></table></figure>

<p>与<code>crf_unary_score</code>类似，<code>crf_unary_score</code>是要在<code>inputs</code>这个二维矩阵中选值，而<code>crf_binary_score</code>要做的是要在同样是二维矩阵的<code>transition_params</code>中选值。<code>start_tag_indices * num_tags</code>计算的就是<code>offsets</code>，即横坐标。</p>
<h3 id="crf-log-norm计算"><a href="#crf-log-norm计算" class="headerlink" title="crf_log_norm计算"></a><code>crf_log_norm</code>计算</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crf_log_norm</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">    inputs: TensorLike, sequence_lengths: TensorLike, transition_params: TensorLike</span></span></span><br><span class="line"><span class="function"><span class="params"></span>) -&gt; tf.Tensor:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Computes the normalization for a CRF.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      inputs: A [batch_size, max_seq_len, num_tags] tensor of unary potentials</span></span><br><span class="line"><span class="string">          to use as input to the CRF layer.</span></span><br><span class="line"><span class="string">      sequence_lengths: A [batch_size] vector of true sequence lengths.</span></span><br><span class="line"><span class="string">      transition_params: A [num_tags, num_tags] transition matrix.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      log_norm: A [batch_size] vector of normalizers for a CRF.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    sequence_lengths = tf.cast(sequence_lengths, dtype=tf.int32)</span><br><span class="line">    <span class="comment"># Split up the first and rest of the inputs in preparation for the forward</span></span><br><span class="line">    <span class="comment"># algorithm.</span></span><br><span class="line">    first_input = tf.<span class="built_in">slice</span>(inputs, [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [-<span class="number">1</span>, <span class="number">1</span>, -<span class="number">1</span>])</span><br><span class="line">    first_input = tf.squeeze(first_input, [<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># If max_seq_len is 1, we skip the algorithm and simply reduce_logsumexp</span></span><br><span class="line">    <span class="comment"># over the &quot;initial state&quot; (the unary potentials).</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_single_seq_fn</span>():</span></span><br><span class="line">        log_norm = tf.reduce_logsumexp(first_input, [<span class="number">1</span>])</span><br><span class="line">        <span class="comment"># Mask `log_norm` of the sequences with length &lt;= zero.</span></span><br><span class="line">        log_norm = tf.where(</span><br><span class="line">            tf.less_equal(sequence_lengths, <span class="number">0</span>), tf.zeros_like(log_norm), log_norm</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> log_norm</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_multi_seq_fn</span>():</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Forward computation of alpha values.&quot;&quot;&quot;</span></span><br><span class="line">        rest_of_input = tf.<span class="built_in">slice</span>(inputs, [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>], [-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>])</span><br><span class="line">        <span class="comment"># Compute the alpha values in the forward algorithm in order to get the</span></span><br><span class="line">        <span class="comment"># partition function.</span></span><br><span class="line"></span><br><span class="line">        alphas = crf_forward(</span><br><span class="line">            rest_of_input, first_input, transition_params, sequence_lengths</span><br><span class="line">        )</span><br><span class="line">        log_norm = tf.reduce_logsumexp(alphas, [<span class="number">1</span>])</span><br><span class="line">        <span class="comment"># Mask `log_norm` of the sequences with length &lt;= zero.</span></span><br><span class="line">        log_norm = tf.where(</span><br><span class="line">            tf.less_equal(sequence_lengths, <span class="number">0</span>), tf.zeros_like(log_norm), log_norm</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> log_norm</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.cond(tf.equal(tf.shape(inputs)[<span class="number">1</span>], <span class="number">1</span>), _single_seq_fn, _multi_seq_fn)</span><br></pre></td></tr></table></figure>



<p>计算是当每个字拿出来当初始值，即第一次的<strong>previous</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crf_forward</span>(<span class="params"></span></span></span><br><span class="line"><span class="function"><span class="params">    inputs: TensorLike,</span></span></span><br><span class="line"><span class="function"><span class="params">    state: TensorLike,</span></span></span><br><span class="line"><span class="function"><span class="params">    transition_params: TensorLike,</span></span></span><br><span class="line"><span class="function"><span class="params">    sequence_lengths: TensorLike,</span></span></span><br><span class="line"><span class="function"><span class="params"></span>) -&gt; tf.Tensor:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Computes the alpha values in a linear-chain CRF.</span></span><br><span class="line"><span class="string">    See http://www.cs.columbia.edu/~mcollins/fb.pdf for reference.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      inputs: A [batch_size, num_tags] matrix of unary potentials.</span></span><br><span class="line"><span class="string">      state: A [batch_size, num_tags] matrix containing the previous alpha</span></span><br><span class="line"><span class="string">         values.</span></span><br><span class="line"><span class="string">      transition_params: A [num_tags, num_tags] matrix of binary potentials.</span></span><br><span class="line"><span class="string">          This matrix is expanded into a [1, num_tags, num_tags] in preparation</span></span><br><span class="line"><span class="string">          for the broadcast summation occurring within the cell.</span></span><br><span class="line"><span class="string">      sequence_lengths: A [batch_size] vector of true sequence lengths.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      new_alphas: A [batch_size, num_tags] matrix containing the</span></span><br><span class="line"><span class="string">          new alpha values.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    sequence_lengths = tf.cast(sequence_lengths, dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">    last_index = tf.maximum(</span><br><span class="line">        tf.constant(<span class="number">0</span>, dtype=sequence_lengths.dtype), sequence_lengths - <span class="number">1</span></span><br><span class="line">    )</span><br><span class="line">    inputs = tf.transpose(inputs, [<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line">    transition_params = tf.expand_dims(transition_params, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_scan_fn</span>(<span class="params">_state, _inputs</span>):</span></span><br><span class="line">        _state = tf.expand_dims(_state, <span class="number">2</span>)</span><br><span class="line">        transition_scores = _state + transition_params</span><br><span class="line">        new_alphas = _inputs + tf.reduce_logsumexp(transition_scores, [<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">return</span> new_alphas</span><br><span class="line"></span><br><span class="line">    all_alphas = tf.transpose(tf.scan(_scan_fn, inputs, state), [<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line">    <span class="comment"># add first state for sequences of length 1</span></span><br><span class="line">    all_alphas = tf.concat([tf.expand_dims(state, <span class="number">1</span>), all_alphas], <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    idxs = tf.stack([tf.<span class="built_in">range</span>(tf.shape(last_index)[<span class="number">0</span>]), last_index], axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.gather_nd(all_alphas, idxs)</span><br></pre></td></tr></table></figure>



<p>这里要注意的是<code>tf.scan</code>负责遍历， <code>tf.reduce_logsumexp</code>表示<code>log(sum(exp(元素值))</code></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/10/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2020-10-16-DeepLearning%E4%B8%ADCRF%E8%AE%A1%E7%AE%97%E5%8E%9F%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2020-10-16-DeepLearning%E4%B8%ADCRF%E8%AE%A1%E7%AE%97%E5%8E%9F%E7%90%86/" class="post-title-link" itemprop="url">DeepLearning中CRF计算原理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-10-16 21:07:00" itemprop="dateCreated datePublished" datetime="2020-10-16T21:07:00+00:00">2020-10-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>主要内容来处：<a target="_blank" rel="noopener" href="https://createmomo.github.io/">https://createmomo.github.io</a>：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://createmomo.github.io/2017/09/12/CRF_Layer_on_the_Top_of_BiLSTM_1/">CRF Layer on the Top of BiLSTM - 1</a> Outline and Introduction</li>
<li><a target="_blank" rel="noopener" href="https://createmomo.github.io/2017/09/23/CRF_Layer_on_the_Top_of_BiLSTM_2/">CRF Layer on the Top of BiLSTM - 2</a> CRF Layer (Emission and Transition Score)</li>
<li><a target="_blank" rel="noopener" href="https://createmomo.github.io/2017/10/08/CRF-Layer-on-the-Top-of-BiLSTM-3/">CRF Layer on the Top of BiLSTM - 3</a> CRF Loss Function</li>
<li><a target="_blank" rel="noopener" href="https://createmomo.github.io/2017/10/17/CRF-Layer-on-the-Top-of-BiLSTM-4/">CRF Layer on the Top of BiLSTM - 4</a> Real Path Score</li>
<li><a target="_blank" rel="noopener" href="https://createmomo.github.io/2017/11/11/CRF-Layer-on-the-Top-of-BiLSTM-5/">CRF Layer on the Top of BiLSTM - 5</a> The Total Score of All the Paths</li>
<li><a target="_blank" rel="noopener" href="https://createmomo.github.io/2017/11/24/CRF-Layer-on-the-Top-of-BiLSTM-6/">CRF Layer on the Top of BiLSTM - 6</a> Infer the Labels for a New Sentence</li>
<li><a target="_blank" rel="noopener" href="https://createmomo.github.io/2017/12/06/CRF-Layer-on-the-Top-of-BiLSTM-7/">CRF Layer on the Top of BiLSTM - 7</a> Chainer Implementation Warm Up</li>
<li><a target="_blank" rel="noopener" href="https://createmomo.github.io/2017/12/07/CRF-Layer-on-the-Top-of-BiLSTM-8/">CRF Layer on the Top of BiLSTM - 8</a> Demo Code</li>
</ul>
<h3 id="CRF计算原理"><a href="#CRF计算原理" class="headerlink" title="CRF计算原理"></a>CRF计算原理</h3><p>CRF的计算分为三个部分，第一部分先介绍输入参数，第二部分说明在训练阶段如何计算-损失函数，第三部分是预测时的计算方式。</p>
<h4 id="输入参数"><a href="#输入参数" class="headerlink" title="输入参数"></a>输入参数</h4><p>CRF的输入参数有两个，一是<strong>发射分数</strong>，它可以是LSTM的输出结果，即每个word对应每个tag的得分。二是<strong>转移矩阵</strong>，它的内容是一个tag转移到下一个tag的权重。<br>假设我们有2个tag，和3个word，对应的发射分数和转移矩阵如下：<br>发射分数:<br>| word/tag | t0 | t1 |<br>| — | — | — |<br>| w0 | 0.3 | 0.7 |<br>| w1 | 0.6 | 0.4 |<br>| w2 | 0.2 | 0.8 |<br>例如$Emission_{w0, t0}$，表示为w0映射到t0的概率是0.3。</p>
<p>转移矩阵：<br>| tag-index | 0 | 1 |<br>| — | — | — |<br>| 0 | 0.6 | 0.4 |<br>| 1 | 0.1 | 0.9 |<br>例如$Transition_{t0, t0}$，t0转移到t0的概率是0.6。</p>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>$p_i$ 是每i条路径，则所有路径的得分是：<br>$$<br>P_{total} = P_1 + P_2 + … + P_N = e^{S_1} + e^{S_2} + … + e^{S_N}<br>$$<br>那么crf的损失函数如下：<br>$$<br>Loss Function = \frac{P_{RealPath}}{P_1 + P_2 + … + P_N}<br>$$<br>那么：<br>$$<br>LogLossFunction = \log \frac{P_{RealPath}}{P_1 + P_2 + … + P_N}<br>$$<br>因此要最小化：<br>$$<br>\begin{aligned}<br>LogLossFunction &amp;= -\log \frac{P_{RealPath}}{P_1 + P_2 + … + P_N} \<br>&amp;= - \log \frac{P_{RealPath}}{P_1 + P_2 + … + P_N} \<br>&amp;= - (\log(e^{S_{RealPath}}) - \log(e^{S_1} + e^{S_2} + … + e^{S_N})) \<br>&amp;= - (S_{RealPath} - \log(e^{S_1} + e^{S_2} + … + e^{S_N})) \<br>\end{aligned}<br>$$</p>
<p>即真实路径在所有路径中的概率最大。因此我们只有计算出$P_{RealPath}$和$P_{total}$这两部分，就可以进行训练了。</p>
<h5 id="单路径分数"><a href="#单路径分数" class="headerlink" title="单路径分数"></a>单路径分数</h5><p>$S_i$由两部分组成：<br>$$<br>S_i = EmissionScore + TransitionScore<br>$$</p>
<p>举例，计算 t0，t1，t0 这条路径的值：<br>$$<br>EmissionScore=Emission_{w0,t0}+Emission_{w1,t1}+Emission_{w2,t0}<br>$$<br>$$<br>TransitionScore=Transition_{to-&gt;t1} + Transition_{t1-&gt;t0}<br>$$</p>
<h5 id="所有路径总分数"><a href="#所有路径总分数" class="headerlink" title="所有路径总分数"></a>所有路径总分数</h5><p>计算所有路径总分数需要先定义2个变量：<br><strong>obs</strong>：obj表示当前的信息<br><strong>previous</strong>：previous表示上一步各个tag经过这个tag的所有路径的得分总各。<br>另外用<strong>transition</strong>表示转移矩阵<br>$w_0$-&gt;$w_1$<br>当前变量值 ：<br>$$<br>\begin{aligned}<br>obs = [x_{11}, x_{12}] \<br>previous = [x_{01}, x_{02}]<br>\end{aligned}<br>$$</p>
<p>$$<br>scores = previous + obj + transition<br>$$</p>
<p>$$<br>scores =<br>\begin{pmatrix}<br>x_{01}&amp;x_{01}\<br>x_{02}&amp;x_{02}<br>\end{pmatrix} +<br>\begin{pmatrix}<br>x_{11}&amp;x_{12}\<br>x_{11}&amp;x_{12}<br>\end{pmatrix} +<br>\begin{pmatrix}<br>t_{11}&amp;t_{12}\<br>t_{21}&amp;t_{22}<br>\end{pmatrix}<br>$$</p>
<p>$$<br>previous=[\log (e^{x_{01}+x_{11}+t_{11}} + e^{x_{02}+x_{11}+t_{21}}), \log (e^{x_{01}+x_{12}+t_{12}} + e^{x_{02}+x_{12}+t_{22}})]<br>$$</p>
<h4 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h4><p>$$<br>scores =<br>\begin{pmatrix}</p>
<p>x_{01}+x_{11}+t_{11}&amp;x_{01}+x_{12}+t_{12}\<br>x_{02}+x_{11}+t_{21}&amp;x_{02}+x_{12}+t_{22}</p>
<p>\end{pmatrix}<br>$$</p>
<p>$$<br>previous=[\max (scores[00], scores[10]),\max (scores[01],scores[11])]<br>$$</p>
<p>$$<br>scores =<br>\begin{pmatrix}</p>
<p>x_{01}+x_{11}+t_{11}&amp;x_{01}+x_{12}+t_{12}\<br>x_{02}+x_{11}+t_{21}&amp;x_{02}+x_{12}+t_{22}</p>
<p>\end{pmatrix}=<br>\begin{pmatrix}<br>0.2&amp;0.3\<br>0.5&amp;0.4<br>\end{pmatrix}<br>$$</p>
<p>$$<br>previous=[\max (scores[00], scores[10]),\max (scores[01],scores[11])] = [0.5, 0.4]<br>$$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/10/13/Tensorflow2.x%E5%AE%9E%E6%88%98/Tensorflow%E5%AE%9E%E6%88%98(4)-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98_%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/10/13/Tensorflow2.x%E5%AE%9E%E6%88%98/Tensorflow%E5%AE%9E%E6%88%98(4)-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98_%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB/" class="post-title-link" itemprop="url">卷积神经网络实战_图片分类</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-10-13 20:43:00" itemprop="dateCreated datePublished" datetime="2020-10-13T20:43:00+00:00">2020-10-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="理论部分"><a href="#理论部分" class="headerlink" title="理论部分"></a>理论部分</h2><h3 id="CNN解决的问题"><a href="#CNN解决的问题" class="headerlink" title="CNN解决的问题"></a>CNN解决的问题</h3><p>在CNN出现之前，图像对于人工智能来说是一个难题，有2个原因：</p>
<ol>
<li>图像需要处理的数据量太大，导致成本很高，效率很低。</li>
<li>图像在数字化的过程中很难保留原有的特征，导致图像处理的准确率不高。</li>
</ol>
<p>另一个角度（用全连接神经网络处理大尺寸图像的缺点）：</p>
<ol>
<li>其次参数过多效率低下，训练困难，同时大量的参数也很快会导致网络过拟合</li>
<li>图像展开为向量会丢失空间信息；</li>
</ol>
<h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p><img src="_image/juanji.gif"></p>
<p>这个过程我们可以理解为我们使用一个过滤器（卷积核）来过滤图像的各个小区域，从而得到这些小区域的特征值。</p>
<p>在具体应用中，往往有多个卷积核，可以认为，每个卷积核代表了一种图像模式，如果某个图像块与此卷积核卷积出的值大，则认为此图像块十分接近于此卷积核。如果我们设计了6个卷积核，可以理解：我们认为这个图像上有6种底层纹理模式，也就是我们用6中基础模式就能描绘出一副图像。以下就是25种不同的卷积核的示例：</p>
<p><img src="_image/150926.jpg"></p>
<h3 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h3><p>池化层简单说就是下采样，他可以大大降低数据的维度，也可以缓解卷积层对位置的过度敏感性。其过程如下：</p>
<p><img src="_image/chihua.gif"></p>
<p>上图中，我们可以看到，原始图片是20×20的，我们对其进行下采样，采样窗口为10×10，最终将其下采样成为一个2×2大小的特征图。</p>
<p>之所以这么做的原因，是因为即使做完了卷积，图像仍然很大（因为卷积核比较小），所以为了降低数据维度，就进行下采样。</p>
<p>总结：池化层相比卷积层可以更有效的降低数据维度，这么做不但可以大大减少运算量，还可以有效的避免过拟合。</p>
<h2 id="实战部分"><a href="#实战部分" class="headerlink" title="实战部分"></a>实战部分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> PIL</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卷积层</span></span><br><span class="line">x = tf.constant(<span class="built_in">range</span>(<span class="number">9</span>), dtype=tf.float32)</span><br><span class="line">x = tf.reshape(x, shape=(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">print(<span class="string">&#x27;x :&#x27;</span>, tf.reshape(x, shape=(<span class="number">3</span>, <span class="number">3</span>)))</span><br><span class="line">conv_layer = tf.keras.layers.Conv2D(filters=<span class="number">1</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), kernel_initializer=tf.keras.initializers.Ones())</span><br><span class="line">conv_ret = conv_layer(x)</span><br><span class="line">print(<span class="string">&#x27;shape :&#x27;</span>, conv_ret.shape)</span><br><span class="line">print(<span class="string">&#x27;conv ret :&#x27;</span>, tf.reshape(conv_ret, shape=(conv_ret.shape[<span class="number">1</span>], conv_ret.shape[<span class="number">2</span>])))</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;kernel size :&#x27;</span>, conv_layer.weights[<span class="number">0</span>].shape)</span><br></pre></td></tr></table></figure>

<pre><code>x : tf.Tensor(
[[0. 1. 2.]
 [3. 4. 5.]
 [6. 7. 8.]], shape=(3, 3), dtype=float32)
shape : (1, 2, 2, 1)
conv ret : tf.Tensor(
[[ 8. 12.]
 [20. 24.]], shape=(2, 2), dtype=float32)
kernel size : (2, 2, 1, 1)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多输入层-卷积层</span></span><br><span class="line">x = tf.constant(<span class="built_in">range</span>(<span class="number">18</span>), dtype=tf.float32)</span><br><span class="line">x = tf.reshape(x, shape=(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>))</span><br><span class="line">print(<span class="string">&#x27;x(channel-1) :&#x27;</span>, tf.reshape(x[:, :, :, <span class="number">0</span>], shape=(<span class="number">3</span>, <span class="number">3</span>)))</span><br><span class="line">print(<span class="string">&#x27;x(channel-2) :&#x27;</span>, tf.reshape(x[:, :, :, <span class="number">1</span>], shape=(<span class="number">3</span>, <span class="number">3</span>)))</span><br><span class="line"></span><br><span class="line">conv_layer = tf.keras.layers.Conv2D(<span class="number">1</span>, kernel_size=(<span class="number">2</span>, <span class="number">2</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), kernel_initializer=tf.keras.initializers.Ones())</span><br><span class="line">conv_ret = conv_layer(x)</span><br><span class="line">print(<span class="string">&#x27;shape :&#x27;</span>, conv_ret.shape)</span><br><span class="line">print(<span class="string">&#x27;conv ret :&#x27;</span>, tf.reshape(conv_ret, shape=(conv_ret.shape[<span class="number">1</span>], conv_ret.shape[<span class="number">2</span>])))</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;kernel size :&#x27;</span>, conv_layer.weights[<span class="number">0</span>].shape)</span><br></pre></td></tr></table></figure>

<pre><code>x(channel-1) : tf.Tensor(
[[ 0.  2.  4.]
 [ 6.  8. 10.]
 [12. 14. 16.]], shape=(3, 3), dtype=float32)
x(channel-2) : tf.Tensor(
[[ 1.  3.  5.]
 [ 7.  9. 11.]
 [13. 15. 17.]], shape=(3, 3), dtype=float32)
shape : (1, 2, 2, 1)
conv ret : tf.Tensor(
[[ 36.  52.]
 [ 84. 100.]], shape=(2, 2), dtype=float32)
kernel size : (2, 2, 2, 1)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 池化层</span></span><br><span class="line">x = tf.constant(<span class="built_in">range</span>(<span class="number">9</span>), dtype=tf.float32)</span><br><span class="line">x = tf.reshape(x, shape=(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">print(<span class="string">&#x27;x :&#x27;</span>,tf.reshape(x, shape=(<span class="number">3</span>, <span class="number">3</span>)))</span><br><span class="line"></span><br><span class="line">pool_ret = tf.keras.layers.MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=(<span class="number">1</span>, <span class="number">1</span>))(x)</span><br><span class="line">print(<span class="string">&#x27;pooling ret: &#x27;</span>, tf.reshape(pool_ret, shape=(conv_ret.shape[<span class="number">1</span>], conv_ret.shape[<span class="number">2</span>])))</span><br></pre></td></tr></table></figure>

<pre><code>x : tf.Tensor(
[[0. 1. 2.]
 [3. 4. 5.]
 [6. 7. 8.]], shape=(3, 3), dtype=float32)
pooling ret:  tf.Tensor(
[[4. 5.]
 [7. 8.]], shape=(2, 2), dtype=float32)</code></pre>
<h3 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h3><p>LeNet 诞生于 1994 年，是最早的卷积神经网络之一，LeNet分为卷积层块和全连接层块两个部分。</p>
<p>卷积层块里的基本单位是卷积层后接最大池化层：卷积层用来识别图像里的空间模式，如线条和物体局部，之后的最大池化层则用来降低卷积层对位置的敏感性。卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使用 5×5 的窗口，并在输出上使用sigmoid激活函数。第一个卷积层输出通道数为6，第二个卷积层输出通道数则增加到16。这是因为第二个卷积层比第一个卷积层的输入的高和宽要小，所以增加输出通道使两个卷积层的参数尺寸类似。卷积层块的两个最大池化层的窗口形状均为 2×2 ，且步幅为2。由于池化窗口与步幅形状相同，池化窗口在输入上每次滑动所覆盖的区域互不重叠。</p>
<p>卷积层块的输出形状为(批量大小, 通道, 高, 宽)。当卷积层块的输出传入全连接层块时，全连接层块会将小批量中每个样本变平（flatten）。也就是说，全连接层的输入形状将变成二维，其中第一维是小批量中的样本，第二维是每个样本变平后的向量表示，且向量长度为通道、高和宽的乘积。全连接层块含3个全连接层。它们的输出个数分别是120、84和10，其中10为输出的类别个数。</p>
<p><img src="_image/LeNet.png" alt="leNet"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">leNet_model = tf.keras.Sequential()</span><br><span class="line">leNet_model.add(tf.keras.layers.InputLayer(input_shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">leNet_model.add(tf.keras.layers.Conv2D(filters=<span class="number">6</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line">leNet_model.add(tf.keras.layers.AveragePooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=(<span class="number">2</span>, <span class="number">2</span>))) <span class="comment"># strides default is None, If None, it will default to `pool_size`.  </span></span><br><span class="line"></span><br><span class="line">leNet_model.add(tf.keras.layers.Conv2D(filters=<span class="number">16</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line">leNet_model.add(tf.keras.layers.AveragePooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">leNet_model.add(tf.keras.layers.Flatten())</span><br><span class="line">leNet_model.add(tf.keras.layers.Dense(units=<span class="number">120</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line">leNet_model.add(tf.keras.layers.Dense(units=<span class="number">84</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line">leNet_model.add(tf.keras.layers.Dense(units=<span class="number">10</span>, activation = <span class="string">&#x27;softmax&#x27;</span>))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">leNet_model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_5 (Conv2D)            (None, 28, 28, 6)         156       
_________________________________________________________________
average_pooling2d (AveragePo (None, 14, 14, 6)         0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 10, 10, 16)        2416      
_________________________________________________________________
average_pooling2d_1 (Average (None, 5, 5, 16)          0         
_________________________________________________________________
flatten (Flatten)            (None, 400)               0         
_________________________________________________________________
dense (Dense)                (None, 120)               48120     
_________________________________________________________________
dense_1 (Dense)              (None, 84)                10164     
_________________________________________________________________
dense_2 (Dense)              (None, 10)                850       
=================================================================
Total params: 61,706
Trainable params: 61,706
Non-trainable params: 0
_________________________________________________________________</code></pre>
<h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><p>2012年，AlexNet横空出世。这个模型的名字来源于论文第一作者的姓名Alex Krizhevsky [1]。AlexNet使用了8层卷积神经网络，并以很大的优势赢得了ImageNet 2012图像识别挑战赛。它首次证明了学习到的特征可以超越手工设计的特征，从而一举打破计算机视觉研究的前状。</p>
<p>AlexNet与LeNet的设计理念非常相似，但也有显著的区别。</p>
<ol>
<li><p><strong>更深更宽</strong>，与相对较小的LeNet相比，AlexNet包含8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层，AlexNet使用的卷积通道数也大于LeNet中的卷积通道数十倍。</p>
</li>
<li><p><strong>AlexNet将sigmoid激活函数改成了更加简单的ReLU激活函数</strong>。一方面，ReLU激活函数的计算更简单，例如它并没有sigmoid激活函数中的求幂运算。另一方面，ReLU激活函数在不同的参数初始化方法下使模型更容易训练。这是由于当sigmoid激活函数输出极接近0或1时，这些区域的梯度几乎为0，从而造成反向传播无法继续更新部分模型参数；而ReLU激活函数在正区间的梯度恒为1。因此，若模型参数初始化不当，sigmoid函数可能在正区间得到几乎为0的梯度，从而令模型无法得到有效训练。</p>
</li>
<li><p><strong>训练时使用Dropout随机忽略一部分神经元，以避免模型过拟合</strong>。Dropout虽有单独的论文论述，但是AlexNet将其实用化，通过实践证实了它的效果。在AlexNet中主要是最后几个全连接层使用了Dropout</p>
</li>
<li><p>AlexNet引入了大量的<strong>图像增广</strong>，如翻转、裁剪和颜色变化，从而进一步扩大数据集来缓解过拟合。</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">alexNet_model = tf.keras.Sequential()</span><br><span class="line">alexNet_model.add(tf.keras.layers.InputLayer(input_shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用较大的11 x 11窗口来捕获物体。同时使用步幅4来较大幅度减小输出高和宽。这里使用的输出通道数比LeNet中的也要大很多</span></span><br><span class="line">alexNet_model.add(tf.keras.layers.Conv2D(filters=<span class="number">96</span>, kernel_size=(<span class="number">11</span>, <span class="number">11</span>), strides=(<span class="number">4</span>, <span class="number">4</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">alexNet_model.add(tf.keras.layers.MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span></span><br><span class="line">alexNet_model.add(tf.keras.layers.ZeroPadding2D(padding=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">alexNet_model.add(tf.keras.layers.Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">alexNet_model.add(tf.keras.layers.MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。</span></span><br><span class="line"><span class="comment"># 前两个卷积层后不使用池化层来减小输入的高和宽</span></span><br><span class="line">alexNet_model.add(tf.keras.layers.ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">alexNet_model.add(tf.keras.layers.Conv2D(filters=<span class="number">384</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"></span><br><span class="line">alexNet_model.add(tf.keras.layers.ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">alexNet_model.add(tf.keras.layers.Conv2D(filters=<span class="number">384</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"></span><br><span class="line">alexNet_model.add(tf.keras.layers.ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">alexNet_model.add(tf.keras.layers.Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), strides=(<span class="number">1</span>, <span class="number">1</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合</span></span><br><span class="line">alexNet_model.add(tf.keras.layers.Dense(<span class="number">4096</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">alexNet_model.add(tf.keras.layers.Dropout(rate=<span class="number">0.5</span>))</span><br><span class="line">alexNet_model.add(tf.keras.layers.Dense(<span class="number">4096</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">alexNet_model.add(tf.keras.layers.Dropout(rate=<span class="number">0.5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span></span><br><span class="line">alexNet_model.add(tf.keras.layers.Dense(<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">alexNet_model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_7 (Conv2D)            (None, 54, 54, 96)        11712     
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 26, 26, 96)        0         
_________________________________________________________________
zero_padding2d (ZeroPadding2 (None, 30, 30, 96)        0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 26, 26, 256)       614656    
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 12, 12, 256)       0         
_________________________________________________________________
zero_padding2d_1 (ZeroPaddin (None, 14, 14, 256)       0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 12, 12, 384)       885120    
_________________________________________________________________
zero_padding2d_2 (ZeroPaddin (None, 14, 14, 384)       0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 12, 12, 384)       1327488   
_________________________________________________________________
zero_padding2d_3 (ZeroPaddin (None, 14, 14, 384)       0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 12, 12, 256)       884992    
_________________________________________________________________
dense_3 (Dense)              (None, 12, 12, 4096)      1052672   
_________________________________________________________________
dropout (Dropout)            (None, 12, 12, 4096)      0         
_________________________________________________________________
dense_4 (Dense)              (None, 12, 12, 4096)      16781312  
_________________________________________________________________
dropout_1 (Dropout)          (None, 12, 12, 4096)      0         
_________________________________________________________________
dense_5 (Dense)              (None, 12, 12, 10)        40970     
=================================================================
Total params: 21,598,922
Trainable params: 21,598,922
Non-trainable params: 0
_________________________________________________________________</code></pre>
<h3 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h3><p>AlexNet在LeNet的基础上增加了3个卷积层。但AlexNet作者对它们的卷积窗口、输出通道数和构造顺序均做了大量的调整。虽然AlexNet指明了深度卷积神经网络可以取得出色的结果，但并没有提供简单的规则以指导后来的研究者如何设计新的网络。我们将在本章的后续几节里介绍几种不同的深度网络设计思路。</p>
<p>本节介绍VGG，它的名字来源于论文作者所在的实验室Visual Geometry Group [1]。VGG提出了可以通过重复使用简单的基础块来构建深度模型的思路。</p>
<p>VGG块的组成规律是：连续使用数个相同的填充为1、窗口形状为 3×3 的卷积层后接上一个步幅为2、窗口形状为 2×2 的最大池化层。卷积层保持输入的高和宽不变，而池化层则对其减半。我们使用vgg_block函数来实现这个基础的VGG块，它可以指定卷积层的数量num_convs和输出通道数num_channels。</p>
<p>不同结构的vgg：<br><img src="_image/vgg.jpeg"></p>
<p><strong>有用设计</strong>：两个3´3的卷积层串联相当于1个5´5的卷积层，即一个像素会跟周围5´5的像素产生关联，可以说感受野大小为5´5。而3个3´3的卷积层串联的效果则相当于1个7´7的卷积层。除此之外，3个串联的3´3的卷积层，拥有比1个7´7的卷积层更少的参数量，只有后者的。最重要的是，3个3´3的卷积层拥有比1个7´7的卷积层更多的非线性变换（前者可以使用三次ReLU激活函数，而后者只有一次），使得CNN对特征的学习能力更强。</p>
<p><img src="_image/3x3-5.jpeg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGGBlock</span>(<span class="params">tf.keras.layers.Layer</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_convs, num_channels</span>):</span></span><br><span class="line">    <span class="built_in">super</span>(VGGBlock, self).__init__()</span><br><span class="line">    self.convs = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_convs):</span><br><span class="line">      self.convs.append(tf.keras.layers.ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line">      self.convs.append(tf.keras.layers.Conv2D(filters=num_channels, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    self.maxpool = tf.keras.layers.MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> self.convs:</span><br><span class="line">      inputs = layer(inputs)</span><br><span class="line">    outputs = self.maxpool(inputs)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line">vgg_block = VGGBlock(<span class="number">3</span>, <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">test_inputs = tf.random.uniform(shape=(<span class="number">2</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>), dtype=tf.float32)</span><br><span class="line">vgg_block.call(test_inputs).shape</span><br></pre></td></tr></table></figure>




<pre><code>TensorShape([2, 16, 16, 64])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_vggNet</span>(<span class="params">conv_arch</span>):</span></span><br><span class="line">    vggNet_model = tf.keras.Sequential()</span><br><span class="line">    vggNet_model.add(tf.keras.layers.InputLayer(input_shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">1</span>)))</span><br><span class="line">    <span class="comment"># 卷积层部分</span></span><br><span class="line">    <span class="keyword">for</span> (num_convs, num_channels) <span class="keyword">in</span> conv_arch:</span><br><span class="line">        vggNet_model.add(VGGBlock(num_convs, num_channels))</span><br><span class="line">    vggNet_model.add(tf.keras.layers.Flatten())</span><br><span class="line">    <span class="comment"># 全连接层部分</span></span><br><span class="line">    vggNet_model.add(tf.keras.layers.Dense(<span class="number">4096</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    vggNet_model.add(tf.keras.layers.Dropout(rate=<span class="number">0.5</span>))</span><br><span class="line">    vggNet_model.add(tf.keras.layers.Dense(<span class="number">4096</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    vggNet_model.add(tf.keras.layers.Dropout(rate=<span class="number">0.5</span>))</span><br><span class="line">    vggNet_model.add(tf.keras.layers.Dense(units=<span class="number">10</span>))</span><br><span class="line">    <span class="keyword">return</span> vggNet_model</span><br><span class="line"></span><br><span class="line">conv_arch = ((<span class="number">1</span>, <span class="number">64</span>), (<span class="number">1</span>, <span class="number">128</span>), (<span class="number">2</span>, <span class="number">256</span>), (<span class="number">2</span>, <span class="number">512</span>), (<span class="number">2</span>, <span class="number">512</span>))</span><br><span class="line">vggNet = generate_vggNet(conv_arch)</span><br><span class="line">vggNet.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_5&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
vgg_block_16 (VGGBlock)      (None, 112, 112, 64)      640       
_________________________________________________________________
vgg_block_17 (VGGBlock)      (None, 56, 56, 128)       73856     
_________________________________________________________________
vgg_block_18 (VGGBlock)      (None, 28, 28, 256)       885248    
_________________________________________________________________
vgg_block_19 (VGGBlock)      (None, 14, 14, 512)       3539968   
_________________________________________________________________
vgg_block_20 (VGGBlock)      (None, 7, 7, 512)         4719616   
_________________________________________________________________
flatten_1 (Flatten)          (None, 25088)             0         
_________________________________________________________________
dense_12 (Dense)             (None, 4096)              102764544 
_________________________________________________________________
dropout_6 (Dropout)          (None, 4096)              0         
_________________________________________________________________
dense_13 (Dense)             (None, 4096)              16781312  
_________________________________________________________________
dropout_7 (Dropout)          (None, 4096)              0         
_________________________________________________________________
dense_14 (Dense)             (None, 10)                40970     
=================================================================
Total params: 128,806,154
Trainable params: 128,806,154
Non-trainable params: 0
_________________________________________________________________</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vgg16_app = tf.keras.applications.VGG16(weights=<span class="literal">None</span>)</span><br><span class="line">vgg16_app.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;vgg16&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_9 (InputLayer)         [(None, 224, 224, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544 
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
predictions (Dense)          (None, 1000)              4097000   
=================================================================
Total params: 138,357,544
Trainable params: 138,357,544
Non-trainable params: 0
_________________________________________________________________</code></pre>
<h3 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h3><p>Google Inception Net首次出现在ILSVRC 2014的比赛中（和VGGNet同年），就以较大优势取得了第一名。那届比赛中的Inception Net通常被称为Inception V1，它最大的特点是控制了计算量和参数量的同时，获得了非常好的分类性能——top-5错误率6.67%，只有AlexNet的一半不到。</p>
<p>Inception Module的基本结构，其中有4个分支：</p>
<ol>
<li>第一个分支对输入进行1´1的卷积，这其实也是NIN中提出的一个重要结构。1´1的卷积是一个非常优秀的结构，它可以跨通道组织信息，提高网络的表达能力，同时可以对输出通道升维和降维。可以看到Inception Module的4个分支都用到了1´1卷积，来进行低成本（计算量比3´3小很多）的跨通道的特征变换。</li>
<li>第二个分支先使用了1´1卷积，然后连接3´3卷积，相当于进行了两次特征变换。</li>
<li>第三个分支类似，先是1´1的卷积，然后连接5´5卷积。</li>
<li>最后一个分支则是3´3最大池化后直接使用1´1卷积。<br><img src="_image/inception.png" alt="inception"></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Inception</span>(<span class="params">tf.keras.layers.Layer</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="built_in">super</span>(Inception, self).__init__()</span><br><span class="line"></span><br><span class="line">    self.b1_conv_1 = tf.keras.layers.Conv2D(filters=<span class="number">64</span>, kernel_size=<span class="number">1</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    self.b2_conv_1 = tf.keras.layers.Conv2D(filters=<span class="number">64</span>, kernel_size=<span class="number">1</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">    self.b2_padding = tf.keras.layers.ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    self.b2_conv_3 = tf.keras.layers.Conv2D(filters=<span class="number">64</span>, kernel_size=<span class="number">3</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># padding(1) + conv(3*3) = conv(3*3, padding=&#x27;same&#x27;)</span></span><br><span class="line"></span><br><span class="line">    self.b3_conv_1 = tf.keras.layers.Conv2D(filters=<span class="number">64</span>, kernel_size=<span class="number">1</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">    self.b3_padding = tf.keras.layers.ZeroPadding2D(padding=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">    self.b3_conv_5 = tf.keras.layers.Conv2D(filters=<span class="number">64</span>, kernel_size=<span class="number">5</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    self.b4_padding = tf.keras.layers.ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    self.b4_pool_3 = tf.keras.layers.MaxPool2D(pool_size=<span class="number">3</span>, strides=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    self.b4_conv_1 = tf.keras.layers.Conv2D(filters=<span class="number">64</span>, kernel_size=<span class="number">1</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    self.concatenate = tf.keras.layers.Concatenate()</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">    <span class="comment"># 线路1，单1 x 1卷积层</span></span><br><span class="line">    branch_1 = self.b1_conv_1(inputs)</span><br><span class="line">    <span class="comment"># 线路2，1 x 1卷积层后接3 x 3卷积层</span></span><br><span class="line">    branch_2 = self.b2_conv_3(self.b2_padding(self.b2_conv_1(inputs)))</span><br><span class="line">    <span class="comment"># 线路3，1 x 1卷积层后接5 x 5卷积层</span></span><br><span class="line">    branch_3 = self.b3_conv_5(self.b3_padding(self.b3_conv_1(inputs)))</span><br><span class="line">    <span class="comment"># 线路4，3 x 3最大池化层后接1 x 1卷积层</span></span><br><span class="line">    branch_4 = self.b4_conv_1(self.b4_padding(self.b4_pool_3(inputs)))</span><br><span class="line">    <span class="comment"># channel_axis = -1</span></span><br><span class="line">    outputs = tf.keras.layers.concatenate([branch_1, branch_2, branch_3, branch_4], axis=-<span class="number">1</span>) </span><br><span class="line">    <span class="keyword">return</span> outputs</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inception = Inception()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_inputs = tf.random.uniform(shape=(<span class="number">2</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">3</span>))</span><br><span class="line">inception(test_inputs).shape</span><br></pre></td></tr></table></figure>




<pre><code>TensorShape([2, 10, 10, 256])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tmp = tf.keras.applications.InceptionV3(weights=<span class="literal">None</span>)</span><br><span class="line">tmp.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;inception_v3&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           [(None, 299, 299, 3) 0                                            
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 149, 149, 32) 864         input_11[0][0]                   
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d_53[0][0]                  
__________________________________________________________________________________________________
activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 147, 147, 32) 9216        activation[0][0]                 
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_54[0][0]                  
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 147, 147, 64) 18432       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_55[0][0]                  
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_24 (MaxPooling2D) (None, 73, 73, 64)   0           activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 73, 73, 80)   5120        max_pooling2d_24[0][0]           
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_56[0][0]                  
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 71, 71, 192)  138240      activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_57[0][0]                  
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_25 (MaxPooling2D) (None, 35, 35, 192)  0           activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_61 (Conv2D)              (None, 35, 35, 64)   12288       max_pooling2d_25[0][0]           
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_61[0][0]                  
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
conv2d_59 (Conv2D)              (None, 35, 35, 48)   9216        max_pooling2d_25[0][0]           
__________________________________________________________________________________________________
conv2d_62 (Conv2D)              (None, 35, 35, 96)   55296       activation_8[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_59[0][0]                  
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_62[0][0]                  
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
average_pooling2d_2 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_25[0][0]           
__________________________________________________________________________________________________
conv2d_58 (Conv2D)              (None, 35, 35, 64)   12288       max_pooling2d_25[0][0]           
__________________________________________________________________________________________________
conv2d_60 (Conv2D)              (None, 35, 35, 64)   76800       activation_6[0][0]               
__________________________________________________________________________________________________
conv2d_63 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               
__________________________________________________________________________________________________
conv2d_64 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_2[0][0]        
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_58[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_60[0][0]                  
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_63[0][0]                  
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_64[0][0]                  
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               
                                                                 activation_7[0][0]               
                                                                 activation_10[0][0]              
                                                                 activation_11[0][0]              
__________________________________________________________________________________________________
conv2d_68 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_68[0][0]                  
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
conv2d_66 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_69 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_66[0][0]                  
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_69[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
average_pooling2d_3 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_65 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     
__________________________________________________________________________________________________
conv2d_67 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_70 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              
__________________________________________________________________________________________________
conv2d_71 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_3[0][0]        
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_65[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_67[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_70[0][0]                  
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_71[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              
                                                                 activation_14[0][0]              
                                                                 activation_17[0][0]              
                                                                 activation_18[0][0]              
__________________________________________________________________________________________________
conv2d_75 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_75[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_73 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_76 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_73[0][0]                  
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_76[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
average_pooling2d_4 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_72 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     
__________________________________________________________________________________________________
conv2d_74 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_77 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              
__________________________________________________________________________________________________
conv2d_78 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_4[0][0]        
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_72[0][0]                  
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_74[0][0]                  
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_77[0][0]                  
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_78[0][0]                  
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              
                                                                 activation_21[0][0]              
                                                                 activation_24[0][0]              
                                                                 activation_25[0][0]              
__________________________________________________________________________________________________
conv2d_80 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_80[0][0]                  
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     
__________________________________________________________________________________________________
conv2d_81 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_81[0][0]                  
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_79 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     
__________________________________________________________________________________________________
conv2d_82 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_79[0][0]                  
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_82[0][0]                  
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
max_pooling2d_26 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     
__________________________________________________________________________________________________
mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              
                                                                 activation_29[0][0]              
                                                                 max_pooling2d_26[0][0]           
__________________________________________________________________________________________________
conv2d_87 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_87[0][0]                  
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
conv2d_88 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_88[0][0]                  
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     
__________________________________________________________________________________________________
conv2d_84 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_89 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_84[0][0]                  
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_89[0][0]                  
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
conv2d_85 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              
__________________________________________________________________________________________________
conv2d_90 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_85[0][0]                  
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_90[0][0]                  
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_83 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     
__________________________________________________________________________________________________
conv2d_86 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              
__________________________________________________________________________________________________
conv2d_91 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              
__________________________________________________________________________________________________
conv2d_92 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_83[0][0]                  
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_86[0][0]                  
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_91[0][0]                  
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_92[0][0]                  
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     
__________________________________________________________________________________________________
mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              
                                                                 activation_33[0][0]              
                                                                 activation_38[0][0]              
                                                                 activation_39[0][0]              
__________________________________________________________________________________________________
conv2d_97 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_97[0][0]                  
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
conv2d_98 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_98[0][0]                  
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     
__________________________________________________________________________________________________
conv2d_94 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_99 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_94[0][0]                  
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_99[0][0]                  
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
conv2d_95 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              
__________________________________________________________________________________________________
conv2d_100 (Conv2D)             (None, 17, 17, 160)  179200      activation_46[0][0]              
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_95[0][0]                  
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_100[0][0]                 
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     
__________________________________________________________________________________________________
average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_93 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     
__________________________________________________________________________________________________
conv2d_96 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              
__________________________________________________________________________________________________
conv2d_101 (Conv2D)             (None, 17, 17, 192)  215040      activation_47[0][0]              
__________________________________________________________________________________________________
conv2d_102 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_93[0][0]                  
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_96[0][0]                  
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_101[0][0]                 
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_102[0][0]                 
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     
__________________________________________________________________________________________________
mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              
                                                                 activation_43[0][0]              
                                                                 activation_48[0][0]              
                                                                 activation_49[0][0]              
__________________________________________________________________________________________________
conv2d_107 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_107[0][0]                 
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
conv2d_108 (Conv2D)             (None, 17, 17, 160)  179200      activation_54[0][0]              
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_108[0][0]                 
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     
__________________________________________________________________________________________________
conv2d_104 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_109 (Conv2D)             (None, 17, 17, 160)  179200      activation_55[0][0]              
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_104[0][0]                 
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_109[0][0]                 
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     
__________________________________________________________________________________________________
conv2d_105 (Conv2D)             (None, 17, 17, 160)  179200      activation_51[0][0]              
__________________________________________________________________________________________________
conv2d_110 (Conv2D)             (None, 17, 17, 160)  179200      activation_56[0][0]              
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_105[0][0]                 
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_110[0][0]                 
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     
__________________________________________________________________________________________________
average_pooling2d_7 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_103 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     
__________________________________________________________________________________________________
conv2d_106 (Conv2D)             (None, 17, 17, 192)  215040      activation_52[0][0]              
__________________________________________________________________________________________________
conv2d_111 (Conv2D)             (None, 17, 17, 192)  215040      activation_57[0][0]              
__________________________________________________________________________________________________
conv2d_112 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_7[0][0]        
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_103[0][0]                 
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_106[0][0]                 
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_111[0][0]                 
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_112[0][0]                 
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     
__________________________________________________________________________________________________
mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              
                                                                 activation_53[0][0]              
                                                                 activation_58[0][0]              
                                                                 activation_59[0][0]              
__________________________________________________________________________________________________
conv2d_117 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_117[0][0]                 
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     
__________________________________________________________________________________________________
conv2d_118 (Conv2D)             (None, 17, 17, 192)  258048      activation_64[0][0]              
__________________________________________________________________________________________________
batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_118[0][0]                 
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     
__________________________________________________________________________________________________
conv2d_114 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_119 (Conv2D)             (None, 17, 17, 192)  258048      activation_65[0][0]              
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_114[0][0]                 
__________________________________________________________________________________________________
batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_119[0][0]                 
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     
__________________________________________________________________________________________________
conv2d_115 (Conv2D)             (None, 17, 17, 192)  258048      activation_61[0][0]              
__________________________________________________________________________________________________
conv2d_120 (Conv2D)             (None, 17, 17, 192)  258048      activation_66[0][0]              
__________________________________________________________________________________________________
batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_115[0][0]                 
__________________________________________________________________________________________________
batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_120[0][0]                 
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     
__________________________________________________________________________________________________
average_pooling2d_8 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_113 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     
__________________________________________________________________________________________________
conv2d_116 (Conv2D)             (None, 17, 17, 192)  258048      activation_62[0][0]              
__________________________________________________________________________________________________
conv2d_121 (Conv2D)             (None, 17, 17, 192)  258048      activation_67[0][0]              
__________________________________________________________________________________________________
conv2d_122 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_8[0][0]        
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_113[0][0]                 
__________________________________________________________________________________________________
batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_116[0][0]                 
__________________________________________________________________________________________________
batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_121[0][0]                 
__________________________________________________________________________________________________
batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_122[0][0]                 
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     
__________________________________________________________________________________________________
mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              
                                                                 activation_63[0][0]              
                                                                 activation_68[0][0]              
                                                                 activation_69[0][0]              
__________________________________________________________________________________________________
conv2d_125 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     
__________________________________________________________________________________________________
batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_125[0][0]                 
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     
__________________________________________________________________________________________________
conv2d_126 (Conv2D)             (None, 17, 17, 192)  258048      activation_72[0][0]              
__________________________________________________________________________________________________
batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_126[0][0]                 
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     
__________________________________________________________________________________________________
conv2d_123 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     
__________________________________________________________________________________________________
conv2d_127 (Conv2D)             (None, 17, 17, 192)  258048      activation_73[0][0]              
__________________________________________________________________________________________________
batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_123[0][0]                 
__________________________________________________________________________________________________
batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_127[0][0]                 
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     
__________________________________________________________________________________________________
conv2d_124 (Conv2D)             (None, 8, 8, 320)    552960      activation_70[0][0]              
__________________________________________________________________________________________________
conv2d_128 (Conv2D)             (None, 8, 8, 192)    331776      activation_74[0][0]              
__________________________________________________________________________________________________
batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_124[0][0]                 
__________________________________________________________________________________________________
batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_128[0][0]                 
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     
__________________________________________________________________________________________________
max_pooling2d_27 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     
__________________________________________________________________________________________________
mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              
                                                                 activation_75[0][0]              
                                                                 max_pooling2d_27[0][0]           
__________________________________________________________________________________________________
conv2d_133 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_133[0][0]                 
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     
__________________________________________________________________________________________________
conv2d_130 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_134 (Conv2D)             (None, 8, 8, 384)    1548288     activation_80[0][0]              
__________________________________________________________________________________________________
batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_130[0][0]                 
__________________________________________________________________________________________________
batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_134[0][0]                 
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     
__________________________________________________________________________________________________
conv2d_131 (Conv2D)             (None, 8, 8, 384)    442368      activation_77[0][0]              
__________________________________________________________________________________________________
conv2d_132 (Conv2D)             (None, 8, 8, 384)    442368      activation_77[0][0]              
__________________________________________________________________________________________________
conv2d_135 (Conv2D)             (None, 8, 8, 384)    442368      activation_81[0][0]              
__________________________________________________________________________________________________
conv2d_136 (Conv2D)             (None, 8, 8, 384)    442368      activation_81[0][0]              
__________________________________________________________________________________________________
average_pooling2d_9 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     
__________________________________________________________________________________________________
conv2d_129 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     
__________________________________________________________________________________________________
batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_131[0][0]                 
__________________________________________________________________________________________________
batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_132[0][0]                 
__________________________________________________________________________________________________
batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_135[0][0]                 
__________________________________________________________________________________________________
batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_136[0][0]                 
__________________________________________________________________________________________________
conv2d_137 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_9[0][0]        
__________________________________________________________________________________________________
batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_129[0][0]                 
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     
__________________________________________________________________________________________________
activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     
__________________________________________________________________________________________________
activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     
__________________________________________________________________________________________________
batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_137[0][0]                 
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     
__________________________________________________________________________________________________
mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              
                                                                 activation_79[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_82[0][0]              
                                                                 activation_83[0][0]              
__________________________________________________________________________________________________
activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     
__________________________________________________________________________________________________
mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              
                                                                 mixed9_0[0][0]                   
                                                                 concatenate_2[0][0]              
                                                                 activation_84[0][0]              
__________________________________________________________________________________________________
conv2d_142 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_142[0][0]                 
__________________________________________________________________________________________________
activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     
__________________________________________________________________________________________________
conv2d_139 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_143 (Conv2D)             (None, 8, 8, 384)    1548288     activation_89[0][0]              
__________________________________________________________________________________________________
batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_139[0][0]                 
__________________________________________________________________________________________________
batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_143[0][0]                 
__________________________________________________________________________________________________
activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     
__________________________________________________________________________________________________
activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     
__________________________________________________________________________________________________
conv2d_140 (Conv2D)             (None, 8, 8, 384)    442368      activation_86[0][0]              
__________________________________________________________________________________________________
conv2d_141 (Conv2D)             (None, 8, 8, 384)    442368      activation_86[0][0]              
__________________________________________________________________________________________________
conv2d_144 (Conv2D)             (None, 8, 8, 384)    442368      activation_90[0][0]              
__________________________________________________________________________________________________
conv2d_145 (Conv2D)             (None, 8, 8, 384)    442368      activation_90[0][0]              
__________________________________________________________________________________________________
average_pooling2d_10 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     
__________________________________________________________________________________________________
conv2d_138 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     
__________________________________________________________________________________________________
batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_140[0][0]                 
__________________________________________________________________________________________________
batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_141[0][0]                 
__________________________________________________________________________________________________
batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_144[0][0]                 
__________________________________________________________________________________________________
batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_145[0][0]                 
__________________________________________________________________________________________________
conv2d_146 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_10[0][0]       
__________________________________________________________________________________________________
batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_138[0][0]                 
__________________________________________________________________________________________________
activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     
__________________________________________________________________________________________________
activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     
__________________________________________________________________________________________________
activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     
__________________________________________________________________________________________________
activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     
__________________________________________________________________________________________________
batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_146[0][0]                 
__________________________________________________________________________________________________
activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     
__________________________________________________________________________________________________
mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              
                                                                 activation_88[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              
                                                                 activation_92[0][0]              
__________________________________________________________________________________________________
activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     
__________________________________________________________________________________________________
mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              
                                                                 mixed9_1[0][0]                   
                                                                 concatenate_3[0][0]              
                                                                 activation_93[0][0]              
__________________________________________________________________________________________________
avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    
__________________________________________________________________________________________________
predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   
==================================================================================================
Total params: 23,851,784
Trainable params: 23,817,352
Non-trainable params: 34,432
__________________________________________________________________________________________________</code></pre>
<h3 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h3><p>ResNet（Residual Neural Network）由微软研究院的Kaiming He等4名华人提出，通过使用Residual Unit成功训练152层深的神经网络，在ILSVRC 2015比赛中获得了冠军，取得3.57%的top-5错误率，同时参数量却比VGGNet低，效果非常突出。</p>
<p>假定某段神经网络的输入是x，期望输出是，如果我们直接把输入x传到输出作为初始结果，那么此时我们需要学习的目标就是。如图14所示，这就是一个ResNet的残差学习单元（Residual Unit），ResNet相当于将学习目标改变了，不再是学习一个完整的输出，只是输出和输入的差别，即残差。</p>
<p>可以看到普通直连的卷积神经网络和ResNet的最大区别在于，ResNet有很多旁路的支线将输入直接连到后面的层，使得后面的层可以直接学习残差，这种结构也被称为shortcut或skip connections。</p>
<p><img src="_image/residual.png"></p>
<p><strong>Inception V2</strong> 学习了VGGNet，用两个3´3的卷积代替5´5的大卷积（用以降低参数量并减轻过拟合），还提出了著名的Batch Normalization（以下简称BN）方法。</p>
<p><strong>Inception V3</strong> 网络则主要的改造：引入了Factorization into small convolutions的思想，将一个较大的二维卷积拆成两个较小的一维卷积，比如将7´7卷积拆成1´7卷积和7´1卷积，或者将3´3卷积拆成1´3卷积和3´1卷积，如图12所示。一方面节约了大量参数，加速运算并减轻了过拟合（比将7´7卷积拆成1´7卷积和7´1卷积，比拆成3个3´3卷积更节约参数）</p>
<p>总结：<br>在AlexNet之后，我们可以将卷积神经网络的发展分为两类，一类是网络结构上的改进调整（图18中的左侧分支），另一类是网络深度的增加（图18中的右侧分支）。<br><img src="_image/lenet-inception_restnet.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Residual</span>(<span class="params">tf.keras.layers.Layer</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_channels, use_1x1conv=<span class="literal">False</span>, strides=<span class="number">1</span>, **kwargs</span>):</span></span><br><span class="line">    <span class="built_in">super</span>(Residual, self).__init__()</span><br><span class="line">    self.zeropadding1 = tf.keras.layers.ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    self.conv1 = tf.keras.layers.Conv2D(num_channels, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), strides=strides)</span><br><span class="line">    self.zeropadding2 = tf.keras.layers.ZeroPadding2D(padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    self.conv2 = tf.keras.layers.Conv2D(num_channels, kernel_size=(<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> use_1x1conv:</span><br><span class="line">      self.conv3 = tf.keras.layers.Conv2D(num_channels, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), strides=strides)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      self.conv3 = <span class="literal">None</span></span><br><span class="line">    self.bn1 = tf.keras.layers.BatchNormalization()</span><br><span class="line">    self.bn2 = tf.keras.layers.BatchNormalization()</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, X</span>):</span></span><br><span class="line">    Y = tf.keras.layers.ReLU()(self.bn1(self.conv1(self.zeropadding1(X))))</span><br><span class="line">    Y = self.bn2(self.conv2(self.zeropadding2(Y)))</span><br><span class="line">    <span class="keyword">if</span> self.conv3:</span><br><span class="line">      X = self.conv3(X)</span><br><span class="line">    <span class="keyword">return</span> tf.keras.layers.ReLU()(Y + X)</span><br><span class="line">residual = Residual(<span class="number">64</span>, use_1x1conv=<span class="literal">True</span>)</span><br><span class="line">test_inputs = tf.random.uniform(shape=(<span class="number">2</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>))</span><br><span class="line">residual(test_inputs).shape</span><br></pre></td></tr></table></figure>




<pre><code>TensorShape([2, 32, 32, 64])</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">resNet_app = tf.keras.applications.ResNet50(weights=<span class="literal">None</span>)</span><br><span class="line">resNet_app.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;resnet50&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_12 (InputLayer)           [(None, 224, 224, 3) 0                                            
__________________________________________________________________________________________________
conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_12[0][0]                   
__________________________________________________________________________________________________
conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  
__________________________________________________________________________________________________
conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 
__________________________________________________________________________________________________
conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   
__________________________________________________________________________________________________
pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 
__________________________________________________________________________________________________
pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  
__________________________________________________________________________________________________
conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 
__________________________________________________________________________________________________
conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          
                                                                 conv2_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           
__________________________________________________________________________________________________
conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           
                                                                 conv2_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           
__________________________________________________________________________________________________
conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           
                                                                 conv2_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          
                                                                 conv3_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           
__________________________________________________________________________________________________
conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           
                                                                 conv3_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           
__________________________________________________________________________________________________
conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           
                                                                 conv3_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           
__________________________________________________________________________________________________
conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           
                                                                 conv3_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          
                                                                 conv4_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           
__________________________________________________________________________________________________
conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           
                                                                 conv4_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           
__________________________________________________________________________________________________
conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           
                                                                 conv4_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           
__________________________________________________________________________________________________
conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           
                                                                 conv4_block4_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           
__________________________________________________________________________________________________
conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           
                                                                 conv4_block5_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           
__________________________________________________________________________________________________
conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        
__________________________________________________________________________________________________
conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        
__________________________________________________________________________________________________
conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           
                                                                 conv4_block6_3_bn[0][0]          
__________________________________________________________________________________________________
conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           
__________________________________________________________________________________________________
conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          
                                                                 conv5_block1_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           
__________________________________________________________________________________________________
conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           
                                                                 conv5_block2_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           
__________________________________________________________________________________________________
conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        
__________________________________________________________________________________________________
conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        
__________________________________________________________________________________________________
conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           
                                                                 conv5_block3_3_bn[0][0]          
__________________________________________________________________________________________________
conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           
__________________________________________________________________________________________________
avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           
__________________________________________________________________________________________________
predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   
==================================================================================================
Total params: 25,636,712
Trainable params: 25,583,592
Non-trainable params: 53,120
__________________________________________________________________________________________________</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.utils.plot_model(resNet_app)</span><br></pre></td></tr></table></figure>




<p><img src="_image/output_23_0.png" alt="png"></p>
<p>CNN技巧：</p>
<ol>
<li>“1Padding+3x3卷积” 与 “2Padding+5x5卷积”可以保持特征图长宽不变。</li>
<li>1x1卷积在不需要padding的情况下就可以保持特征图长宽不变，通常用来降低channel数量。</li>
<li>3x3卷积很有效（并能减少参数），2个3x3卷积=5x5卷积, 3个3x3卷积=7x7卷积（这里的等于指感受野）。</li>
<li>一个较大的二维卷积拆成两个较小的一维卷积，比如将7´7卷积拆成1´7卷积和7´1卷积。一方面节约了大量参数，加速运算并减轻了过拟合。</li>
<li>卷积在做特征提取时，通常不会改变特征图的长宽，则是通用pooling层来减小特征图长宽。</li>
<li>整个卷积网络变化趋势：特征图长宽逐渐减少（提高感受野），通道数量逐渐增加（提取更多特征信息）。</li>
</ol>
<h3 id="图片分类"><a href="#图片分类" class="headerlink" title="图片分类"></a>图片分类</h3><h4 id="数据下载"><a href="#数据下载" class="headerlink" title="数据下载"></a>数据下载</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip</span></span><br><span class="line"><span class="comment"># !unzip cats_and_dogs_filtered.zip</span></span><br></pre></td></tr></table></figure>

<h4 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">PATH = os.path.join(<span class="string">&#x27;./&#x27;</span>, <span class="string">&#x27;cats_and_dogs_filtered&#x27;</span>)</span><br><span class="line"></span><br><span class="line">train_dir = os.path.join(PATH, <span class="string">&#x27;train&#x27;</span>)</span><br><span class="line">validation_dir = os.path.join(PATH, <span class="string">&#x27;validation&#x27;</span>)</span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">32</span></span><br><span class="line">IMG_SIZE = (<span class="number">160</span>, <span class="number">160</span>)</span><br><span class="line"></span><br><span class="line">train_dataset = tf.keras.preprocessing.image_dataset_from_directory(train_dir,</span><br><span class="line">                        shuffle=<span class="literal">True</span>,</span><br><span class="line">                        batch_size=BATCH_SIZE,</span><br><span class="line">                        image_size=IMG_SIZE)</span><br><span class="line"></span><br><span class="line">validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(validation_dir,</span><br><span class="line">                          shuffle=<span class="literal">True</span>,</span><br><span class="line">                          batch_size=BATCH_SIZE,</span><br><span class="line">                          image_size=IMG_SIZE)</span><br><span class="line"></span><br><span class="line">class_names = train_dataset.class_names</span><br><span class="line">num_classes = <span class="built_in">len</span>(class_names)</span><br><span class="line">print(class_names)</span><br></pre></td></tr></table></figure>

<pre><code>Found 2000 files belonging to 2 classes.
Found 1000 files belonging to 2 classes.
[&#39;cats&#39;, &#39;dogs&#39;]</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_data</span>(<span class="params">dataset</span>):</span></span><br><span class="line">  plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">  <span class="keyword">for</span> images, labels <span class="keyword">in</span> dataset.take(<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>):</span><br><span class="line">      ax = plt.subplot(<span class="number">3</span>, <span class="number">3</span>, i + <span class="number">1</span>)</span><br><span class="line">      plt.imshow(images[i].numpy().astype(<span class="string">&quot;uint8&quot;</span>))</span><br><span class="line">      plt.title(class_names[labels[i]])</span><br><span class="line">      plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line"></span><br><span class="line">show_data(train_dataset)</span><br></pre></td></tr></table></figure>


<p><img src="_image/output_29_0.png" alt="png"></p>
<h4 id="构建模型并训练"><a href="#构建模型并训练" class="headerlink" title="构建模型并训练"></a>构建模型并训练</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_model</span>():</span></span><br><span class="line">  model = Sequential([</span><br><span class="line">    layers.experimental.preprocessing.Rescaling(<span class="number">1.</span>/<span class="number">255</span>, input_shape=(<span class="number">160</span>, <span class="number">160</span>, <span class="number">3</span>)),</span><br><span class="line">    layers.Conv2D(<span class="number">16</span>, <span class="number">3</span>, padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.MaxPooling2D(),</span><br><span class="line">    layers.Conv2D(<span class="number">32</span>, <span class="number">3</span>, padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.MaxPooling2D(),</span><br><span class="line">    layers.Conv2D(<span class="number">64</span>, <span class="number">3</span>, padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.MaxPooling2D(),</span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(num_classes)</span><br><span class="line">  ])</span><br><span class="line">  <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span>(<span class="params">model, train_dataset, validation_dataset, epochs=<span class="number">10</span>,</span>):</span></span><br><span class="line">  model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">          loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">          metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">  history = model.fit(</span><br><span class="line">    train_dataset,</span><br><span class="line">    validation_data=validation_dataset,</span><br><span class="line">    epochs=epochs</span><br><span class="line">  )</span><br><span class="line">  <span class="keyword">return</span> history</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_history</span>(<span class="params">history, epochs=<span class="number">10</span></span>):</span></span><br><span class="line">  acc = history.history[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">  val_acc = history.history[<span class="string">&#x27;val_accuracy&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  loss=history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">  val_loss=history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  epochs_range = <span class="built_in">range</span>(epochs)</span><br><span class="line"></span><br><span class="line">  plt.figure(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">  plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">  plt.plot(epochs_range, acc, label=<span class="string">&#x27;Training Accuracy&#x27;</span>)</span><br><span class="line">  plt.plot(epochs_range, val_acc, label=<span class="string">&#x27;Validation Accuracy&#x27;</span>)</span><br><span class="line">  plt.legend(loc=<span class="string">&#x27;lower right&#x27;</span>)</span><br><span class="line">  plt.title(<span class="string">&#x27;Training and Validation Accuracy&#x27;</span>)</span><br><span class="line"></span><br><span class="line">  plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">  plt.plot(epochs_range, loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">  plt.plot(epochs_range, val_loss, label=<span class="string">&#x27;Validation Loss&#x27;</span>)</span><br><span class="line">  plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line">  plt.title(<span class="string">&#x27;Training and Validation Loss&#x27;</span>)</span><br><span class="line">  plt.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sample_model = generate_model()</span><br><span class="line">history = train_model(sample_model, train_dataset, validation_dataset, epochs=<span class="number">10</span>)</span><br><span class="line">plot_history(history)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/10
63/63 [==============================] - 69s 1s/step - loss: 0.7187 - accuracy: 0.5605 - val_loss: 0.6372 - val_accuracy: 0.6250
Epoch 2/10
63/63 [==============================] - 32s 516ms/step - loss: 0.6184 - accuracy: 0.6575 - val_loss: 0.6171 - val_accuracy: 0.6930
Epoch 3/10
63/63 [==============================] - 36s 564ms/step - loss: 0.5688 - accuracy: 0.7185 - val_loss: 0.6320 - val_accuracy: 0.6750
Epoch 4/10
63/63 [==============================] - 36s 566ms/step - loss: 0.5011 - accuracy: 0.7600 - val_loss: 0.6163 - val_accuracy: 0.6820
Epoch 5/10
63/63 [==============================] - 37s 580ms/step - loss: 0.4381 - accuracy: 0.7865 - val_loss: 0.6432 - val_accuracy: 0.7060
Epoch 6/10
63/63 [==============================] - 38s 607ms/step - loss: 0.3843 - accuracy: 0.8220 - val_loss: 0.6558 - val_accuracy: 0.7250
Epoch 7/10
63/63 [==============================] - 37s 583ms/step - loss: 0.2740 - accuracy: 0.8825 - val_loss: 0.7358 - val_accuracy: 0.7180
Epoch 8/10
63/63 [==============================] - 38s 604ms/step - loss: 0.1906 - accuracy: 0.9180 - val_loss: 0.8276 - val_accuracy: 0.7210
Epoch 9/10
63/63 [==============================] - 40s 629ms/step - loss: 0.1391 - accuracy: 0.9480 - val_loss: 0.9111 - val_accuracy: 0.7340
Epoch 10/10
63/63 [==============================] - 41s 648ms/step - loss: 0.0952 - accuracy: 0.9665 - val_loss: 1.0884 - val_accuracy: 0.7120</code></pre>
<p><img src="_image/output_33_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_model_with_data_augmentation_and_dropout</span>():</span></span><br><span class="line">  data_augmentation = keras.Sequential(</span><br><span class="line">    [</span><br><span class="line">      layers.experimental.preprocessing.RandomFlip(<span class="string">&quot;horizontal&quot;</span>, input_shape=(<span class="number">160</span>, <span class="number">160</span>,<span class="number">3</span>)),</span><br><span class="line">      layers.experimental.preprocessing.RandomRotation(<span class="number">0.1</span>),</span><br><span class="line">      layers.experimental.preprocessing.RandomZoom(<span class="number">0.1</span>),</span><br><span class="line">    ]</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">  model = Sequential([</span><br><span class="line">    data_augmentation,</span><br><span class="line">    layers.experimental.preprocessing.Rescaling(<span class="number">1.</span>/<span class="number">255</span>),</span><br><span class="line">    layers.Conv2D(<span class="number">16</span>, <span class="number">3</span>, padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.MaxPooling2D(),</span><br><span class="line">    layers.Conv2D(<span class="number">32</span>, <span class="number">3</span>, padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.MaxPooling2D(),</span><br><span class="line">    layers.Conv2D(<span class="number">64</span>, <span class="number">3</span>, padding=<span class="string">&#x27;same&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.MaxPooling2D(),</span><br><span class="line">    layers.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(num_classes)</span><br><span class="line">  ])</span><br><span class="line">  <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">with_data_augmentation_and_dropout_model = generate_model_with_data_augmentation_and_dropout()</span><br><span class="line">history = train_model(with_data_augmentation_and_dropout_model, train_dataset, validation_dataset, epochs=<span class="number">15</span>)</span><br><span class="line">plot_history(history, epochs=<span class="number">15</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/15
63/63 [==============================] - 35s 563ms/step - loss: 0.7666 - accuracy: 0.5060 - val_loss: 0.6933 - val_accuracy: 0.5000
Epoch 2/15
63/63 [==============================] - 36s 570ms/step - loss: 0.6933 - accuracy: 0.4970 - val_loss: 0.6924 - val_accuracy: 0.5900
Epoch 3/15
63/63 [==============================] - 35s 552ms/step - loss: 0.6944 - accuracy: 0.5090 - val_loss: 0.6920 - val_accuracy: 0.5860
Epoch 4/15
63/63 [==============================] - 35s 555ms/step - loss: 0.6894 - accuracy: 0.5420 - val_loss: 0.6890 - val_accuracy: 0.5810
Epoch 5/15
63/63 [==============================] - 34s 546ms/step - loss: 0.6824 - accuracy: 0.5685 - val_loss: 0.6842 - val_accuracy: 0.5640
Epoch 6/15
63/63 [==============================] - 35s 550ms/step - loss: 0.6776 - accuracy: 0.5735 - val_loss: 0.6683 - val_accuracy: 0.5840
Epoch 7/15
63/63 [==============================] - 35s 559ms/step - loss: 0.6499 - accuracy: 0.6380 - val_loss: 0.6459 - val_accuracy: 0.6110
Epoch 8/15
63/63 [==============================] - 35s 560ms/step - loss: 0.6231 - accuracy: 0.6710 - val_loss: 0.6170 - val_accuracy: 0.6690
Epoch 9/15
63/63 [==============================] - 36s 567ms/step - loss: 0.6075 - accuracy: 0.6870 - val_loss: 0.5888 - val_accuracy: 0.7010
Epoch 10/15
63/63 [==============================] - 35s 558ms/step - loss: 0.5903 - accuracy: 0.6930 - val_loss: 0.5931 - val_accuracy: 0.6900
Epoch 11/15
63/63 [==============================] - 36s 573ms/step - loss: 0.5764 - accuracy: 0.7070 - val_loss: 0.5924 - val_accuracy: 0.6880
Epoch 12/15
63/63 [==============================] - 35s 562ms/step - loss: 0.5679 - accuracy: 0.7160 - val_loss: 0.5671 - val_accuracy: 0.7040
Epoch 13/15
63/63 [==============================] - 35s 559ms/step - loss: 0.5727 - accuracy: 0.7105 - val_loss: 0.5832 - val_accuracy: 0.6940
Epoch 14/15
63/63 [==============================] - 36s 571ms/step - loss: 0.5539 - accuracy: 0.7225 - val_loss: 0.5918 - val_accuracy: 0.7000
Epoch 15/15
63/63 [==============================] - 36s 565ms/step - loss: 0.5497 - accuracy: 0.7160 - val_loss: 0.5694 - val_accuracy: 0.6990</code></pre>
<p><img src="_image/output_35_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_model_with_vgg</span>():</span></span><br><span class="line">  vgg16 = tf.keras.applications.VGG16(include_top=<span class="literal">False</span>, weights=<span class="literal">None</span>, input_shape=(<span class="number">160</span>, <span class="number">160</span>, <span class="number">3</span>))</span><br><span class="line">  vgg16.load_weights(<span class="string">&#x27;vgg16_weights_tf_dim_ordering_tf_kernels.h5&#x27;</span>, by_name=<span class="literal">True</span>)</span><br><span class="line">  vgg16.trainable=<span class="literal">False</span></span><br><span class="line">  data_augmentation = tf.keras.Sequential([</span><br><span class="line">    tf.keras.layers.experimental.preprocessing.RandomFlip(<span class="string">&#x27;horizontal&#x27;</span>),</span><br><span class="line">    tf.keras.layers.experimental.preprocessing.RandomRotation(<span class="number">0.2</span>),</span><br><span class="line">  ])</span><br><span class="line"></span><br><span class="line">  preprocess_input = tf.keras.applications.vgg16.preprocess_input</span><br><span class="line"></span><br><span class="line">  inputs = tf.keras.Input(shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line">  x = data_augmentation(inputs)</span><br><span class="line">  x = preprocess_input(x)</span><br><span class="line">  x = vgg16(x, training=<span class="literal">True</span>)</span><br><span class="line">  x = tf.keras.layers.GlobalAveragePooling2D()(x)</span><br><span class="line">  x = tf.keras.layers.Dropout(<span class="number">0.2</span>)(x)</span><br><span class="line">  outputs = tf.keras.layers.Dense(num_classes)(x)</span><br><span class="line">  model = tf.keras.Model(inputs, outputs)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">with_vgg_model = generate_model_with_vgg()</span><br><span class="line">history = train_model(with_vgg_model, train_dataset, validation_dataset, epochs=<span class="number">10</span>)</span><br><span class="line">plot_history(history, epochs=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<pre><code>WARNING:tensorflow:Model was constructed with shape (None, 160, 160, 3) for input Tensor(&quot;input_9:0&quot;, shape=(None, 160, 160, 3), dtype=float32), but it was called on an input with incompatible shape (None, 224, 224, 3).
Epoch 1/10
WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(&quot;input_10:0&quot;, shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 160, 160, 3).
WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(&quot;input_10:0&quot;, shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 160, 160, 3).
63/63 [==============================] - ETA: 0s - loss: 2.2022 - accuracy: 0.7145WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(&quot;input_10:0&quot;, shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 160, 160, 3).
63/63 [==============================] - 335s 5s/step - loss: 2.2022 - accuracy: 0.7145 - val_loss: 0.6007 - val_accuracy: 0.8890
Epoch 2/10
63/63 [==============================] - 321s 5s/step - loss: 0.8997 - accuracy: 0.8455 - val_loss: 0.3511 - val_accuracy: 0.9260
Epoch 3/10
63/63 [==============================] - 317s 5s/step - loss: 0.6832 - accuracy: 0.8770 - val_loss: 0.2706 - val_accuracy: 0.9440
Epoch 4/10
63/63 [==============================] - 379s 6s/step - loss: 0.5846 - accuracy: 0.8890 - val_loss: 0.2178 - val_accuracy: 0.9620
Epoch 5/10
63/63 [==============================] - 335s 5s/step - loss: 0.5474 - accuracy: 0.9040 - val_loss: 0.2843 - val_accuracy: 0.9450
Epoch 6/10
63/63 [==============================] - 353s 6s/step - loss: 0.4610 - accuracy: 0.9095 - val_loss: 0.1814 - val_accuracy: 0.9570
Epoch 7/10
63/63 [==============================] - 399s 6s/step - loss: 0.4025 - accuracy: 0.9105 - val_loss: 0.1666 - val_accuracy: 0.9640
Epoch 8/10
63/63 [==============================] - 369s 6s/step - loss: 0.3679 - accuracy: 0.9250 - val_loss: 0.1574 - val_accuracy: 0.9610
Epoch 9/10
63/63 [==============================] - 344s 5s/step - loss: 0.3023 - accuracy: 0.9200 - val_loss: 0.1745 - val_accuracy: 0.9650
Epoch 10/10
63/63 [==============================] - 336s 5s/step - loss: 0.3916 - accuracy: 0.9170 - val_loss: 0.1473 - val_accuracy: 0.9650</code></pre>
<p><img src="_image/output_37_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evalation</span>(<span class="params">model, dataset</span>):</span></span><br><span class="line">  image_batch, label_batch = dataset.as_numpy_iterator().<span class="built_in">next</span>()</span><br><span class="line">  predictions = model.predict(image_batch)</span><br><span class="line">  predictions = tf.math.argmax(predictions, axis=-<span class="number">1</span>)</span><br><span class="line">  print(<span class="string">&#x27;Predictions:\n&#x27;</span>, predictions.numpy())</span><br><span class="line">  print(<span class="string">&#x27;Labels:\n&#x27;</span>, label_batch)</span><br><span class="line"></span><br><span class="line">  plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">9</span>):</span><br><span class="line">    ax = plt.subplot(<span class="number">3</span>, <span class="number">3</span>, i + <span class="number">1</span>)</span><br><span class="line">    plt.imshow(image_batch[i].astype(<span class="string">&quot;uint8&quot;</span>))</span><br><span class="line">    plt.title(class_names[predictions[i]])</span><br><span class="line">    plt.axis(<span class="string">&quot;off&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">evalation(with_vgg_model, validation_dataset)</span><br></pre></td></tr></table></figure>

<pre><code>Predictions:
 [1 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0]
Labels:
 [1 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 1 0 0 1 0]</code></pre>
<p><img src="_image/output_39_1.png" alt="png"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/07/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2020-07-29-Batch_Normalization%E4%B8%8ELayer_Normalization%E7%9A%84%E7%90%86%E8%A7%A3%E6%95%B4%E7%90%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/29/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2020-07-29-Batch_Normalization%E4%B8%8ELayer_Normalization%E7%9A%84%E7%90%86%E8%A7%A3%E6%95%B4%E7%90%86/" class="post-title-link" itemprop="url">Batch Normalization与Layer Normalization的理解整理</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-29 21:07:00" itemprop="dateCreated datePublished" datetime="2020-07-29T21:07:00+00:00">2020-07-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景　　"></a>问题背景　　</h3><p>　接着引入covariate shift的概念：如果ML系统实例集合&lt;X,Y&gt;中的输入值X的分布老是变，这不符合IID假设，网络模型很难稳定的学规律，这不得引入迁移学习才能搞定吗，我们的ML系统还得去学习怎么迎合这种分布变化啊。对于深度学习这种包含很多隐层的网络结构，在训练过程中，因为各层参数不停在变化，所以每个隐层都会面临covariate shift的问题，也就是在训练过程中，隐层的输入分布老是变来变去，这就是所谓的“Internal Covariate Shift”，Internal指的是深层网络的隐层，是发生在网络内部的事情，而不是covariate shift问题只发生在输入层。　　<br>　我们知道网络一旦train起来，那么参数就要发生更新，除了输入层的数据外(因为输入层数据，我们已经人为的为每个样本归一化)，后面网络每一层的输入数据分布是一直在发生变化的，因为在训练的时候，前面层训练参数的更新将导致后面层输入数据分布的变化。以网络第二层为例：网络的第二层输入，是由第一层的参数和input计算得到的，而第一层的参数在整个训练过程中一直在变化，因此必然会引起后面每一层输入数据分布的改变。我们把网络中间层在训练过程中，数据分布的改变称之为：“Internal  Covariate Shift”。Paper所提出的算法，就是要解决在训练过程中，中间层数据分布发生改变的情况，于是就有了Batch  Normalization，这个牛逼算法的诞生。</p>
<h3 id="Normalization-的通用框架"><a href="#Normalization-的通用框架" class="headerlink" title="Normalization 的通用框架"></a>Normalization 的通用框架</h3><p>$$<br>\hat{x}=\frac{x-\mu}{\sigma^2}<br>$$<br>$$<br>y = g\hat{x}+b<br>$$</p>
<p>$\mu$和$\sigma^2$分别是均值和方差，它们是根据特征值计算出来的，g和b是需要训练过程中去学习的参数。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>Layer Normalization与Batch Normalization对比：</strong>　　<br>　BN针对一个minibatch的输入样本，计算均值和方差，基于计算的均值和方差来对某一层神经网络的输入X中每一个case进行归一化操作。但BN有两个明显不足：1、高度依赖于mini-batch的大小，实际使用中会对mini-Batch大小进行约束，不适合类似在线学习（mini-batch为1）情况；2、不适用于RNN网络中normalize操作：BN实际使用时需要计算并且保存某一层神经网络mini-batch的均值和方差等统计信息，对于对一个固定深度的前向神经网络（DNN，CNN）使用BN，很方便；但对于RNN来说，sequence的长度是不一致的，换句话说RNN的深度不是固定的，不同的time-step需要保存不同的statics特征，可能存在一个特殊sequence比其的sequence长很多，这样training时，计算很麻烦。但LN可以有效解决上面这两个问题。</p>
<p>  LN适用于LSTM的加速，但用于CNN加速时并没有取得比BN更好的效果。</p>
<p><strong>BN的特点</strong></p>
<p>但是，BN 的转换是针对单个神经元可训练的——不同神经元的输入经过再平移和再缩放后分布在不同的区间，而 LN 对于一整层的神经元训练得到同一个转换——所有的输入都在同一个区间范围内。如果不同输入特征不属于相似的类别（比如颜色和大小），那么 LN 的处理可能会降低模型的表达能力。</p>
<p><strong>LN的缺点</strong></p>
<p>BN 的转换是针对单个神经元可训练的——不同神经元的输入经过再平移和再缩放后分布在不同的区间，而 LN 对于一整层的神经元训练得到同一个转换——所有的输入都在同一个区间范围内。如果不同输入特征不属于相似的类别（比如颜色和大小），那么 LN 的处理可能会降低模型的表达能力。</p>
<hr>
<p>参考：<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/55852062">Batch Normalization（BN，批量归一化）</a><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/guoyaohua/p/8724433.html">【深度学习】深入理解Batch Normalization批标准化</a><br><a target="_blank" rel="noopener" href="https://blog.csdn.net/hjimce/article/details/50866313">深度学习（二十九）Batch Normalization 学习笔记</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/59728870">深度学习加速策略BN、WN和LN的联系与区别，各自的优缺点和适用的场景？？</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/07/22/Tensorflow2.x%E5%AE%9E%E6%88%98/Tensorflow%E5%AE%9E%E6%88%98(2)_%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98_%E5%94%90%E8%AF%97%E7%94%9F%E6%88%90%E5%99%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/22/Tensorflow2.x%E5%AE%9E%E6%88%98/Tensorflow%E5%AE%9E%E6%88%98(2)_%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98_%E5%94%90%E8%AF%97%E7%94%9F%E6%88%90%E5%99%A8/" class="post-title-link" itemprop="url">Tensorflow实战(2)_循环神经网络实战_唐诗生成器</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-22 20:43:00" itemprop="dateCreated datePublished" datetime="2020-07-22T20:43:00+00:00">2020-07-22</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="本次分享内容："><a href="#本次分享内容：" class="headerlink" title="本次分享内容："></a>本次分享内容：</h2><ul>
<li>上次分享内容回顾</li>
<li>RNN 理论知识</li>
<li>唐诗生成器实例讲解</li>
<li>本次课程内容总结</li>
</ul>
<p>上次分享我们介绍了关于Tensorflow2的基础语法，以及通过手写数字识别任务讲解了如何通过Tensorflow2来搭建全连接神经网络模型。今天我们来介绍用于处理序列信息的网络结构-RNN。</p>
<h2 id="RNN理论知识"><a href="#RNN理论知识" class="headerlink" title="RNN理论知识"></a>RNN理论知识</h2><p>循环神经网络（Recurrent neural network：RNN）是神经网络的一种。循环神经网络可以描述动态时间行为，与前馈神经网络（feedforward neural network）接受较特定结构的输入不同，RNN将状态在自身网络中循环传递，因此可以接受更广泛的时间序列结构输入。<br>如果说一个全连接的神经网络的计算公式是：$y^t=f(x^t)$，那么RNN的公式可以这样表示$y^t, h^t = f(x^t, h^{t-1})$ 。一个单层的RNN可以用下图表示：<br><img src="_image/RNN.png"></p>
<h3 id="Deep-RNN"><a href="#Deep-RNN" class="headerlink" title="Deep RNN"></a>Deep RNN</h3><p>与全连接神经网络一样，RNN也可以叠加多层：<br><img src="_image/Deep_RNN.png"></p>
<h3 id="Bidirectional-RNN"><a href="#Bidirectional-RNN" class="headerlink" title="Bidirectional RNN"></a>Bidirectional RNN</h3><p>Bidirectional RNN 是将传统RNN的状态神经元拆分为两个部分，一个负责forward states，另一个负责backward states。Forward states的输出并不会连接到Backward states的输入。这个结构提供给输出层输入序列中每一个点的完整的过去和未来的上下文信息。<br><img src="_image/Bidirectional_RNN.png"></p>
<h3 id="RNN-计算方式"><a href="#RNN-计算方式" class="headerlink" title="RNN 计算方式"></a>RNN 计算方式</h3><h4 id="Native-RNN"><a href="#Native-RNN" class="headerlink" title="Native RNN"></a>Native RNN</h4><p>$$<br>\begin{align}<br>&amp; h_t = \sigma(W^h h_{t-1} + W^i x_t) \<br>&amp; y_t = \sigma(W^o h_t)<br>\end{align}<br>$$</p>
<h4 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h4><p>$$<br>\begin{align}<br>&amp; i_t = sigm(W^{xi}x_t + W^{hi}h_{t-1}) \<br>&amp; f_t = sigm(W^{xf}x_t + W^{hf}h_{t-1}) \<br>&amp; o_t = sigm(W^{xo}x_t + W^{ho}h_{t-1}) \<br>&amp; \tilde{c_t} = tanh(W^{xc}x_t + W^{hc}h_{t-1}) \<br>&amp; c_t = f_t \bigodot c_{t-1} + i_t \bigodot \tilde{c_t} \<br>&amp; h_t = o_t \bigodot tanh(c_t) \<br>&amp; y_t = \sigma(W^o h_t)<br>\end{align}<br>$$<br>LSTM内部主要有阶段：</p>
<ol>
<li><p>忘记阶段。这个阶段主要是对上一个节点传进来的输入进行选择性忘记。简单来说就是会 “忘记不重要的，记住重要的”。具体来说是通过计算得到的 $f_t$ （f表示forget）来作为忘记门控，来控制上一个状态的 $c_{t-1}$ 哪些需要留哪些需要忘。</p>
</li>
<li><p>选择记忆阶段。这个阶段将这个阶段的输入有选择性地进行“记忆”。主要是会对输入进行选择记忆。哪些重要则着重记录下来，哪些不重要，则少记一些。当前的输入内容由前面计算得到的 $\tilde{c_t}$ 表示。而选择的门控信号则是由 $i_t$ （i代表information）来进行控制。</p>
</li>
<li><p>将上面两步得到的结果相加，即可得到传输给下一个状态的 $c_{t}$ 。也就是上图中的第一个公式。</p>
</li>
<li><p>输出阶段。这个阶段将决定哪些将会被当成当前状态的输出。主要是通过 $o_t$ 来进行控制的。并且对上一阶段得到的 $c_t$ 进行了缩放（通过一个tanh激活函数进行变化）。</p>
</li>
</ol>
<p>另外LSTM与标准RNN不同的是它有两个state，分别是$c_t, h_t$ 。</p>
<h4 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h4><p>$$<br>\begin{align}<br>&amp; z_t = sigm(W^{xz}x_t + W^{hz}h_{t-1}) \<br>&amp; r_t = sigm(W^{xr}x_t + W^{hr}h_{t-1}) \<br>&amp; \tilde{h_t} = tanh(W^{xh}x_t + r_t \bigodot (W^{hh}h_{t-1}) \<br>&amp; h_t = (1-z_t) \bigodot \tilde{h_t} + z_t \bigodot h_{t-1} \<br>&amp; y_t = \sigma(W^o h_t)<br>\end{align}<br>$$</p>
<p>$z_t \bigodot h_{t-1}$ ：表示对原本隐藏状态的选择性“遗忘”。这里的 $z_t$ 可以想象成遗忘门（forget gate），忘记 $h_{t-1}$ 维度中一些不重要的信息。</p>
<p>$(1-z_t) \bigodot \tilde{h_t}$ ：表示对包含当前节点信息的 $\tilde{h_t}$ 进行选择性“记忆”。</p>
<p>GRU很聪明的一点就在于，我们使用了同一个门控 $z_t$ 就同时可以进行遗忘和选择记忆</p>
<h3 id="Tensorflow-Code"><a href="#Tensorflow-Code" class="headerlink" title="Tensorflow Code"></a>Tensorflow Code</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># RNN layer 与 RNNCell layer 的区别</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 锄禾日当午 -&gt; [0, 1, 2, 3, 4]</span></span><br><span class="line"><span class="comment"># 离离原上草 -&gt; [5, 6, 6, 7, 8]</span></span><br><span class="line"></span><br><span class="line">words = tf.constant([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]], dtype=tf.int32)</span><br><span class="line">print(<span class="string">&#x27;words :&#x27;</span>, words.shape) <span class="comment"># batch_size, sequence_length</span></span><br><span class="line"></span><br><span class="line">embedding_ret = tf.keras.layers.Embedding(input_dim=<span class="number">9</span>, output_dim=<span class="number">4</span>)(words)</span><br><span class="line">print(<span class="string">&#x27;embedding ret shape :&#x27;</span>, embedding_ret.shape) <span class="comment"># batch_size, sequence_length, embedding_size</span></span><br><span class="line"></span><br><span class="line">gru_cell = tf.keras.layers.GRUCell(units=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">rnn = tf.keras.layers.RNN(gru_cell)</span><br><span class="line">initial_state=tf.zeros(shape=(<span class="number">2</span>, <span class="number">4</span>), dtype=tf.float32)</span><br><span class="line">rnn_ret = rnn(embedding_ret, initial_state=initial_state)</span><br><span class="line">print(<span class="string">&#x27;rnn ret is : \n&#x27;</span>, rnn_ret) <span class="comment"># batch_size, rnn_units</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">self_rnn</span>(<span class="params">rnn_cell, embedding, initial_state</span>):</span></span><br><span class="line">    states = initial_state</span><br><span class="line">    all_outputs = []</span><br><span class="line">    all_states = []</span><br><span class="line">    <span class="keyword">for</span> position <span class="keyword">in</span> <span class="built_in">range</span>(embedding.shape[<span class="number">1</span>]): <span class="comment"># embedding.shape[1] 对应字符串长度</span></span><br><span class="line">        inputs = embedding[: , position, : ] <span class="comment"># 取每个batch上，对应位置上的embedding值 </span></span><br><span class="line">        outputs, states = rnn_cell(inputs, states)</span><br><span class="line">        all_outputs.append(outputs)</span><br><span class="line">        all_states.append(states)</span><br><span class="line">    <span class="keyword">return</span> all_outputs[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">self_rnn_ret = self_rnn(gru_cell, embedding_ret, initial_state=initial_state)</span><br><span class="line">print(<span class="string">&#x27;self rnn ret is : \n&#x27;</span>, self_rnn_ret)</span><br></pre></td></tr></table></figure>

<pre><code>words : (2, 5)
embedding ret shape : (2, 5, 4)
rnn ret is : 
 tf.Tensor(
[[ 0.02378952  0.01149105  0.01898541  0.02086249]
 [-0.00381493  0.01658207  0.00360551  0.00680503]], shape=(2, 4), dtype=float32)
self rnn ret is : 
 tf.Tensor(
[[ 0.02378952  0.01149105  0.01898541  0.02086249]
 [-0.00381493  0.01658207  0.00360551  0.00680503]], shape=(2, 4), dtype=float32)</code></pre>
<p>RNNCell是RNN是单步的执行单元，RNN layer 的执行原理是遍历每步并将state将向后转递</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lstm_cell = tf.keras.layers.LSTMCell(<span class="number">4</span>)</span><br><span class="line">inputs = tf.ones(shape=(<span class="number">2</span>, <span class="number">3</span>), dtype=tf.float32)</span><br><span class="line">states1 = tf.zeros(shape=(<span class="number">2</span>, <span class="number">4</span>), dtype=tf.float32)</span><br><span class="line">states2 = tf.zeros(shape=(<span class="number">2</span>, <span class="number">4</span>), dtype=tf.float32)</span><br><span class="line">outpus, states = lstm_cell(inputs, (states1, states2))</span><br><span class="line">print(states)</span><br></pre></td></tr></table></figure>

<pre><code>[&lt;tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[ 0.251225  , -0.09634911,  0.13881163, -0.04482196],
       [ 0.251225  , -0.09634911,  0.13881163, -0.04482196]],
      dtype=float32)&gt;, &lt;tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[ 0.47264358, -0.22557989,  0.3101259 , -0.10946771],
       [ 0.47264358, -0.22557989,  0.3101259 , -0.10946771]],
      dtype=float32)&gt;]</code></pre>
<p>可以看出代码结果与理论是对应的，LSTM 会返回两个state，一个是$c_t$， 另一个是$h_t$</p>
<h2 id="唐诗生成器实例"><a href="#唐诗生成器实例" class="headerlink" title="唐诗生成器实例"></a>唐诗生成器实例</h2><p>古诗生成器：已知有一堆现成的古诗作为训练数据，我们的目标是生成一个可以写作古诗的模型。</p>
<p><img src="_image/task.png"></p>
<h3 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_poem</span>(<span class="params">file_name</span>):</span></span><br><span class="line">    poems = []</span><br><span class="line">    file = <span class="built_in">open</span>(file_name, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    words = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file:  <span class="comment">#every line is a poem</span></span><br><span class="line">        title, author, poem = line.strip().split(<span class="string">&quot;::&quot;</span>)  <span class="comment">#get title and poem</span></span><br><span class="line">        poem = poem.replace(<span class="string">&#x27; &#x27;</span>,<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(poem) &lt; <span class="number">10</span> <span class="keyword">or</span> <span class="built_in">len</span>(poem) &gt; <span class="number">64</span>:  <span class="comment">#filter poem</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;_&#x27;</span> <span class="keyword">in</span> poem <span class="keyword">or</span> <span class="string">&#x27;《&#x27;</span> <span class="keyword">in</span> poem <span class="keyword">or</span> <span class="string">&#x27;[&#x27;</span> <span class="keyword">in</span> poem <span class="keyword">or</span> <span class="string">&#x27;(&#x27;</span> <span class="keyword">in</span> poem <span class="keyword">or</span> <span class="string">&#x27;（&#x27;</span> <span class="keyword">in</span> poem:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># poem = &#x27;[&#x27; + poem + &#x27;]&#x27; #add start and end signs</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(poem) &gt; <span class="number">100</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        poems.append(<span class="built_in">list</span>(poem))</span><br><span class="line">        words += <span class="built_in">list</span>(poem)</span><br><span class="line">  </span><br><span class="line">    words = <span class="built_in">list</span>(<span class="built_in">set</span>(words))</span><br><span class="line">    words.sort()</span><br><span class="line">    words = [<span class="string">&#x27;[PAD]&#x27;</span>, <span class="string">&#x27;[BOS]&#x27;</span>, <span class="string">&#x27;[EOS]&#x27;</span>] + words</span><br><span class="line">  </span><br><span class="line">    word_dict = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> wid, word <span class="keyword">in</span> <span class="built_in">enumerate</span>(words):</span><br><span class="line">        word_dict[word] = wid </span><br><span class="line">    <span class="keyword">return</span> poems, words, word_dict</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_data_set</span>(<span class="params">data, maxlen=<span class="number">128</span></span>):</span></span><br><span class="line">    ret = []</span><br><span class="line">    <span class="keyword">for</span> text_list <span class="keyword">in</span> data:</span><br><span class="line">        ids = [word_dict[word] <span class="keyword">for</span> word <span class="keyword">in</span> text_list]</span><br><span class="line">        ret.append(ids)</span><br><span class="line">    <span class="keyword">return</span> tf.keras.preprocessing.sequence.pad_sequences(ret, maxlen=maxlen, padding=<span class="string">&#x27;post&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">poems, words, word_dict = read_poem(<span class="string">&#x27;data/poetryTang.txt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">vocab_number = <span class="built_in">len</span>(words) + <span class="number">1</span></span><br><span class="line">print(<span class="string">&#x27;字典大小：&#x27;</span>, <span class="built_in">str</span>(vocab_number))</span><br><span class="line"></span><br><span class="line">x_data = [[<span class="string">&#x27;[BOS]&#x27;</span>] + poem <span class="keyword">for</span> poem <span class="keyword">in</span> poems]</span><br><span class="line">y_data = [poem + [<span class="string">&#x27;[EOS]&#x27;</span>] <span class="keyword">for</span> poem <span class="keyword">in</span> poems]</span><br><span class="line"></span><br><span class="line">x_valid_data = x_data[<span class="number">0</span>:<span class="number">1000</span>]</span><br><span class="line">y_valid_data = y_data[<span class="number">0</span>:<span class="number">1000</span>]</span><br><span class="line"></span><br><span class="line">x_train_data = x_data[<span class="number">1000</span>:]</span><br><span class="line">y_train_data = y_data[<span class="number">1000</span>:]</span><br><span class="line"></span><br><span class="line">x_mini_train_data = x_train_data[<span class="number">0</span>:<span class="number">1000</span>]</span><br><span class="line">y_mini_train_data = y_train_data[<span class="number">0</span>:<span class="number">1000</span>]</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;训练集size :&#x27;</span>, <span class="built_in">len</span>(x_train_data))</span><br><span class="line">print(<span class="string">&#x27;验证集size :&#x27;</span>, <span class="built_in">len</span>(x_valid_data))</span><br><span class="line"></span><br><span class="line">x_train_dataset  = generate_data_set(x_train_data, maxlen=<span class="number">65</span>)</span><br><span class="line">y_train_dataset  = generate_data_set(y_train_data, maxlen=<span class="number">65</span>)</span><br><span class="line"></span><br><span class="line">x_valid_dataset  = generate_data_set(x_valid_data, maxlen=<span class="number">65</span>)</span><br><span class="line">y_valid_dataset  = generate_data_set(y_valid_data, maxlen=<span class="number">65</span>)</span><br><span class="line"></span><br><span class="line">x_mini_train_dataset  = generate_data_set(x_mini_train_data, maxlen=<span class="number">65</span>)</span><br><span class="line">y_mini_train_dataset  = generate_data_set(y_mini_train_data, maxlen=<span class="number">65</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># np.array(words)[x_train_dataset[0]]</span></span><br></pre></td></tr></table></figure>

<pre><code>字典大小： 6632
训练集size : 41136
验证集size : 1000</code></pre>
<h3 id="搭建模型"><a href="#搭建模型" class="headerlink" title="搭建模型"></a>搭建模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span>(<span class="params">vocab_size</span>):</span></span><br><span class="line">    <span class="built_in">input</span> = tf.keras.Input(shape=[<span class="literal">None</span>,], name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line">    embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=<span class="number">768</span>, mask_zero=<span class="literal">True</span>, name=<span class="string">&#x27;embedding_layer&#x27;</span>)</span><br><span class="line">    output = embedding(<span class="built_in">input</span>)</span><br><span class="line">    output = tf.keras.layers.Dropout(<span class="number">0.5</span>, name=<span class="string">&#x27;dropout_1&#x27;</span>)(output)</span><br><span class="line">    output = tf.keras.layers.GRU(units = <span class="number">1024</span>, return_sequences=<span class="literal">True</span>, name=<span class="string">&#x27;rnn_layer_1&#x27;</span>)(output)</span><br><span class="line">    output = tf.keras.layers.LayerNormalization(epsilon=<span class="number">1e-6</span>, name=<span class="string">&#x27;layernorm_layer_1&#x27;</span>)(output)</span><br><span class="line"></span><br><span class="line">    output = tf.keras.layers.GRU(units=<span class="number">512</span>, return_sequences=<span class="literal">True</span>, name=<span class="string">&#x27;rnn_layer_2&#x27;</span>)(output)</span><br><span class="line">    output = tf.keras.layers.LayerNormalization(epsilon=<span class="number">1e-6</span>, name=<span class="string">&#x27;layernorm_layer_2&#x27;</span>)(output)</span><br><span class="line"></span><br><span class="line">    output = tf.keras.layers.Dropout(<span class="number">0.5</span>, name=<span class="string">&#x27;dropout_2&#x27;</span>)(output)</span><br><span class="line">    output = tf.keras.layers.Dense(vocab_number, name=<span class="string">&#x27;output_layer&#x27;</span>, activation=<span class="string">&quot;softmax&quot;</span>)(output)</span><br><span class="line">    model = tf.keras.Model(inputs=<span class="built_in">input</span>, outputs=output, name=<span class="string">&quot;rnn_genrater_model&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line">model = build_model(vocab_size=vocab_number)</span><br><span class="line">model.load_weights(<span class="string">&#x27;./model_20.h5&#x27;</span>, by_name=<span class="literal">True</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;rnn_genrater_model&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
inputs (InputLayer)          [(None, None)]            0         
_________________________________________________________________
embedding_layer (Embedding)  (None, None, 768)         5093376   
_________________________________________________________________
dropout_1 (Dropout)          (None, None, 768)         0         
_________________________________________________________________
rnn_layer_1 (GRU)            (None, None, 1024)        5511168   
_________________________________________________________________
layernorm_layer_1 (LayerNorm (None, None, 1024)        2048      
_________________________________________________________________
rnn_layer_2 (GRU)            (None, None, 512)         2362368   
_________________________________________________________________
layernorm_layer_2 (LayerNorm (None, None, 512)         1024      
_________________________________________________________________
dropout_2 (Dropout)          (None, None, 512)         0         
_________________________________________________________________
output_layer (Dense)         (None, None, 6632)        3402216   
=================================================================
Total params: 16,372,200
Trainable params: 16,372,200
Non-trainable params: 0
_________________________________________________________________</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_function</span>(<span class="params">real, pred</span>):</span></span><br><span class="line">    mask = tf.math.logical_not(tf.math.equal(real, <span class="number">0</span>))</span><br><span class="line">    loss_ = loss_object(real, pred) </span><br><span class="line"></span><br><span class="line">    mask = tf.cast(mask, dtype=loss_.dtype)</span><br><span class="line">    loss_ *= mask</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean(loss_)</span><br></pre></td></tr></table></figure>

<h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(loss=loss_function, metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name=<span class="string">&#x27;train_accuracy&#x27;</span>)], optimizer=<span class="string">&#x27;adam&#x27;</span>)</span><br><span class="line">history = model.fit(x_mini_train_dataset, y_mini_train_dataset, batch_size=<span class="number">64</span>, epochs=<span class="number">1</span>, validation_data=(x_valid_dataset, y_valid_dataset))</span><br></pre></td></tr></table></figure>

<pre><code>16/16 [==============================] - 66s 4s/step - loss: 1.6746 - train_accuracy: 0.2262 - val_loss: 2.7021 - val_train_accuracy: 0.2201</code></pre>
<h3 id="查看效果"><a href="#查看效果" class="headerlink" title="查看效果"></a>查看效果</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">probs_to_word</span>(<span class="params">weights</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;probs to word&quot;&quot;&quot;</span></span><br><span class="line">    prefixSum = np.cumsum(weights) <span class="comment">#prefix sum</span></span><br><span class="line">    ratio = np.random.rand(<span class="number">1</span>)</span><br><span class="line">    index = np.searchsorted(prefixSum, ratio * prefixSum[-<span class="number">1</span>]) <span class="comment"># large margin has high possibility to be sampled</span></span><br><span class="line">    <span class="keyword">return</span> words[index[<span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_sample</span>(<span class="params">probs_to_word_fun</span>):</span></span><br><span class="line">    chars = [<span class="number">1</span>] <span class="comment"># [BOS]</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        ret = model.call(tf.constant([chars], dtype=tf.int32))</span><br><span class="line">        <span class="comment"># print(&#x27;ret:&#x27;, ret.shape)</span></span><br><span class="line">        choice_word = probs_to_word_fun(ret.numpy()[<span class="number">0</span>][-<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">if</span> choice_word == <span class="string">&#x27;[EOS]&#x27;</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        chars.append(word_dict[choice_word])</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join([words[tmp] <span class="keyword">for</span> tmp <span class="keyword">in</span> chars])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    poetry = random_sample(probs_to_word)</span><br><span class="line">    print(poetry)</span><br></pre></td></tr></table></figure>

<pre><code>[BOS]去便天峰来，百忧忘道士。争来蜀水平，独与鱼台守。雨景能相和，茵间茶不歇。
[BOS]金凤曲兮南岩嚬，彤纱碧袅幽思。深妆绿蘋含浅碧，妍姿激暎流水中。花剡馆静吟满云，台边帆挂无得闲。疏谷似云远杀人，梁禽肠断长不还。
[BOS]桃花江北平，相望未能情。咂酒穿花晚，看书归马多。寒山倚谿寺，夕水落南陂。唯有南迁客，相游高隐难。
[BOS]微雨寺门安，覆井千峰绿。僧语寄佳空，西风见人怪。
[BOS]竹坞晚凉霁，药庭头李鸣。秋花入山尽，闻道应相寻。
[BOS]秦甸数千里，风流河转流。人间不能用，山上保风流。已对秦钱酒，唯擎楚客舟。双舟无处去，但见独留留。
[BOS]昨夜风微吹落梅，新声万骑报明台。此中欲折长杨柳，到处将文更战来。
[BOS]绿杨高万在，东照复全归。太守看山远，家家觉日稀。学泉封岁醉，过水著霄稀。欲问初归计，朝朝暮复归。
[BOS]蓬蒿春日长，殷勤雨露声。未央仙府好，有弄空山荣。坐见白昼日，闲因白云城。年年见官意，洒送出林名。
[BOS]故树春堂欲画阑，预辞新熟过梨花。金毛晴烧青衫近，青绿阴园白露寒。</code></pre>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/07/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2020-07-16-%E9%80%9A%E8%BF%87Tensorflow2%E4%BD%BF%E7%94%A8Bert%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/07/16/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2020-07-16-%E9%80%9A%E8%BF%87Tensorflow2%E4%BD%BF%E7%94%A8Bert%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F/" class="post-title-link" itemprop="url">通过Tensorflow2使用Bert预训练模型的两种方式</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-07-16 21:07:00" itemprop="dateCreated datePublished" datetime="2020-07-16T21:07:00+00:00">2020-07-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>以中文Bert为例</p>
<p>下面的例子均以中文Bert预训练模型为例</p>
<h4 id="方式1：使用Tensorflow-Hub"><a href="#方式1：使用Tensorflow-Hub" class="headerlink" title="方式1：使用Tensorflow Hub"></a>方式1：使用Tensorflow Hub</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow_hub <span class="keyword">as</span> hub</span><br><span class="line"></span><br><span class="line">hub_url_or_local_path = <span class="string">&quot;https://tfhub.dev/tensorflow/bert_zh_L-12_H-768_A-12/2&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者将模型下载到本地</span></span><br><span class="line"><span class="comment"># !wget &quot;https://storage.googleapis.com/tfhub-modules/tensorflow/bert_zh_L-12_H-768_A-12/2.tar.gz&quot;</span></span><br><span class="line"><span class="comment"># !tar -xzvf 2.tar.gz -C bert_zh_L-12_H-768_A-12</span></span><br><span class="line"><span class="comment"># hub_url_or_local_path = &quot;./bert_zh_L-12_H-768_A-12&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span>():</span></span><br><span class="line">  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=<span class="string">&quot;input_word_ids&quot;</span>)</span><br><span class="line">  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=<span class="string">&quot;input_mask&quot;</span>)</span><br><span class="line">  segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=<span class="string">&quot;segment_ids&quot;</span>)</span><br><span class="line">  bert_layer = hub.KerasLayer(hub_url_or_local_path, name=<span class="string">&#x27;bert&#x27;</span>, trainable=<span class="literal">True</span>)</span><br><span class="line">  pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])</span><br><span class="line">  model = tf.keras.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=sequence_output)</span><br><span class="line">  <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">model = build_model()</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<p>使用这种方式的时候在执行build_model时bert的参数已经被加载进来了。</p>
<h4 id="方式2：使用Transformers"><a href="#方式2：使用Transformers" class="headerlink" title="方式2：使用Transformers"></a>方式2：使用Transformers</h4><p>通过transformers使用bert模型的方式不只这一种，下面的方式是我个人比较喜欢的一种方式（尽量使用Tensorflow原生方式）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TFBertMainLayer</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span>(<span class="params">cls_num</span>):</span></span><br><span class="line">    input_ids = tf.keras.layers.Input(shape=[<span class="literal">None</span>, ], dtype=tf.int32, name=<span class="string">&#x27;input_ids&#x27;</span>)</span><br><span class="line">    attention_mask = tf.keras.layers.Input(shape=[<span class="literal">None</span>, ], dtype=tf.int32, name=<span class="string">&#x27;attention_mask&#x27;</span>)</span><br><span class="line">    token_type_ids = tf.keras.layers.Input(shape=[<span class="literal">None</span>, ], dtype=tf.int32, name=<span class="string">&#x27;token_type_ids&#x27;</span>)</span><br><span class="line">    bert = TFBertMainLayer(bert_config, name=<span class="string">&#x27;bert&#x27;</span>)</span><br><span class="line">    bert.trainable = <span class="literal">True</span></span><br><span class="line">    outputs = bert(input_ids, attention_mask, token_type_ids)</span><br><span class="line">    pool = outputs[<span class="number">1</span>]</span><br><span class="line">    model = tf.keras.Model(inputs=[input_ids, attention_mask, token_type_ids], outputs=pool)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">bert_config = BertConfig.from_pretrained(<span class="string">&quot;bert-base-chinese&quot;</span>)</span><br><span class="line">model = build_model(bert_config=bert_config)</span><br><span class="line">model.load_weights(pre_train_save_file, by_name=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>使用这种方式的时候build_model时，bert的参数还没有加载，需要通过load_weigths方式将参数加载进来。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/06/24/Tensorflow2.x%E5%AE%9E%E6%88%98/Tensorflow%E5%AE%9E%E6%88%98(1)-Tensorflow%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%90%AD%E5%BB%BA%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/06/24/Tensorflow2.x%E5%AE%9E%E6%88%98/Tensorflow%E5%AE%9E%E6%88%98(1)-Tensorflow%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%90%AD%E5%BB%BA%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">Tensorflow实战(1)-Tensorflow基本介绍及搭建全连接神经网络</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-06-24 20:43:00" itemprop="dateCreated datePublished" datetime="2020-06-24T20:43:00+00:00">2020-06-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>大家好，今天是Tensorflow实战系列的第一次分享，本次分享共有3个主题：</p>
<ul>
<li>Tensorflow介绍</li>
<li>Tensorflow核心概念</li>
<li>使用Tensorflow实现手写数字识别任务</li>
</ul>
<p>由于本次分享内容以实战为主不会涉及过多理论的讲解，但是分享过程中涉及到的理论知识也会做一个快速回顾。</p>
<h2 id="Tensorflow-Introduction"><a href="#Tensorflow-Introduction" class="headerlink" title="Tensorflow Introduction"></a>Tensorflow Introduction</h2><p>Tensorflow 是由Google研发的开源软件库，它既是一个实现机器学习算法的接口，同时也是执行机器学习算法的框架，它对深度学习中常用的神经网络结构等算法进行了封装，因此开发人员可以快速的进行模型搭建。</p>
<h3 id="1、Tensorflow-发展史"><a href="#1、Tensorflow-发展史" class="headerlink" title="1、Tensorflow 发展史"></a>1、Tensorflow 发展史</h3><ul>
<li>2011 年，Google Brain内部孵化出一个项目叫做DistBelief, 它是为深度神经网络构建的一个机器学习系统，是Tensorflow的前身。</li>
<li>2015年11月，Google正式发布了Tensorflow的白皮书并开源TensorFlow 0.1 版本。</li>
<li>2017年02月，Tensorflow正式发布了1.0.0版本，同时也标志着稳定版的诞生。</li>
<li>2019年10月，TensorFlow在经历七个多月(2019年3月1日-2019年10月1日)的2.0 Alpha 版本的更新迭代后发布 2.0 正式版。</li>
</ul>
<p>通过上面的发展史我们可以看到，虽然经过了9年时间Tensorflow依然是目前最流行的深度学习框架之一。</p>
<p><img src="./_image/framework.png"></p>
<h3 id="2、Tensorflow-VS-Pytorch"><a href="#2、Tensorflow-VS-Pytorch" class="headerlink" title="2、Tensorflow VS Pytorch"></a>2、Tensorflow VS Pytorch</h3><p>上面说到Tensorflow是目前最流行的深度学习框架之一，那另一款可以和Tensorflow一较高下的深度学习框架就是-Pytorch了。Pytorch是由Facebook研发的一款开源的机器学习库，自16年发布以来发展非常迅猛。Tensorflow和Pytorch如何选择呢，我的看法是：都可以，虽然刚开始时Pytorch和Tensorflow还是差别较大的，比较Pytorch有动态图、类python的编程方式，Tensorflow则支持可视化，生产部署更加简单易用，但通过这几年的发展Pytorch和Tensorfow越来越像了，Tensorflow添加了动态图，而Pytorch也在工业部署上有了很大改善。因此在两都的选择上不必太过纠结。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">print(sys.version)</span><br></pre></td></tr></table></figure>

<pre><code>3.6.9 (default, Nov  7 2019, 10:44:02) 
[GCC 8.3.0]</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> module <span class="keyword">in</span> tf, np, mpl:</span><br><span class="line">    print(module.__name__, module.__version__)</span><br></pre></td></tr></table></figure>

<pre><code>tensorflow 2.1.0
numpy 1.18.1
matplotlib 3.2.1</code></pre>
<h2 id="Tensorflow-核心概念"><a href="#Tensorflow-核心概念" class="headerlink" title="Tensorflow 核心概念"></a>Tensorflow 核心概念</h2><h3 id="1、Tensor-张量"><a href="#1、Tensor-张量" class="headerlink" title="1、Tensor (张量)"></a>1、Tensor (张量)</h3><p>在Tensorflow中计算的数据都是以Tensor的形式来表示的。Tensor 可以把它看成是一个多维数组，并且它和NumPy中的np.arrays也非常相似。它有3个重要的属性：</p>
<ul>
<li>value </li>
<li>shape</li>
<li>dtype</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">rank_3_tensor = tf.constant([</span><br><span class="line">  [[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">   [<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]],</span><br><span class="line">  [[<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>],</span><br><span class="line">   [<span class="number">15</span>, <span class="number">16</span>, <span class="number">17</span>, <span class="number">18</span>, <span class="number">19</span>]],</span><br><span class="line">  [[<span class="number">20</span>, <span class="number">21</span>, <span class="number">22</span>, <span class="number">23</span>, <span class="number">24</span>],</span><br><span class="line">   [<span class="number">25</span>, <span class="number">26</span>, <span class="number">27</span>, <span class="number">28</span>, <span class="number">29</span>]],])</span><br><span class="line">                    </span><br><span class="line">print(rank_3_tensor)</span><br></pre></td></tr></table></figure>

<pre><code>tf.Tensor(
[[[ 0  1  2  3  4]
  [ 5  6  7  8  9]]

 [[10 11 12 13 14]
  [15 16 17 18 19]]

 [[20 21 22 23 24]
  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)</code></pre>
<p><img src="./_image/tensor.png" alt="tensor"></p>
<p>tensor的dypte和编程语言中的变量类型非常相似，只是因此模型计算过程中运算量非常大对精度和粒度的要求更高。</p>
<ul>
<li>tf.float16: 16-bit half-precision floating-point.</li>
<li>tf.float32: 32-bit single-precision floating-point.</li>
<li>tf.float64: 64-bit double-precision floating-point.</li>
<li>tf.int8: 8-bit signed integer.</li>
<li>tf.int16: 16-bit signed integer.</li>
<li>tf.int32: 32-bit signed integer.</li>
<li>tf.int64: 64-bit signed integer.</li>
<li>tf.bool: Boolean.</li>
<li>tf.string: String.</li>
</ul>
<p>更好可参考：<a target="_blank" rel="noopener" href="https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/dtypes/DType">https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/dtypes/DType</a></p>
<h3 id="2、Compute-Grapth-计算图-与Autograd-自动求导"><a href="#2、Compute-Grapth-计算图-与Autograd-自动求导" class="headerlink" title="2、Compute Grapth (计算图) 与Autograd(自动求导)"></a>2、Compute Grapth (计算图) 与Autograd(自动求导)</h3><p>计算图是一种描述计算过程的语言。图的节点由事先定义的运算构成，图的各个节点之间由张量（tensor）来连接，Tensorflow的计算过程就是张量（tensor）在节点之间从前到后的流动传输过程。另外在图上计算变量的梯度也非常容易，在使用梯度下降求解模型参数时非常方便。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">a = tf.Variable(<span class="number">3.</span>)</span><br><span class="line">b = tf.Variable(<span class="number">2.</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">    c = a + b</span><br><span class="line">    d = b + <span class="number">1</span></span><br><span class="line">    e = c * d</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;e :&#x27;</span>, e.numpy())</span><br><span class="line"></span><br><span class="line">a_gradient, b_gradient = tape.gradient(e, [a, b])</span><br><span class="line">print(<span class="string">&#x27;b_gradient : &#x27;</span>, b_gradient.numpy())</span><br><span class="line">print(<span class="string">&#x27;a_gradient : &#x27;</span>, a_gradient.numpy())</span><br></pre></td></tr></table></figure>

<pre><code>e : 15.0
b_gradient :  8.0
a_gradient :  3.0</code></pre>
<p><img src="./_image/grapth_compute.png" alt="计算图"></p>
<p>以求e关于变量b的偏导数为例，从e到b的路径有两条，将每条路径中的值相乘再将种路径的值相加即可得到最终的偏导数结果。</p>
<p>即使不了解计算图等概念也不会影响我们使用Tensorflow来完成各式各样任务，但是它可以帮忙我们了解Tensorflow的运作机制，在遇到问题时可以更合理的问题问题原因。</p>
<h2 id="模型和数据说明"><a href="#模型和数据说明" class="headerlink" title="模型和数据说明"></a>模型和数据说明</h2><p>在讲解后面的内容之前，先对之后会使用的模型和数据做一个回顾和说明。后面的例子中会搭建一个全连接的神经网络来实现对手写数字识别任务。</p>
<h3 id="数据说明"><a href="#数据说明" class="headerlink" title="数据说明"></a>数据说明</h3><p>本次分享我们主要使用的数据是 MNIST， MNIST Dataset 是一个手写数字数据集，其包含 60,000 个示例训练集和 10,000 个示例测试集，它主要用于机器视觉领域的图像分类，每个样本是28*28的灰度图片，共0-9 10个类别。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train_all, y_train_all), (x_test, y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果第一层layer的activation是relu的话，这里要做规一化</span></span><br><span class="line">x_train_all, x_test = x_train_all/<span class="number">255.0</span>, x_test/<span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在训练集中取前5000做为验证集</span></span><br><span class="line">x_valid, x_train = x_train_all[:<span class="number">5000</span>], x_train_all[<span class="number">5000</span>:]</span><br><span class="line">y_valid, y_train = y_train_all[:<span class="number">5000</span>], y_train_all[<span class="number">5000</span>:]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(x_valid.shape, y_valid.shape)</span><br><span class="line">print(x_train.shape, y_train.shape)</span><br><span class="line">print(x_test.shape, y_test.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(5000, 28, 28) (5000,)
(55000, 28, 28) (55000,)
(10000, 28, 28) (10000,)</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotImages</span>(<span class="params">images</span>):</span></span><br><span class="line">    fig, axes = plt.subplots(<span class="number">1</span>, <span class="built_in">len</span>(images), figsize=(<span class="number">5</span>,<span class="number">5</span>))</span><br><span class="line">    axes = axes.flatten()</span><br><span class="line">    <span class="keyword">for</span> img, ax <span class="keyword">in</span> <span class="built_in">zip</span>(images, axes):</span><br><span class="line">        ax.imshow(img, interpolation=<span class="string">&quot;nearest&quot;</span>, cmap=<span class="string">&quot;binary&quot;</span>)</span><br><span class="line">        ax.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plotImages(x_train[<span class="number">0</span>:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>


<p><img src="./_image/output_17_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&#x27;label ：&#x27;</span>, y_train[<span class="number">0</span>:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<pre><code>label ： [7 3 4 6 1]</code></pre>
<h3 id="全连接神经网络"><a href="#全连接神经网络" class="headerlink" title="全连接神经网络"></a>全连接神经网络</h3><p>全连接神经网络(fully connected neural network)，顾名思义，就是相邻两层之间任意两个节点之间都有连接。全连接神经网络是最为普通的一种模型（比如和CNN相比），由于是全连接，所以会有更多的权重值和连接，因此也意味着占用更多的内存和计算。</p>
<p><img src="./_image/fully_connect_model.png" alt="全连接神经网络模型"></p>
<p>全连接层的计算方式：<br><img src="./_image/fully_connect_nn.png" alt="全连接层"></p>
<p>推荐演示工具：<a target="_blank" rel="noopener" href="https://playground.tensorflow.org/">https://playground.tensorflow.org/</a></p>
<h2 id="Tensorlfow2搭建一个全连接神经网络"><a href="#Tensorlfow2搭建一个全连接神经网络" class="headerlink" title="Tensorlfow2搭建一个全连接神经网络"></a>Tensorlfow2搭建一个全连接神经网络</h2><h3 id="0、Why-Tensorflow2-X"><a href="#0、Why-Tensorflow2-X" class="headerlink" title="0、Why Tensorflow2.X"></a>0、Why Tensorflow2.X</h3><pre><code>Tensorflow1.X 版本的编程方式更像是在画一张计算图，通常构建一个模型的时候是先定义一张图，然后在图中添加计算结点，最终将这个张图拿去做计算。而2.X将计算图的构建过程隐藏在底层中了，这使得它的语法看起来更加友好也比较符合正常的编程思维。</code></pre>
<p><img src="./_image/tensorflow2.png" alt="tensorflow_keras"></p>
<p>在TF2版本中，有两种高级API，分别是Estimator和tf.keras，Estimator早在TF1版本就已经出现而tf.keras是TF2中新增加的。后面的内容主要会以tf.keras为主。</p>
<h3 id="1、定义模型结构"><a href="#1、定义模型结构" class="headerlink" title="1、定义模型结构"></a>1、定义模型结构</h3><p>**Sequential API (连续)**：Sequential API 通过model.add方法添加神经网络层，适合链式结构的神经网络。</p>
<p>**Functional API (函数式)**：Functional API 通过指定inputs和outputs，将inputs到outputs的中间计算过程做为模型计算逻辑。它可以让计算逻辑更加灵活不局限于链式这样的简单结构。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_sequential_model</span>():</span></span><br><span class="line">    model = tf.keras.Sequential(name=<span class="string">&#x27;sequential_model&#x27;</span>)</span><br><span class="line">    model.add(tf.keras.layers.Flatten(input_shape=[<span class="number">28</span>, <span class="number">28</span>], name=<span class="string">&#x27;flatten&#x27;</span>))</span><br><span class="line">    model.add(tf.keras.layers.Dense(<span class="number">300</span>, activation=<span class="string">&quot;relu&quot;</span>, name=<span class="string">&#x27;h1&#x27;</span>))</span><br><span class="line">    model.add(tf.keras.layers.Dense(<span class="number">200</span>, activation=<span class="string">&quot;relu&quot;</span>, name=<span class="string">&#x27;h2&#x27;</span>)) </span><br><span class="line">    model.add(tf.keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">&quot;relu&quot;</span>, name=<span class="string">&#x27;h3&#x27;</span>))</span><br><span class="line">    model.add(tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&quot;softmax&quot;</span>, name=<span class="string">&#x27;outputs&#x27;</span>))</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">sequential_model = generate_sequential_model()</span><br><span class="line">sequential_model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_model&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten (Flatten)            (None, 784)               0         
_________________________________________________________________
h1 (Dense)                   (None, 300)               235500    
_________________________________________________________________
h2 (Dense)                   (None, 200)               60200     
_________________________________________________________________
h3 (Dense)                   (None, 100)               20100     
_________________________________________________________________
outputs (Dense)              (None, 10)                1010      
=================================================================
Total params: 316,810
Trainable params: 316,810
Non-trainable params: 0
_________________________________________________________________</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_functional_model</span>():</span></span><br><span class="line">    inputs = tf.keras.Input(shape=[<span class="number">28</span>, <span class="number">28</span>], name=<span class="string">&#x27;inputs&#x27;</span>)</span><br><span class="line">    flatten = tf.keras.layers.Flatten(name=<span class="string">&#x27;flatten&#x27;</span>)(inputs)</span><br><span class="line">    h1 = tf.keras.layers.Dense(<span class="number">300</span>, activation=<span class="string">&quot;relu&quot;</span>, name=<span class="string">&#x27;h1&#x27;</span>)(flatten)</span><br><span class="line">    h2 = tf.keras.layers.Dense(<span class="number">200</span>, activation=<span class="string">&quot;relu&quot;</span>, name=<span class="string">&#x27;h2&#x27;</span>)(h1)</span><br><span class="line">    h3 = tf.keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">&quot;relu&quot;</span>, name=<span class="string">&#x27;h3&#x27;</span>)(h2)</span><br><span class="line">    outputs = tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&quot;softmax&quot;</span>, name=<span class="string">&#x27;outputs&#x27;</span>)(h3)</span><br><span class="line">    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=<span class="string">&quot;functional_model&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line">functioal_model = generate_functional_model()</span><br><span class="line">functioal_model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;functional_model&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
inputs (InputLayer)          [(None, 28, 28)]          0         
_________________________________________________________________
flatten (Flatten)            (None, 784)               0         
_________________________________________________________________
h1 (Dense)                   (None, 300)               235500    
_________________________________________________________________
h2 (Dense)                   (None, 200)               60200     
_________________________________________________________________
h3 (Dense)                   (None, 100)               20100     
_________________________________________________________________
outputs (Dense)              (None, 10)                1010      
=================================================================
Total params: 316,810
Trainable params: 316,810
Non-trainable params: 0
_________________________________________________________________</code></pre>
<h3 id="2、Loss-Function-损失函数"><a href="#2、Loss-Function-损失函数" class="headerlink" title="2、Loss Function (损失函数)"></a>2、Loss Function (损失函数)</h3><p>交叉熵损失：tf.keras.losses.SparseCategoricalCrossentropy，常用的适用于分类任务的Loss。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cce = tf.keras.losses.SparseCategoricalCrossentropy()</span><br><span class="line">loss = cce(</span><br><span class="line">  tf.convert_to_tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]),</span><br><span class="line">  tf.convert_to_tensor([[<span class="number">.9</span>, <span class="number">.05</span>, <span class="number">.05</span>], [<span class="number">.5</span>, <span class="number">.89</span>, <span class="number">.6</span>], [<span class="number">.05</span>, <span class="number">.01</span>, <span class="number">.94</span>]]))</span><br><span class="line">print(<span class="string">&#x27;Loss: &#x27;</span>, loss.numpy())  <span class="comment"># Loss: 0.3239</span></span><br></pre></td></tr></table></figure>

<pre><code>Loss:  0.32396814</code></pre>
<h3 id="3、Optimaizer-优化方法"><a href="#3、Optimaizer-优化方法" class="headerlink" title="3、Optimaizer (优化方法)"></a>3、Optimaizer (优化方法)</h3><pre><code>在确定了损失函数之后，我们就可以选择一个优化算法来让损失函数最小化。以SGD举例：</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">a = tf.Variable(<span class="number">3.</span>)</span><br><span class="line">b = tf.Variable(<span class="number">2.</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">    c = a + b</span><br><span class="line">    d = b + <span class="number">1</span></span><br><span class="line">    e = c * d</span><br><span class="line"></span><br><span class="line">a_gradient, b_gradient = tape.gradient(e, [a, b])</span><br><span class="line">print(<span class="string">&#x27;b_gradient : &#x27;</span>, b_gradient.numpy())</span><br><span class="line">print(<span class="string">&#x27;a_gradient : &#x27;</span>, a_gradient.numpy())</span><br><span class="line"></span><br><span class="line">sgd_optimizer.apply_gradients([(a_gradient, a), (b_gradient, b)])</span><br><span class="line">print(<span class="string">&#x27;a update: &#x27;</span>, a.numpy())</span><br><span class="line">print(<span class="string">&#x27;b update: &#x27;</span>, b.numpy())</span><br></pre></td></tr></table></figure>

<pre><code>b_gradient :  8.0
a_gradient :  3.0
a update:  2.97
b update:  1.92</code></pre>
<h3 id="4、Metrics-评价方法"><a href="#4、Metrics-评价方法" class="headerlink" title="4、Metrics (评价方法)"></a>4、Metrics (评价方法)</h3><p> 评价函数和<strong>损失函数</strong>相似，只不过评价函数的结果不会用于训练过程中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sca = tf.keras.metrics.SparseCategoricalAccuracy() </span><br><span class="line">_ = sca.update_state([<span class="number">2</span>, <span class="number">1</span>], [[<span class="number">0.02</span>, <span class="number">0.9</span>, <span class="number">0.08</span>], [<span class="number">0.05</span>, <span class="number">0.95</span>, <span class="number">0</span>]]) </span><br><span class="line">print(sca.result().numpy() )</span><br></pre></td></tr></table></figure>

<pre><code>0.5</code></pre>
<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><p>上面提到的模型结构、损失函数、优化方法是构成模型必不可少的3个要素。在集齐这些要素之后就要可以拿数据训练模型了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = functioal_model</span><br><span class="line">model.<span class="built_in">compile</span>(loss=cce, optimizer=sgd_optimizer, metrics=[sca])</span><br><span class="line">history = model.fit(x_train, y_train, epochs=<span class="number">2</span>, validation_data=(x_valid, y_valid))</span><br></pre></td></tr></table></figure>

<pre><code>Train on 55000 samples, validate on 5000 samples
Epoch 1/2
55000/55000 [==============================] - 5s 94us/sample - loss: 0.6173 - sparse_categorical_accuracy: 0.8341 - val_loss: 0.2859 - val_sparse_categorical_accuracy: 0.9198
Epoch 2/2
55000/55000 [==============================] - 5s 87us/sample - loss: 0.2660 - sparse_categorical_accuracy: 0.9233 - val_loss: 0.2109 - val_sparse_categorical_accuracy: 0.9404</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在测试集上的效果</span></span><br><span class="line">model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>

<pre><code>10000/10000 [==============================] - 0s 50us/sample - loss: 0.2149 - sparse_categorical_accuracy: 0.9377





[0.2148841947108507, 0.9377]</code></pre>
<h2 id="模型保存"><a href="#模型保存" class="headerlink" title="模型保存"></a>模型保存</h2><h3 id="通过callbacks的方式进行保存"><a href="#通过callbacks的方式进行保存" class="headerlink" title="通过callbacks的方式进行保存"></a>通过callbacks的方式进行保存</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">output_model_file = <span class="string">&quot;./mnist_model_callback.h5&quot;</span></span><br><span class="line">callbacks = [</span><br><span class="line">    tf.keras.callbacks.ModelCheckpoint(output_model_file, save_best_only=<span class="literal">True</span>, save_weights_only=<span class="literal">False</span>)</span><br><span class="line">]</span><br><span class="line">history = model.fit(x_train, y_train, epochs=<span class="number">2</span>, validation_data=(x_valid, y_valid), callbacks=callbacks)</span><br></pre></td></tr></table></figure>

<pre><code>Train on 55000 samples, validate on 5000 samples
Epoch 1/2
55000/55000 [==============================] - 5s 90us/sample - loss: 0.2079 - sparse_categorical_accuracy: 0.9392 - val_loss: 0.1790 - val_sparse_categorical_accuracy: 0.9520
Epoch 2/2
55000/55000 [==============================] - 5s 89us/sample - loss: 0.1709 - sparse_categorical_accuracy: 0.9506 - val_loss: 0.1563 - val_sparse_categorical_accuracy: 0.9576</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">&#x27;训练后的模型参数：&#x27;</span>, model.variables[<span class="number">0</span>].numpy()[<span class="number">0</span>, :<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<pre><code>训练后的模型参数： [ 0.01215426 -0.05889301  0.04321195  0.05594952 -0.00950153]</code></pre>
<h3 id="保存成SavedModel"><a href="#保存成SavedModel" class="headerlink" title="保存成SavedModel"></a>保存成SavedModel</h3><p>在使用TensorFlow Serving时，会用到这种格式的模型，模型目录结构如下所示：</p>
<ul>
<li>assets是一个可选目录，用于存放预测时的辅助文档信息；</li>
<li>variables保存的变量信息；</li>
<li>saved_model.pb或saved_model.pbtxt存放MetaGraphDef，存储训练预测模型的程序逻辑</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">saved_model_file = <span class="string">&quot;mnist_model_saved_model&quot;</span></span><br><span class="line">model.save(saved_model_file)</span><br></pre></td></tr></table></figure>

<pre><code>WARNING:tensorflow:From /home/hwyang/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
INFO:tensorflow:Assets written to: mnist_model_saved_model/assets</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型保存的输入输入格式</span></span><br><span class="line">!saved_model_cli show --<span class="built_in">dir</span> ./mnist_model_saved_model --tag_set serve --signature_def serving_default</span><br></pre></td></tr></table></figure>

<pre><code>2020-06-24 11:13:37.498139: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library &#39;libnvinfer.so.6&#39;; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-06-24 11:13:37.498235: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library &#39;libnvinfer_plugin.so.6&#39;; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-06-24 11:13:37.498296: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
The given SavedModel SignatureDef contains the following input(s):
  inputs[&#39;inputs&#39;] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 28, 28)
      name: serving_default_inputs:0
The given SavedModel SignatureDef contains the following output(s):
  outputs[&#39;outputs&#39;] tensor_info:
      dtype: DT_FLOAT
      shape: (-1, 10)
      name: StatefulPartitionedCall:0
Method name is: tensorflow/serving/predict</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用模型</span></span><br><span class="line">!saved_model_cli run --<span class="built_in">dir</span> ./mnist_model_saved_model\</span><br><span class="line">    --tag_set serve --signature_def serving_default \</span><br><span class="line">    --input_exprs <span class="string">&#x27;inputs=np.ones((2, 28, 28))&#x27;</span></span><br></pre></td></tr></table></figure>

<pre><code>2020-06-24 11:13:39.641330: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library &#39;libnvinfer.so.6&#39;; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-06-24 11:13:39.641450: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library &#39;libnvinfer_plugin.so.6&#39;; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-06-24 11:13:39.641460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-06-24 11:13:40.425721: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library &#39;libcuda.so.1&#39;; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-06-24 11:13:40.425767: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-06-24 11:13:40.425785: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (work-computer): /proc/driver/nvidia/version does not exist
2020-06-24 11:13:40.426013: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-06-24 11:13:40.433525: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1799995000 Hz
2020-06-24 11:13:40.435146: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x402f9a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-06-24 11:13:40.435196: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /home/hwyang/.local/lib/python3.6/site-packages/tensorflow_core/python/tools/saved_model_cli.py:420: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.
Result for output key outputs:
[[6.3519548e-07 4.2883544e-11 3.6132155e-04 3.7582448e-01 7.1212423e-15
  1.1317922e-03 1.6414268e-12 1.1638527e-12 6.2268174e-01 2.5810540e-10]
 [6.3519548e-07 4.2883544e-11 3.6132155e-04 3.7582448e-01 7.1212423e-15
  1.1317922e-03 1.6414268e-12 1.1638527e-12 6.2268174e-01 2.5810540e-10]]</code></pre>
<h3 id="两种保存方式的使用场景"><a href="#两种保存方式的使用场景" class="headerlink" title="两种保存方式的使用场景"></a>两种保存方式的使用场景</h3><p>1、在需要间断的训练模型时使用callbacks的方式更加合适，例如模型运行中被意外中断了就可以通过callbacks过程中保存的模型快速恢复之前的训练状态。</p>
<p>2、而当我们要部署模型时使用SavedModel可以将模型快速的部署tensorflow serving中。</p>
<h2 id="模型加载"><a href="#模型加载" class="headerlink" title="模型加载"></a>模型加载</h2><p>1、只加载参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model_only_weiths = generate_functional_model()</span><br><span class="line">print(<span class="string">&#x27;加载前的参数值：&#x27;</span>, model_only_weiths.variables[<span class="number">0</span>].numpy()[<span class="number">0</span>, :<span class="number">5</span>])</span><br><span class="line">model_only_weiths.load_weights(output_model_file)</span><br><span class="line">print(<span class="string">&#x27;加载后的参数值：&#x27;</span>, model_only_weiths.variables[<span class="number">0</span>].numpy()[<span class="number">0</span>, :<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<pre><code>加载前的参数值： [-0.0438241   0.07230127 -0.00713674 -0.06280634  0.01845549]
加载后的参数值： [ 0.01215426 -0.05889301  0.04321195  0.05594952 -0.00950153]</code></pre>
<p>2、加载模型结构和参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model_weithts_and_model = tf.keras.models.load_model(output_model_file)</span><br><span class="line">print(<span class="string">&#x27;加载后的参数值：&#x27;</span>, model_weithts_and_model.variables[<span class="number">0</span>].numpy()[<span class="number">0</span>, :<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<pre><code>加载后的参数值： [ 0.01215426 -0.05889301  0.04321195  0.05594952 -0.00950153]</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打印模型结构</span></span><br><span class="line">model_weithts_and_model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;functional_model&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
inputs (InputLayer)          [(None, 28, 28)]          0         
_________________________________________________________________
flatten (Flatten)            (None, 784)               0         
_________________________________________________________________
h1 (Dense)                   (None, 300)               235500    
_________________________________________________________________
h2 (Dense)                   (None, 200)               60200     
_________________________________________________________________
h3 (Dense)                   (None, 100)               20100     
_________________________________________________________________
outputs (Dense)              (None, 10)                1010      
=================================================================
Total params: 316,810
Trainable params: 316,810
Non-trainable params: 0
_________________________________________________________________</code></pre>
<h2 id="完整的图片分类任务实例"><a href="#完整的图片分类任务实例" class="headerlink" title="完整的图片分类任务实例"></a>完整的图片分类任务实例</h2><p>1、加载数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tf.keras.datasets.fashion_mnist</span></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train_all, y_train_all), (x_test, y_test) = mnist.load_data()</span><br><span class="line">print(<span class="built_in">type</span>(x_train_all), <span class="built_in">type</span>(y_train_all))</span><br><span class="line"><span class="comment"># 如果第一层layer的activation是relu的话，这里要做规一化</span></span><br><span class="line">x_train_all, x_test = x_train_all/<span class="number">255.0</span>, x_test/<span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">x_valid, x_train = x_train_all[:<span class="number">5000</span>], x_train_all[<span class="number">5000</span>:]</span><br><span class="line">y_valid, y_train = y_train_all[:<span class="number">5000</span>], y_train_all[<span class="number">5000</span>:]</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;numpy.ndarray&#39;&gt; &lt;class &#39;numpy.ndarray&#39;&gt;</code></pre>
<p>2、定义模型，forward时的计算（神经网络结构）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mnist_model = tf.keras.Sequential()</span><br><span class="line">mnist_model.add(tf.keras.layers.Flatten(input_shape=[<span class="number">28</span>, <span class="number">28</span>]))</span><br><span class="line"><span class="comment"># 下面的activation 如果是relu的话，那x一定要做规一化即除上255，如果是sigmoid的话就不会有问题</span></span><br><span class="line">mnist_model.add(tf.keras.layers.Dense(<span class="number">300</span>, activation=<span class="string">&quot;relu&quot;</span>)) </span><br><span class="line">mnist_model.add(tf.keras.layers.Dense(<span class="number">200</span>, activation=<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">mnist_model.add(tf.keras.layers.Dense(<span class="number">100</span>, activation=<span class="string">&quot;relu&quot;</span>))</span><br><span class="line">mnist_model.add(tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&quot;softmax&quot;</span>))</span><br></pre></td></tr></table></figure>

<p>3、定义损失函数，并选择优化器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mnist_model.<span class="built_in">compile</span>(loss=<span class="string">&quot;sparse_categorical_crossentropy&quot;</span>, </span><br><span class="line">             optimizer=<span class="string">&quot;sgd&quot;</span>, </span><br><span class="line">             metrics=[<span class="string">&quot;accuracy&quot;</span>])</span><br></pre></td></tr></table></figure>

<p>4、迭代的对数据进行模型训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">history = mnist_model.fit(x_train, y_train, epochs=<span class="number">10</span>, validation_data=(x_valid, y_valid))</span><br></pre></td></tr></table></figure>

<pre><code>Train on 55000 samples, validate on 5000 samples
Epoch 1/10
55000/55000 [==============================] - 5s 93us/sample - loss: 0.6206 - accuracy: 0.8366 - val_loss: 0.2858 - val_accuracy: 0.9184
Epoch 2/10
55000/55000 [==============================] - 5s 97us/sample - loss: 0.2665 - accuracy: 0.9234 - val_loss: 0.2190 - val_accuracy: 0.9372
Epoch 3/10
55000/55000 [==============================] - 5s 93us/sample - loss: 0.2078 - accuracy: 0.9398 - val_loss: 0.1702 - val_accuracy: 0.9504
Epoch 4/10
55000/55000 [==============================] - 5s 93us/sample - loss: 0.1704 - accuracy: 0.9508 - val_loss: 0.1489 - val_accuracy: 0.9592
Epoch 5/10
55000/55000 [==============================] - 5s 97us/sample - loss: 0.1436 - accuracy: 0.9584 - val_loss: 0.1306 - val_accuracy: 0.9626
Epoch 6/10
55000/55000 [==============================] - 5s 97us/sample - loss: 0.1242 - accuracy: 0.9647 - val_loss: 0.1179 - val_accuracy: 0.9686
Epoch 7/10
55000/55000 [==============================] - 5s 87us/sample - loss: 0.1082 - accuracy: 0.9687 - val_loss: 0.1086 - val_accuracy: 0.9696
Epoch 8/10
55000/55000 [==============================] - 5s 90us/sample - loss: 0.0958 - accuracy: 0.9727 - val_loss: 0.1006 - val_accuracy: 0.9708
Epoch 9/10
55000/55000 [==============================] - 5s 99us/sample - loss: 0.0860 - accuracy: 0.9751 - val_loss: 0.0964 - val_accuracy: 0.9730
Epoch 10/10
55000/55000 [==============================] - 5s 96us/sample - loss: 0.0768 - accuracy: 0.9784 - val_loss: 0.0865 - val_accuracy: 0.9764</code></pre>
<p>5、在测试集上对模型进行评估</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_learning_curves</span>(<span class="params">history</span>):</span></span><br><span class="line">    pd.DataFrame(history.history).plot(figsize=(<span class="number">8</span>, <span class="number">5</span>))</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line">    plt.gca().set_ylim(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">plot_learning_curves(history)</span><br></pre></td></tr></table></figure>


<p><img src="./_image/output_63_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss, acc = mnist_model.evaluate(x_test, y_test)</span><br><span class="line">print(loss, acc)</span><br></pre></td></tr></table></figure>

<pre><code>10000/10000 [==============================] - 1s 54us/sample - loss: 0.0923 - accuracy: 0.9716
0.09230228984989226 0.9716</code></pre>
<h2 id="Tensorflow-Keras-Custom"><a href="#Tensorflow-Keras-Custom" class="headerlink" title="Tensorflow Keras - Custom"></a>Tensorflow Keras - Custom</h2><p>在之前构建模型时使用的都是Tensorflow已经封装好的方法，下面通过实例来展示如何封装自己的计算方法。</p>
<p>1、Custom Layer (自定义层)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomizedDenseLayer</span>(<span class="params">tf.keras.layers.Layer</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, units, activation=<span class="literal">None</span>, **kwargs</span>):</span></span><br><span class="line">        self.units = units</span><br><span class="line">        self.activation = tf.keras.layers.Activation(activation)</span><br><span class="line">        <span class="built_in">super</span>(CustomizedDenseLayer, self).__init__(**kwargs)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">self, input_shape</span>):</span></span><br><span class="line">        <span class="comment"># 构建所需要的参数</span></span><br><span class="line">        self.kernel = self.add_weight(name=<span class="string">&quot;kernel&quot;</span>,</span><br><span class="line">                                      shape=(input_shape[<span class="number">1</span>], self.units),</span><br><span class="line">                                      initializer=<span class="string">&quot;uniform&quot;</span>,</span><br><span class="line">                                      dtype=tf.float32,</span><br><span class="line">                                      trainable=<span class="literal">True</span>)</span><br><span class="line">        self.bias = self.add_weight(name=<span class="string">&quot;bias&quot;</span>, shape=(self.units, ),</span><br><span class="line">                                   initializer = <span class="string">&quot;zeros&quot;</span>,</span><br><span class="line">                                   dtype=tf.float32,</span><br><span class="line">                                   trainable=<span class="literal">True</span>)</span><br><span class="line">        <span class="built_in">super</span>(CustomizedDenseLayer, self).build(input_shape)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># 正向计算</span></span><br><span class="line">        <span class="keyword">return</span> self.activation(x @ self.kernel + self.bias)</span><br></pre></td></tr></table></figure>

<p>2、Custom Model (自定义模型)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CustomizedModel</span>(<span class="params">tf.keras.Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(CustomizedModel, self).__init__(**kwargs)</span><br><span class="line">        self.flatten = tf.keras.layers.Flatten()</span><br><span class="line">        self.h1 = CustomizedDenseLayer(units=<span class="number">300</span>, activation=<span class="string">&quot;relu&quot;</span>, name=<span class="string">&#x27;custom_h1&#x27;</span>)</span><br><span class="line">        self.h2 = CustomizedDenseLayer(units=<span class="number">200</span>, activation=<span class="string">&quot;relu&quot;</span>, name=<span class="string">&#x27;custom_h2&#x27;</span>)</span><br><span class="line">        self.h3 = CustomizedDenseLayer(units=<span class="number">100</span>, activation=<span class="string">&quot;relu&quot;</span>, name=<span class="string">&#x27;custom_h3&#x27;</span>)</span><br><span class="line">        self.output_layer = tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&quot;softmax&quot;</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, <span class="built_in">input</span></span>):</span></span><br><span class="line">        ret = self.flatten(<span class="built_in">input</span>)</span><br><span class="line">        ret = self.h1(ret)</span><br><span class="line">        ret = self.h2(ret)</span><br><span class="line">        ret = self.h3(ret)</span><br><span class="line">        <span class="keyword">return</span> self.output_layer(ret)</span><br><span class="line">    </span><br><span class="line">custom_model = CustomizedModel()</span><br><span class="line">custom_model.build(input_shape=(<span class="literal">None</span>, <span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">custom_model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;customized_model&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten_1 (Flatten)          multiple                  0         
_________________________________________________________________
custom_h1 (CustomizedDenseLa multiple                  235500    
_________________________________________________________________
custom_h2 (CustomizedDenseLa multiple                  60200     
_________________________________________________________________
custom_h3 (CustomizedDenseLa multiple                  20100     
_________________________________________________________________
dense_4 (Dense)              multiple                  1010      
=================================================================
Total params: 316,810
Trainable params: 316,810
Non-trainable params: 0
_________________________________________________________________</code></pre>
<p>3、Custom Train (自定义训练过程)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">custom_fit</span>(<span class="params">model, x_train, y_train, x_valid, y_valid, epochs=<span class="number">1</span>, batch_size=<span class="number">1</span></span>):</span></span><br><span class="line">    steps_per_epoch = <span class="built_in">len</span>(x_train) // batch_size</span><br><span class="line">    </span><br><span class="line">    optimizer = tf.keras.optimizers.SGD()</span><br><span class="line">    train_metric = tf.keras.metrics.SparseCategoricalAccuracy()</span><br><span class="line">    valid_metric = tf.keras.metrics.SparseCategoricalAccuracy()</span><br><span class="line">    loss_obj = tf.keras.losses.SparseCategoricalCrossentropy()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">random_batch</span>(<span class="params">x, y, batch_size=batch_size</span>):</span></span><br><span class="line">        idx = np.random.randint(<span class="number">0</span>, <span class="built_in">len</span>(x_train), size=batch_size)</span><br><span class="line">        <span class="keyword">return</span> x[idx], y[idx]</span><br><span class="line"></span><br><span class="line">    print(<span class="string">&quot;steps_per_epoch is: &quot;</span> , steps_per_epoch)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        train_metric.reset_states()</span><br><span class="line">        valid_metric.reset_states()</span><br><span class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(steps_per_epoch):</span><br><span class="line">            x_batch, y_batch = random_batch(x_train, y_train, batch_size)</span><br><span class="line">            <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">                y_pred = model(x_batch)</span><br><span class="line">                loss = loss_obj(y_batch, y_pred)</span><br><span class="line">            grads = tape.gradient(loss, model.variables)</span><br><span class="line">            optimizer.apply_gradients(<span class="built_in">zip</span>(grads, model.variables))</span><br><span class="line">            train_metric(y_batch, y_pred)</span><br><span class="line">            <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                print(<span class="string">&quot;\rEpoch&quot;</span>, epoch,<span class="string">&quot; train loss: &quot;</span>,  loss.numpy(), <span class="string">&quot; train mse: &quot;</span>, train_metric.result().numpy())</span><br><span class="line">        y_valid_pred = model(x_valid)</span><br><span class="line">        valid_metric(y_valid, y_valid_pred)</span><br><span class="line">        valid_loss = loss_obj(y_valid, y_valid_pred)</span><br><span class="line">        print(<span class="string">&quot;\t&quot;</span>, <span class="string">&quot;valid mse: &quot;</span>, valid_metric.result().numpy())</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">custom_fit(model=custom_model, x_train=x_train, y_train=y_train, x_valid=x_valid, y_valid=y_valid, batch_size=<span class="number">64</span>, epochs=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<pre><code>steps_per_epoch is:  859
WARNING:tensorflow:Layer customized_model is casting an input tensor from dtype float64 to the layer&#39;s dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it&#39;s dtype defaults to floatx.

If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.

To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx(&#39;float64&#39;)`. To change just this layer, pass dtype=&#39;float64&#39; to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.

Epoch 0  train loss:  2.3038578  train mse:  0.1875
Epoch 0  train loss:  2.280334  train mse:  0.21395421
Epoch 0  train loss:  2.2446647  train mse:  0.31584266
Epoch 0  train loss:  2.1839218  train mse:  0.3867317
Epoch 0  train loss:  2.092816  train mse:  0.42627805
Epoch 0  train loss:  1.8289787  train mse:  0.4548715
Epoch 0  train loss:  1.4188151  train mse:  0.48367304
Epoch 0  train loss:  1.1096661  train mse:  0.51466656
Epoch 0  train loss:  0.912598  train mse:  0.5451389
     valid mse:  0.8054
Epoch 1  train loss:  0.86221695  train mse:  0.8125
Epoch 1  train loss:  0.7114984  train mse:  0.80522895
Epoch 1  train loss:  0.5244288  train mse:  0.8143657
Epoch 1  train loss:  0.4718449  train mse:  0.82340115
Epoch 1  train loss:  0.44886717  train mse:  0.8302681
Epoch 1  train loss:  0.49274105  train mse:  0.8369199
Epoch 1  train loss:  0.3548026  train mse:  0.8425801
Epoch 1  train loss:  0.5724619  train mse:  0.8459567
Epoch 1  train loss:  0.34557572  train mse:  0.8497581
     valid mse:  0.8914</code></pre>
<p><a target="_blank" rel="noopener" href="https://playground.tensorflow.org/">https://playground.tensorflow.org/</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/05/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2020-05-09-Transformers%E7%9A%84%E4%B8%80%E4%BA%9B%E8%BF%B7%E6%80%9D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/09/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2020-05-09-Transformers%E7%9A%84%E4%B8%80%E4%BA%9B%E8%BF%B7%E6%80%9D/" class="post-title-link" itemprop="url">Transformers的一些迷思</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-05-09 21:07:00" itemprop="dateCreated datePublished" datetime="2020-05-09T21:07:00+00:00">2020-05-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h4 id="通过from-pretrained缓存的模型在哪"><a href="#通过from-pretrained缓存的模型在哪" class="headerlink" title="通过from_pretrained缓存的模型在哪"></a>通过from_pretrained缓存的模型在哪</h4><p> 如果调用from_pretrained方法时指定了cache_dir 则保存到cache_dir，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cache_dir = kwargs.pop(<span class="string">&quot;cache_dir&quot;</span>, <span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

<p>如果没指定则去通过系统环境变量寻找（”PYTORCH_TRANSFORMERS_CACHE””, “PYTORCH_PRETRAINED_BERT_CACHE”）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.getenv(<span class="string">&quot;PYTORCH_TRANSFORMERS_CACHE&quot;</span>, os.getenv(<span class="string">&quot;PYTORCH_PRETRAINED_BERT_CACHE&quot;</span>, default_cache_path))</span><br></pre></td></tr></table></figure>

<p>如果还没找到则设置为pytorch_home下的transformers目录下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.hub <span class="keyword">import</span> _get_torch_home</span><br><span class="line">torch_cache_home = _get_torch_home()</span><br><span class="line">os.path.join(torch_cache_home, <span class="string">&quot;transformers&quot;</span>)</span><br></pre></td></tr></table></figure>



<h4 id="from-pretrained方法是如何加载模型的"><a href="#from-pretrained方法是如何加载模型的" class="headerlink" title="from_pretrained方法是如何加载模型的"></a>from_pretrained方法是如何加载模型的</h4><p>首先判断是否在pretrained_model_archive_map中，然后判断是否为目录或文件，如果都不是则默认为hf_bucket_url</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://s3.amazonaws.com/models.huggingface.co/bert/&#123;pretrained_model_name_or_path&#125;/&#123;pytorch_model.<span class="built_in">bin</span>/tf_model.h5&#125;</span><br></pre></td></tr></table></figure>

<p>pytorch_model.bin或tf_model.h5 通过from_tf判断</p>
<h4 id="不同模型实现from-pretrained的方式"><a href="#不同模型实现from-pretrained的方式" class="headerlink" title="不同模型实现from_pretrained的方式"></a>不同模型实现from_pretrained的方式</h4><p>from_pretrained 的根据不同 cls 来实现加载不同模型的差异， 以bert为例， cls -&gt; BertPreTrainedModel；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BertPreTrainedModel</span>(<span class="params">PreTrainedModel</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; An abstract class to handle weights initialization and</span></span><br><span class="line"><span class="string">        a simple interface for downloading and loading pretrained models.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    config_class = BertConfig</span><br><span class="line">    pretrained_model_archive_map = BERT_PRETRAINED_MODEL_ARCHIVE_MAP</span><br><span class="line">    load_tf_weights = load_tf_weights_in_bert</span><br><span class="line">    base_model_prefix = <span class="string">&quot;bert&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_weights</span>(<span class="params">self, module</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; Initialize the weights &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(module, (nn.Linear, nn.Embedding)):</span><br><span class="line">            <span class="comment"># Slightly different from the TF version which uses truncated_normal for initialization</span></span><br><span class="line">            <span class="comment"># cf https://github.com/pytorch/pytorch/pull/5617</span></span><br><span class="line">            module.weight.data.normal_(mean=<span class="number">0.0</span>, std=self.config.initializer_range)</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(module, BertLayerNorm):</span><br><span class="line">            module.bias.data.zero_()</span><br><span class="line">            module.weight.data.fill_(<span class="number">1.0</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(module, nn.Linear) <span class="keyword">and</span> module.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            module.bias.data.zero_()</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/03/02/%E5%85%B6%E5%AE%83/2020-03-02-%E5%9F%BA%E4%BA%8Enginx%E7%9A%84acme%E5%85%8D%E8%B4%B9%E8%AF%81%E4%B9%A6%E6%96%B9%E6%A1%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/03/02/%E5%85%B6%E5%AE%83/2020-03-02-%E5%9F%BA%E4%BA%8Enginx%E7%9A%84acme%E5%85%8D%E8%B4%B9%E8%AF%81%E4%B9%A6%E6%96%B9%E6%A1%88/" class="post-title-link" itemprop="url">2020-03-02-基于nginx的acme免费证书方案</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-02 17:36:15" itemprop="dateCreated datePublished" datetime="2020-03-02T17:36:15+00:00">2020-03-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/web/" itemprop="url" rel="index"><span itemprop="name">web</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>为了保护用户信息使网站更加安全，需要给网站添加https协议。搭建一个https网站的前提是要先拥有一个<strong>证书</strong>，当然一般的证书是需要收费，文本提供一个免费的解决方案。</p>
<p>我们使用的github上开源的免费证书工具ACME.SH，网站地址：<a target="_blank" rel="noopener" href="https://github.com/acmesh-official/acme.sh%EF%BC%8C">https://github.com/acmesh-official/acme.sh，</a></p>
<p>在其github主页上已经有了一些很好的入门说明。这里根据实际情况进行操作。</p>
<h3 id="依赖安装"><a href="#依赖安装" class="headerlink" title="依赖安装"></a>依赖安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install cron socat -y</span><br></pre></td></tr></table></figure>




<h3 id="安装ACME-sh"><a href="#安装ACME-sh" class="headerlink" title="安装ACME.sh"></a>安装ACME.sh</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl https://get.acme.sh | sh </span><br></pre></td></tr></table></figure>

<p>安装成功后会提示<code>Install success!</code>，这个命令会将acme命令写到<code>batchrc里</code>，为了方便使用需要 ：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc </span><br></pre></td></tr></table></figure>



<h3 id="申请证书"><a href="#申请证书" class="headerlink" title="申请证书"></a>申请证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">acme.sh --issue -d example.com --standalone</span><br></pre></td></tr></table></figure>

<p> 生成的证书被放在 <code>/root/.acme.sh/</code></p>
<h3 id="复制证书到nginx"><a href="#复制证书到nginx" class="headerlink" title="复制证书到nginx"></a>复制证书到nginx</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">acme.sh --installcert -d freegoooovideos.ml \</span><br><span class="line">        --key-file /etc/nginx/ssl/freegoooovideos.key \</span><br><span class="line">        --fullchain-file /etc/nginx/ssl/fullchain.cer \</span><br><span class="line">        --reloadcmd &quot;systemctl force-reload nginx.service&quot;  #或sudo service nginx force-reload</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p> <code>reloadcmd</code> 会记住让nginx重新加载的方式 ，这样证书更新的时候就可以让你nginx重新加载了。</p>
<p>这个命令不只是复制，它会把信息记录到本地中（<code>.acme/example.com/example.com.conf</code>），这样在更新证书的时候会自动将文件复制到容器中，并让其重新加载配置。</p>
<p>附：nginx的配置文件（/etc/nginx/nginx.conf 默认位置）</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">user</span>  nginx;</span><br><span class="line"><span class="attribute">worker_processes</span>  <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="attribute">error_log</span>  /var/log/nginx/error.log <span class="literal">warn</span>;</span><br><span class="line"><span class="attribute">pid</span>        /var/run/nginx.pid;</span><br><span class="line"></span><br><span class="line"><span class="section">events</span> &#123;</span><br><span class="line">    <span class="attribute">worker_connections</span>  <span class="number">1024</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">  <span class="attribute">map</span> $http_upgrade $connection_upgrade &#123;</span><br><span class="line">    <span class="attribute">default</span> upgrade;</span><br><span class="line">    &#x27;&#x27; close;</span><br><span class="line">  &#125;</span><br><span class="line">  server&#123;</span><br><span class="line">    <span class="attribute">listen</span> <span class="number">443</span> ssl;</span><br><span class="line">    <span class="attribute">ssl</span> <span class="literal">on</span>;</span><br><span class="line">    <span class="attribute">proxy_redirect</span> <span class="literal">off</span>;</span><br><span class="line">    <span class="attribute">ssl_certificate</span>       /etc/nginx/ssl/fullchain.cer;</span><br><span class="line">    ssl_certificate_key   /etc/nginx/ssl/&#123;example&#125;.key;</span><br><span class="line">    <span class="attribute">ssl_protocols</span>         TLSv1 TLSv1.<span class="number">1</span> TLSv1.<span class="number">2</span>;</span><br><span class="line">    <span class="attribute">ssl_ciphers</span>           HIGH:!aNULL:!MD5;</span><br><span class="line">    server_name           &#123;exanoke.com&#125;;</span><br><span class="line">    <span class="attribute">location</span> /freevideos &#123;</span><br><span class="line">      <span class="attribute">access_log</span> /var/log/nginx/access.log;</span><br><span class="line">      <span class="attribute">proxy_pass</span> http://127.0.0.1:4433;</span><br><span class="line">      <span class="attribute">proxy_http_version</span> <span class="number">1</span>.<span class="number">1</span>;</span><br><span class="line">      <span class="attribute">proxy_set_header</span> Upgrade $http_upgrade;</span><br><span class="line">      <span class="attribute">proxy_set_header</span> Connection $connection_upgrade;</span><br><span class="line">      <span class="attribute">proxy_set_header</span> Host $host;</span><br><span class="line">      <span class="attribute">proxy_set_header</span> X-Real-IP $remote_addr;</span><br><span class="line">      <span class="attribute">proxy_set_header</span> X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>









      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/02/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2020-02-20-Albert%E5%9C%A8Bert%E5%9F%BA%E7%A1%80%E4%B8%8A%E7%9A%84%E5%87%A0%E7%82%B9%E6%94%B9%E8%BF%9B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/02/20/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2020-02-20-Albert%E5%9C%A8Bert%E5%9F%BA%E7%A1%80%E4%B8%8A%E7%9A%84%E5%87%A0%E7%82%B9%E6%94%B9%E8%BF%9B/" class="post-title-link" itemprop="url">Albert在Bert基础上的几点改进</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-20 21:07:00" itemprop="dateCreated datePublished" datetime="2020-02-20T21:07:00+00:00">2020-02-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="减少参数"><a href="#减少参数" class="headerlink" title="减少参数"></a>减少参数</h3><ol>
<li>减少Embeding参数 ，用两层替代之前的一层，参数从原来的V * H 变成 V * E + E * H ， 这个E &lt;&lt; H</li>
<li>共享Block参数</li>
</ol>
<p>​    这样做的好处是，将参数减少，进而增加模型的深度和宽度来提升模型效果，但同时带来了计算量的增加（大概3倍）</p>
<p><img src="_image/image-20200220210854958.png" alt="image-20190717212146770"></p>
<h3 id="改进训练任务"><a href="#改进训练任务" class="headerlink" title="改进训练任务"></a>改进训练任务</h3><p>通过实验表示，Next Sentence Predict 任务太过简单，使用 Reverce 的方式会更好；</p>
<h3 id="去掉Dropout"><a href="#去掉Dropout" class="headerlink" title="去掉Dropout"></a>去掉Dropout</h3><p>Dropout实际的操作是防止过拟合，但对于无监督学习来说，训练语料是很多的不会有过拟合的问题，使用Dropout反而会增加内存的使用（会有一些缓存），去掉Dropout会有0.3的性能提升</p>
<h3 id="增加训练数据"><a href="#增加训练数据" class="headerlink" title="增加训练数据"></a>增加训练数据</h3><p>这个就没啥说的了</p>
<p>最重要的一点还是减少参数增加模型的深度和宽度带来的</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="hwyoung"
      src="/avatar.png">
  <p class="site-author-name" itemprop="name">hwyoung</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">77</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">hwyoung</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
