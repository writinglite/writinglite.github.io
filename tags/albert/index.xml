<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>albert on Writing Lite</title><link>/tags/albert.html</link><description>Recent content in albert on Writing Lite</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Thu, 20 Feb 2020 21:07:00 +0000</lastBuildDate><atom:link href="/tags/albert/index.xml" rel="self" type="application/rss+xml"/><item><title>Albert在Bert基础上的几点改进</title><link>/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2020-02-20-albert%E5%9C%A8bert%E5%9F%BA%E7%A1%80%E4%B8%8A%E7%9A%84%E5%87%A0%E7%82%B9%E6%94%B9%E8%BF%9B.html</link><pubDate>Thu, 20 Feb 2020 21:07:00 +0000</pubDate><guid>/post/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/2020-02-20-albert%E5%9C%A8bert%E5%9F%BA%E7%A1%80%E4%B8%8A%E7%9A%84%E5%87%A0%E7%82%B9%E6%94%B9%E8%BF%9B.html</guid><description>减少参数 减少Embeding参数 ，用两层替代之前的一层，参数从原来的V * H 变成 V * E + E * H ， 这个E &amp;laquo; H 共享Block参数 ​ 这样做的好处是，将参数减少，进而增加模型的深度和宽度来提升模型效果，但同时带来了计算量的增加（大概3倍）
改进训练任务 通过实验表示，Next Sentence Predict 任务太过简单，使用 Reverce 的方式会更好；
去掉Dropout Dropout实际的操作是防止过拟合，但对于无监督学习来说，训练语料是很多的不会有过拟合的问题，使用Dropout反而会增加内存的使用（会有一些缓存），去掉Dropout会有0.3的性能提升
增加训练数据 这个就没啥说的了
最重要的一点还是减少参数增加模型的深度和宽度带来的</description></item></channel></rss>