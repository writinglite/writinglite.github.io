<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>tensorflow hub on Writing Lite</title><link>/tags/tensorflow-hub.html</link><description>Recent content in tensorflow hub on Writing Lite</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Thu, 16 Jul 2020 21:07:00 +0000</lastBuildDate><atom:link href="/tags/tensorflow-hub/index.xml" rel="self" type="application/rss+xml"/><item><title>通过Tensorflow2使用Bert预训练模型的两种方式</title><link>/post/deep-learning/2020-07-16-%E9%80%9A%E8%BF%87tensorflow2%E4%BD%BF%E7%94%A8bert%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F.html</link><pubDate>Thu, 16 Jul 2020 21:07:00 +0000</pubDate><guid>/post/deep-learning/2020-07-16-%E9%80%9A%E8%BF%87tensorflow2%E4%BD%BF%E7%94%A8bert%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8F.html</guid><description>以中文Bert为例
下面的例子均以中文Bert预训练模型为例
方式1：使用Tensorflow Hub import tensorflow as tf import tensorflow_hub as hub hub_url_or_local_path = &amp;#34;https://tfhub.dev/tensorflow/bert_zh_L-12_H-768_A-12/2&amp;#34; # 或者将模型下载到本地 # !wget &amp;#34;https://storage.googleapis.com/tfhub-modules/tensorflow/bert_zh_L-12_H-768_A-12/2.tar.gz&amp;#34; # !tar -xzvf 2.tar.gz -C bert_zh_L-12_H-768_A-12 # hub_url_or_local_path = &amp;#34;./bert_zh_L-12_H-768_A-12&amp;#34; def build_model(): input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=&amp;#34;input_word_ids&amp;#34;) input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=&amp;#34;input_mask&amp;#34;) segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=&amp;#34;segment_ids&amp;#34;) bert_layer = hub.KerasLayer(hub_url_or_local_path, name=&amp;#39;bert&amp;#39;, trainable=True) pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids]) model = tf.keras.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=sequence_output) return model model = build_model() model.summary() 使用这种方式的时候在执行build_model时bert的参数已经被加载进来了。</description></item></channel></rss>