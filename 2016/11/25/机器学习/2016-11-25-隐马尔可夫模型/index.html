<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="隐马尔可夫模型解决的序列标注问题，它是一个生成模型。本文先介绍显马尔可夫模型（或者叫马尔可夫链），然后介绍显马尔可夫模型的扩展，即隐马尔可夫模型。显与隐指的是状态序列是否可观测。 显（可视）马尔可夫模型显马尔可夫模型、可视马尔可夫模型、马尔可夫链都是指马尔可夫模型。 随机过程又称随机函数，是随时间而随机变化的过程。马尔可夫模型描述了一类（这些随机变量并非相互独立，每个随机变量的值依赖于这个序列前面">
<meta property="og:type" content="article">
<meta property="og:title" content="隐马尔可夫模型">
<meta property="og:url" content="http://example.com/2016/11/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2016-11-25-%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/index.html">
<meta property="og:site_name" content="Writing Lite">
<meta property="og:description" content="隐马尔可夫模型解决的序列标注问题，它是一个生成模型。本文先介绍显马尔可夫模型（或者叫马尔可夫链），然后介绍显马尔可夫模型的扩展，即隐马尔可夫模型。显与隐指的是状态序列是否可观测。 显（可视）马尔可夫模型显马尔可夫模型、可视马尔可夫模型、马尔可夫链都是指马尔可夫模型。 随机过程又称随机函数，是随时间而随机变化的过程。马尔可夫模型描述了一类（这些随机变量并非相互独立，每个随机变量的值依赖于这个序列前面">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://www.52nlp.cn/images/fb5.png">
<meta property="article:published_time" content="2016-11-25T09:03:00.000Z">
<meta property="article:modified_time" content="2020-12-02T06:52:04.973Z">
<meta property="article:author" content="hwyoung">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.52nlp.cn/images/fb5.png">

<link rel="canonical" href="http://example.com/2016/11/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2016-11-25-%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>隐马尔可夫模型 | Writing Lite</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Writing Lite</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2016/11/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2016-11-25-%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/avatar.png">
      <meta itemprop="name" content="hwyoung">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Writing Lite">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          隐马尔可夫模型
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-11-25 09:03:00" itemprop="dateCreated datePublished" datetime="2016-11-25T09:03:00+00:00">2016-11-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-12-02 06:52:04" itemprop="dateModified" datetime="2020-12-02T06:52:04+00:00">2020-12-02</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>隐马尔可夫模型解决的序列标注问题，它是一个生成模型。本文先介绍显马尔可夫模型（或者叫马尔可夫链），然后介绍显马尔可夫模型的扩展，即隐马尔可夫模型。显与隐指的是状态序列是否可观测。</p>
<h2 id="显（可视）马尔可夫模型"><a href="#显（可视）马尔可夫模型" class="headerlink" title="显（可视）马尔可夫模型"></a>显（可视）马尔可夫模型</h2><p>显马尔可夫模型、可视马尔可夫模型、马尔可夫链都是指马尔可夫模型。</p>
<p>随机过程又称随机函数，是随时间而随机变化的过程。马尔可夫模型描述了一类（这些随机变量并非相互独立，每个随机变量的值依赖于这个序列前面的状态）重要的随机过程。<br>随机过程有两层含义：</p>
<ol>
<li> 它是一个时间的函数，随着时间的改变可改变。</li>
<li> 每个时刻上的函数值是不确定的，是随机的，也就是说，每一时刻上的函数值按照一定的概率而分布。</li>
</ol>
<h3 id="马尔可夫模型与有限状态机"><a href="#马尔可夫模型与有限状态机" class="headerlink" title="马尔可夫模型与有限状态机"></a>马尔可夫模型与有限状态机</h3><p>马尔可夫模型又可视为随机的有限状态机，更准确的说马尔可夫模型和隐马尔可夫模型都是有限自动机的扩充。</p>
<h3 id="马尔可夫模型与n元文法模型"><a href="#马尔可夫模型与n元文法模型" class="headerlink" title="马尔可夫模型与n元文法模型"></a>马尔可夫模型与n元文法模型</h3><p>前面提到在马尔可夫模型中每个随机变量受这个序列前面的状态影响的，如果我们只考虑前面一个状态对后面一个状态出现的概率的影响，这样的链叫做一重马尔可夫链，也就量二元文法模型，如果考虑前面两个状态，这样的叫二重马可尔可夫链，也就是三元文法模型，依此类推，n重马尔可夫链对应n-1元文法模型。</p>
<hr>
<h2 id="隐马尔可夫模型"><a href="#隐马尔可夫模型" class="headerlink" title="隐马尔可夫模型"></a>隐马尔可夫模型</h2><p>马尔可夫模型是关于时序的概率模型，描述由一个隐藏的马尔可夫链随机生成不可可观测 的状态随机序列，再由各个状态生成一个观测而产生观测 随机序列的过程。<br>马尔可夫模型是一个生成模型，因此它也是学习</p>
<p>$$<br>p(y \vert x) = \frac{p(x,y)}{p(x)} = \frac{p(x \vert y)p(y)}{p(x)}<br>$$</p>
<h3 id="相关符号"><a href="#相关符号" class="headerlink" title="相关符号"></a>相关符号</h3><p>高Q是所有可能<strong>状态集合</strong>，V是所有可能的<strong>观测集合</strong>。<br>$$<br>Q={q_1,q_2, … q_N },V={v_1,v_2, … v_M }<br>$$<br>N是可能的状态数，M是可能的观测数。<br>I是长度为T的状态序列，O是对应的观测序列。<br>$$<br>I={i_1,i_2, … i_T },O={o_1,o_2, … o_T }<br>$$<br><strong>A是状态转移矩阵</strong>：<br>$$<br>A=[a_{ij}]<em>{M \times N}<br>$$<br>其中<br>$$<br>a</em>{ij}=P(i_{t+1}=q_j|i_t=q_i), \qquad i=1,2…N;j=1,2…N<br>$$<br>表示在时刻t处于状态qi的状态下在时刻t+1转移到状态qj的概率。</p>
<p><strong>B是观测概率矩阵</strong>：<br>$$<br>B=[b_j(k)]_{N \times M}<br>$$</p>
<p>其中，<br>$$<br>b_j(k) = P(o_t=v_k|i_t=q_j), \qquad k=1,2…M;j=1,2…N<br>$$<br>表示在时刻t处于状态qj的条件下生成观测vk的概率。<br><strong>$\pi$是初始状态概率向量</strong>：<br>$$<br>\pi = (\pi_i)<br>$$<br>其中<br>$$<br>\pi_i=P(i_1=q_i), \qquad i=1,2…N<br>$$<br>表示时刻t=1处于状态qi的概率。</p>
<p><strong>马尔可夫模型$\lambda$可以用三元符号表示</strong>，即<br>$$<br>\lambda=(A,B,\pi)<br>$$</p>
<h3 id="2个假设"><a href="#2个假设" class="headerlink" title="2个假设"></a>2个假设</h3><ol>
<li> 齐次马尔可夫假设，即假设隐藏的马尔可夫链在任意时刻t的状态只依赖于其前一时刻的状态，与其它时刻的状态及观测无关，也与时刻t无关。<br>$$<br>P(i_t \mid i_{t-1},o_{t-1},…,i_1,o_1) = P(i_t \mid i_{t-1}), \qquad t=1,2,…,T<br>$$</li>
<li> 观测独立假设，即假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其它观测及状态无关。<br>$$<br>P(o_t \mid i_T,o_T,i_{T-1},o_{T-1},…,i_{t+1},o_{t+1},i_t,i_{t-1},o_{t-1}…,i_1,o_1) = P(o_t \mid i_{t})<br>$$</li>
</ol>
<h3 id="3个要素"><a href="#3个要素" class="headerlink" title="3个要素"></a>3个要素</h3><ol>
<li> 状态转移概率矩阵（输出）(A)</li>
<li> 观测概率矩阵（输入）(B)</li>
<li> 初始状态概率矩阵($\pi$)</li>
</ol>
<h3 id="3个问题"><a href="#3个问题" class="headerlink" title="3个问题"></a>3个问题</h3><ol>
<li> 概率计算问题，给定一个模型$\lambda=(A,B,\pi)$和观测序列$O=(o_1,o_2,…,o_T)$，计算在模型$\lambda$下观测序列O出现的$P(O \mid \lambda)$；</li>
<li> 学习问题，给定足够量的观测数据，如何估计隐马尔可夫模型的参数；即已知观测序列$O=(o_1,o_2,…,o_T)$，估计模型参数$\lambda=(A,B,\pi)$，使得的$P(O \mid \lambda)$在该模型观测序列概率最大。即用极大似然估计的方法估计参数。</li>
<li> 预测问题也称解码问题，给定一个模型和某个特定的输出序列，如何找到最可能产生这个输出的状态序列；即已知模型数$\lambda=(A,B,\pi)$和观测序列$O=(o_1,o_2,…,o_T)$，求给定观测序列条件概率$P(I \mid O)$ 最大的状态序列$I(i_1,i_2,…,i_T)$。即给定观测序列，求最大可能的对应的状态序列。</li>
</ol>
<h2 id="概率计算问题"><a href="#概率计算问题" class="headerlink" title="概率计算问题"></a>概率计算问题</h2><h3 id="直接计算"><a href="#直接计算" class="headerlink" title="直接计算"></a>直接计算</h3><h3 id="前向算法"><a href="#前向算法" class="headerlink" title="前向算法"></a>前向算法</h3><p>定义<strong>前向概率</strong> 给定隐马尔可夫模型$\lambda$，定义从开始到时刻t的部分观测序列为$o_1,o_2,…,o_t$且在时刻t的状态为$q_i$的概率为前向概率，记作<br>$$<br>\alpha_t(i)=P(o_1,o_2,…,o_t,i=q_i \mid \lambda)<br>$$<br>前向算法步骤：<br>（1）初值<br>$$<br>\alpha_1(i)=\pi_ib_i(o_1), \qquad i=1,2…N<br>$$<br>（2）递推<br>$$<br>\alpha_{t+1}(i)=\left[ \sum_{j=1}^N\alpha_i(j)a_{ji} \right]b_i(o_{t+1}), \qquad i=1,2…N<br>$$<br>（3）终止<br>$$<br>P(O \mid \lambda) = \sum_{i=1}^N \alpha_T(i)<br>$$</p>
<h3 id="后向算法"><a href="#后向算法" class="headerlink" title="后向算法"></a>后向算法</h3><p>定义<strong>后向概率</strong> 给定隐马尔可夫模型$\lambda$，定义在时刻t状态为$q_i$的条件下，从t+1到T的部分观测序列为$o_{t+1},o_{t+2},…,o_T$的概率为后向概率，记作<br>$$<br>\beta_t(i)=P(o_{t+1},o_{t+2},…,o_T \mid i_t=q_i,\lambda)<br>$$<br>后向算法步骤：<br>（1）<br>$$<br>\beta_T(i)=1, \qquad i=1,2…N<br>$$<br>（2）对t=T-1,T-2,…,1<br>$$<br>\beta_{t}(i)=\sum_{j=1}^N a_{ij}b_j(o_{t+1})\beta_{t+1}(j), \qquad i=1,2…N<br>$$<br>（3）<br>$$<br>P(O \mid \lambda) = \sum_{i=1}^N \pi_i b_i(o_1)\beta_1(i)<br>$$</p>
<p>可以将观测序列概率P(O|λ)统一写成：<br>$$<br>P(O|\lambda)=\sum_{i=1}^N\sum_{j=1}^N \alpha_t(i)a_{ij}b_j(o_{t+1})\beta_{t+1}(j)<br>$$<br>此式当，t=1和t=T-1时，分别为<br>$$<br>\sum_{i=1}^N \alpha_T(i) \<br>\sum_{i=1}^N \pi_i b_i(o_1)\beta_1(i)<br>$$<br>两个求和符号中的$\alpha_t(i)a_{ij}b_j(o_{t+1})\beta_{t+1}(j)$其实经过概率表示等价于：<br>$$<br>\alpha_t(i)a_{ij}b_j(o_{t+1})\beta_{t+1}(j)=P(o_1,o_2,…,o_T,i_t=q_i,i_{t+1}=q_j|\lambda)<br>$$<br>两次求和其实就是将状态qi和状态qj的所有可能取值都取一遍，N是所有可能的状态数。</p>
<h3 id="一些概率和期望的计算"><a href="#一些概率和期望的计算" class="headerlink" title="一些概率和期望的计算"></a>一些概率和期望的计算</h3><ol>
<li><p>定义，<strong>给定模型$\lambda$和观测$O$，在时刻t处于状态qi的概率</strong>为<br>$$<br>\begin{aligned}<br>\gamma_t(i) &amp; = P(i_t=q_i \mid O,\lambda) = \frac{P(i_t=q_i,O \mid \lambda)}{P(O \mid \lambda)} \<br>&amp; = \frac{P(i_t=q_i,O \mid \lambda)}{\sum_i^N P(i_t=q_i,O \mid \lambda)} \<br>&amp; = \frac{\alpha_t(i)\beta_t(i)}{\sum_i^N\alpha_t(i)\beta_t(i)}<br>\end{aligned}<br>$$<br>在这里<br>$$<br>\begin{aligned}<br>P(i_t=q_i,O \mid \lambda) &amp;= \alpha_t(i)=P(o_1,o_2,…,o_t,i=q_i \mid \lambda) P(o_{t+1},o_{t+2},…,o_T \mid i_t=q_i,\lambda)  \<br>&amp; = \alpha_t(i)\beta_t(i)<br>\end{aligned}<br>$$<br>通俗的解释为，给定模型$\lambda$，观测到整个观测序列O且到t时刻的状态为qi的概率，等于给定模型$\lambda$，到时刻t的观测序列且到t时刻的状态为qi的概率，并且在t时刻的状态为qi的条件下，从t到结束的概率。</p>
</li>
<li><p>定义，<strong>给定模型$\lambda$和观测$O$，在时刻t处于状态qi，且在t+1处于状态j的概率</strong>为<br>$$<br>\begin{aligned}<br>\xi_t(i,j) &amp; = P(i_t=q_i,i_{t+1}=q_j \mid O,\lambda) = \frac{P(i_t=q_i,i_{t+1}=q_j,O \mid \lambda)}{P(O \mid \lambda)} \<br>&amp; = \frac{P(i_t=q_i,i_{t+1}=q_j,O \mid \lambda)}{\sum_i^N P(i_t=q_i,O \mid \lambda)} \<br>&amp; = \frac{P(i_t=q_i,i_{t+1}=q_j,O \mid \lambda)}{\sum_i^N \sum_j^N P(i_t=q_i,i_{t+1}=q_j,O \mid \lambda)} \<br>&amp; = \frac{\alpha_t(i)a_{ij}b_j(o_{t+1})\beta_{t+1}(j)}{\sum_i^N \sum_j^N \alpha_t(i)a_{ij}b_j(o_{t+1})\beta_{t+1}(j)} \<br>\end{aligned}<br>$$<br>在这里<br>$$<br>\begin{aligned}<br>&amp; P(i_t=q_i,i_{t+1}=q_j,O \mid \lambda) \<br>&amp;=\alpha_t(i)a_{ij}b_j(o_{t+1})\beta_{t+1}(j)\<br>&amp;=P(o_1,o_2,…o_t,i_t=q_i|\lambda) P(q_j \mid q_i) P(o_{t+1} \mid q_j) P(o_{t+2},o_{t+3},…,o_T \mid i_{t+1}=q_j,\lambda)<br>\end{aligned}<br>$$<br>通俗解释是，给定模型$\lambda$和观测$O$，在时刻t处于状态qi，且在t+1处于状态j的概率，等于给定隐马尔可夫模型$\lambda$，从开始到时刻t的部分观测序列为$o_1,o_2,…,o_t$且在时刻t的状态为$q_i$的概率，并且在t时刻状态为$q_i$的条件下t+1时刻的状态为$q_j$的概率，并且$q_j$生成$o_{t+1}$的概率，并且在时刻t+1状态为$q_j$的条件下，从t+2到T的部分观测序列为$o_{t+2},o_{t+3},…,o_T$的概率。<br><img src="http://www.52nlp.cn/images/fb5.png" alt="此处输入图片的描述"></p>
</li>
<li><p>利用$\gamma_t(i)$和$\xi_t(i,j)$可以得到一些有用的期望</p>
</li>
</ol>
<p>（1）在观测O下状态i出现的期望值为<br>$$<br>\sum_{t=1}^T\gamma_t(i)<br>$$<br>（2）在观测O下由状态i转移的期望值为<br>$$<br>\sum_{t=1}^{T-1}\gamma_t(i)<br>$$</p>
<p>（3）在观测O下由状态i转移到j期望值<br>$$<br>\sum_{t=1}^{T-1}\xi_t(i,j)<br>$$</p>
<h2 id="学习问题"><a href="#学习问题" class="headerlink" title="学习问题"></a>学习问题</h2><h2 id="预测问题"><a href="#预测问题" class="headerlink" title="预测问题"></a>预测问题</h2><h3 id="维特比算法"><a href="#维特比算法" class="headerlink" title="维特比算法"></a>维特比算法</h3><p>维特比算法的基础概括为以下3点：</p>
<ol>
<li>如果概率最大的路径P（最短路径）经过某个点，比如图中的x22，那么这条路径上从起始眯S到s22的这一段子路径Q，一定是S到x22的最短路径。否则，用S到x22的最短路径R替代Q，便构成了一条比P更短的路径，这是显然是矛盾的。<br> <strong>换句话说，如果概率最大的路径P（最短路径）经过某个点，比如图中的x22，那么是S到x22的最短路径一定是S到E的最短路径的子路径。</strong></li>
<li>从S到E的路径必定经过第i时刻的某个状态 ，假设第i时刻有k个状态，那么如果记录了从S到第i个状态的所有k个结点的最短路径（指的是从S到各个k的最短路径），最终的最短路径必经过其中的一条。这样，在任何时刻，只要考虑非常有限条最短路径即可。</li>
<li>结合上述两点，假定当我们从状态i到状态i+1时，从状态i上各个结点的最短路径已经找到，并且记录在这些结点上，那么在计算从起点S到第i+1状态的某个结点$x_{t+1}$的最短路径时，只要考虑从S到前一个状态i所有的k个结点的最短路径，以及从这k个结点到$x_{t+1}$,j的距离即可</li>
</ol>
<p>其实用一句话来说的话，也就是这样的原理。如果概率最大的路径P（最短路径）经过某个点，比如图中的x22，那么是S到x22的最短路径一定是S到E的最短路径的子路径。</p>
<p>第一步，从S出发，对于第一状态x1的各个节点，不妨假设有n1个，计算出S到它们的距离d(S,$x_{1i}$)，其中$x_{1i}$代表任意状态1的节点。因为只有一步，所以这些距离都是S到它们各自的最短距离。<br>第二步，要计算出从S到它们的最短距离。我们知道，对于特定的节点$x_{2i}$，从S到它的路径可以经过状态1的n1中任何一个节点$x_{1i}$，当然，对应的路径长度就是$d(S,x_{2i}) = d(S,x_{1j}) + d(x_{1j},x_{2i}) $我们要一一计算，找到最小值。<br>$$<br>d(S,x_{2i}) = min\ d(S,x_{1j}) + d(x_{1j},x_{2i})<br>$$<br>也就是说，从S到状态2的最短路径，等于从S到状态1的各个最短路径加上从状态1到状态2的距离中概率最大的一个。也可以说，我们知道S到状态1的n1个最短路径，那么从S到状态2的最短路径就等于这n1条路径到状态2中概率最大的一个。</p>
<h3 id="HMM与CRF"><a href="#HMM与CRF" class="headerlink" title="HMM与CRF"></a>HMM与CRF</h3><p>《统计自然语言处理》<br>HMM是生成式模型，以朴素贝叶斯为基础。<br>CRF是判别式模型，以逻辑回归为基础。</p>
<p><a target="_blank" rel="noopener" href="http://blog.csdn.net/xmu_jupiter/article/details/50956389">http://blog.csdn.net/xmu_jupiter/article/details/50956389</a></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2016/11/25/%E5%85%B6%E5%AE%83/2016-11-25-linux%E4%B8%8Blighttd%E5%AE%89%E8%A3%85%EF%BC%8C%E9%83%A8%E7%BD%B2hexo/" rel="prev" title="linux下lighttd安装，部署hexo">
      <i class="fa fa-chevron-left"></i> linux下lighttd安装，部署hexo
    </a></div>
      <div class="post-nav-item">
    <a href="/2016/11/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2016-11-27-EM%E7%AE%97%E6%B3%95/" rel="next" title="EM算法">
      EM算法 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%98%BE%EF%BC%88%E5%8F%AF%E8%A7%86%EF%BC%89%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.</span> <span class="nav-text">显（可视）马尔可夫模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA"><span class="nav-number">1.1.</span> <span class="nav-text">马尔可夫模型与有限状态机</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B%E4%B8%8En%E5%85%83%E6%96%87%E6%B3%95%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.2.</span> <span class="nav-text">马尔可夫模型与n元文法模型</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.</span> <span class="nav-text">隐马尔可夫模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E7%AC%A6%E5%8F%B7"><span class="nav-number">2.1.</span> <span class="nav-text">相关符号</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2%E4%B8%AA%E5%81%87%E8%AE%BE"><span class="nav-number">2.2.</span> <span class="nav-text">2个假设</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3%E4%B8%AA%E8%A6%81%E7%B4%A0"><span class="nav-number">2.3.</span> <span class="nav-text">3个要素</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3%E4%B8%AA%E9%97%AE%E9%A2%98"><span class="nav-number">2.4.</span> <span class="nav-text">3个问题</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A6%82%E7%8E%87%E8%AE%A1%E7%AE%97%E9%97%AE%E9%A2%98"><span class="nav-number">3.</span> <span class="nav-text">概率计算问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B4%E6%8E%A5%E8%AE%A1%E7%AE%97"><span class="nav-number">3.1.</span> <span class="nav-text">直接计算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%89%8D%E5%90%91%E7%AE%97%E6%B3%95"><span class="nav-number">3.2.</span> <span class="nav-text">前向算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%8E%E5%90%91%E7%AE%97%E6%B3%95"><span class="nav-number">3.3.</span> <span class="nav-text">后向算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B%E6%A6%82%E7%8E%87%E5%92%8C%E6%9C%9F%E6%9C%9B%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="nav-number">3.4.</span> <span class="nav-text">一些概率和期望的计算</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98"><span class="nav-number">4.</span> <span class="nav-text">学习问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%A2%84%E6%B5%8B%E9%97%AE%E9%A2%98"><span class="nav-number">5.</span> <span class="nav-text">预测问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%B4%E7%89%B9%E6%AF%94%E7%AE%97%E6%B3%95"><span class="nav-number">5.1.</span> <span class="nav-text">维特比算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HMM%E4%B8%8ECRF"><span class="nav-number">5.2.</span> <span class="nav-text">HMM与CRF</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="hwyoung"
      src="/avatar.png">
  <p class="site-author-name" itemprop="name">hwyoung</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">77</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">hwyoung</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
